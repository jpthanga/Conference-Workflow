{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M/D/Time\n",
    "Poster\n",
    "1012.\n",
    "\n",
    "12/4/1900 x225\n",
    "12/5/1900 x225\n",
    "12/6/1900 x230\n",
    "\n",
    "Oral x2 tracks\n",
    "12/5/1040 x3\n",
    "12/5/1450 x2\n",
    "12/5/1620 x3\n",
    "\n",
    "12/6/1020 x4\n",
    "12/6/1450 x2\n",
    "12/6/1620 x3\n",
    "\n",
    "12/7/1110 x3\n",
    "\n",
    "Spotlight x2 tracks\n",
    "12/5/1040 x7\n",
    "12/5/1450 x6\n",
    "12/5/1620 x11\n",
    "\n",
    "12/6/1020 x8\n",
    "12/6/1450 x6\n",
    "12/6/1620 x11\n",
    "\n",
    "12/7/1110 x7\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import MDS, TSNE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from lxml import etree\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "\n",
    "from ortools.linear_solver import pywraplp\n",
    "from ortools.constraint_solver import pywrapcp\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import sys\n",
    "from cmtutils import extract_stem_words as bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def paper2tmpsvec(xmlfn, papers):    \n",
    "    rids = set()\n",
    "    pids = set()\n",
    "    paper_reviewer_tpms = {}\n",
    "    doc = etree.parse(xmlfn)\n",
    "    for s in tqdm_notebook(doc.xpath('submission')):\n",
    "        pid = int(s.get('submissionId'))\n",
    "        if pid not in papers:\n",
    "            continue\n",
    "        pids.add(pid)\n",
    "        rev_rels = {}\n",
    "        for r in s.xpath('metareviewer|reviewer'):\n",
    "            rid = r.get('email').lower()\n",
    "            score = float(r.get('score'))\n",
    "            rev_rels[rid] = score\n",
    "            rids.add(rid)            \n",
    "        paper_reviewer_tpms[pid] = rev_rels\n",
    "        \n",
    "    rid2idx = dict(zip(rids, range(len(rids))))\n",
    "    paper_tpmsvec = []\n",
    "    for p, rid_rels in tqdm_notebook(paper_reviewer_tpms.items()):\n",
    "        vec = np.zeros(len(rids))\n",
    "        for rid, rel in rid_rels.items():\n",
    "            vec[rid2idx[rid]] = rel\n",
    "        paper_tpmsvec.append((p, vec))\n",
    "    \n",
    "    for p in papers:\n",
    "        if p not in pids:\n",
    "            paper_tpmsvec.append((int(p), np.zeros(len(rids))))\n",
    "    df = pd.DataFrame.from_records(paper_tpmsvec, columns=[\"pid\", \"tpms\"])\n",
    "    return df, rid2idx\n",
    "\n",
    "# df [pid, [np array]]\n",
    "# dict reviewers to paper scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper2tmp(fname, papers):\n",
    "    rids = set()\n",
    "    rids = set()\n",
    "    pids = set()\n",
    "    paper_reviewer_tpms = {}\n",
    "    \n",
    "    #  Paper ID                               1\n",
    "    #  Email          16211020010@fudan.edu.cn\n",
    "    #  TPMS Score                     0.553318\n",
    "    \n",
    "    tpms = pd.read_csv(fname)\n",
    "    \n",
    "    for index, row in tqdm_notebook(tpms.iterrows(), total=14535185):\n",
    "        \n",
    "        Id = row['Paper ID']\n",
    "        \n",
    "        if Id in papers:\n",
    "            email = row[' Email'].lower()\n",
    "            score = row[' TPMS Score']\n",
    "            pids.add(Id)\n",
    "\n",
    "            if Id not in paper_reviewer_tpms.keys():\n",
    "                paper_reviewer_tpms[Id] = {}\n",
    "\n",
    "            paper_reviewer_tpms[Id][email] = score\n",
    "            rids.add(email)\n",
    "    \n",
    "    rid2idx = dict(zip(rids, range(len(rids))))\n",
    "    paper_tpmsvec = []\n",
    "    \n",
    "    \n",
    "    for p, rid_rels in tqdm_notebook(paper_reviewer_tpms.items()):\n",
    "        vec = np.zeros(len(rids))\n",
    "        for rid, rel in rid_rels.items():\n",
    "            vec[rid2idx[rid]] = rel\n",
    "        paper_tpmsvec.append((p, vec))\n",
    "    \n",
    "    for p in papers:\n",
    "        if p not in pids:\n",
    "            paper_tpmsvec.append((int(p), np.zeros(len(rids))))\n",
    "    df = pd.DataFrame.from_records(paper_tpmsvec, columns=[\"pid\", \"tpms\"])\n",
    "      \n",
    "    return df, rid2idx\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each row is a paper\n",
    "def cosinesim(A, znorm=True):    \n",
    "    if znorm:\n",
    "        mean = np.mean(A, axis=1).reshape((-1, 1))\n",
    "        std = np.std(A, axis=1).reshape((-1, 1))    \n",
    "        A = (A - mean) / std        \n",
    "    A[np.isnan(A)] = 0\n",
    "    sim = np.dot(A, A.T)    \n",
    "    D = np.diag(sim)    \n",
    "    invD = 1./D\n",
    "    invD[np.isinf(invD)] = 0    \n",
    "    invD = np.sqrt(invD)    \n",
    "    cosine = sim * invD\n",
    "    cosine = cosine.T * invD\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_equal(strings):\n",
    "    A = [hash(a) for a in strings]\n",
    "    return np.equal.outer(A, A).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Efficient Algorithms for Non-convex Isotonic R...</td>\n",
       "      <td>[effici, algorithm, non, convex, isoton, regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Structure-Aware Convolutional Neural Networks</td>\n",
       "      <td>[structur, awar, convolut, neural, network, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kalman Normalization</td>\n",
       "      <td>[kalman, normal, indispens, compon, batch, nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOGWILD!-Gibbs can be PanAccurate</td>\n",
       "      <td>[hogwild, gibb, panaccur, asynchron, gibb, sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Text-Adaptive Generative Adversarial Networks:...</td>\n",
       "      <td>[text, adapt, gener, adversari, network, manip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IntroVAE: Introspective Variational Autoencode...</td>\n",
       "      <td>[introva, introspect, variat, autoencod, photo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Doubly Robust Bayesian Inference for Non-Stati...</td>\n",
       "      <td>[doubli, robust, bayesian, infer, non, station...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adapted Deep Embeddings: A Synthesis of Method...</td>\n",
       "      <td>[adapt, deep, embed, synthesi, method, shot, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Generalized Inverse Optimization through Onlin...</td>\n",
       "      <td>[gener, invers, optim, onlin, learn, invers, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>An Off-policy Policy Gradient Theorem Using Em...</td>\n",
       "      <td>[polici, polici, gradient, theorem, use, empha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Supervised autoencoders: Improving generalizat...</td>\n",
       "      <td>[supervis, autoencod, improv, gener, perform, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Visual Object Networks: Image Generation with ...</td>\n",
       "      <td>[visual, object, network, imag, gener, disenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Understanding Weight Normalized Deep Neural Ne...</td>\n",
       "      <td>[understand, weight, normal, deep, neural, net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Learning Pipelines with Limited Data and Domai...</td>\n",
       "      <td>[learn, pipelin, limit, data, domain, knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Learning long-range spatial dependencies with ...</td>\n",
       "      <td>[learn, long, rang, spatial, depend, horizont,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Joint Sub-bands Learning with Clique Structure...</td>\n",
       "      <td>[joint, sub, band, learn, cliqu, structur, wav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fast Similarity Search via Optimal Sparse Lifting</td>\n",
       "      <td>[fast, similar, search, via, optim, spars, lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Learning Deep Disentangled Embeddings With the...</td>\n",
       "      <td>[learn, deep, disentangl, embed, statist, loss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Geometrically Coupled Monte Carlo Sampling</td>\n",
       "      <td>[geometr, coupl, mont, carlo, sampl, mont, car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cooperative Holistic 3D Scene Understanding fr...</td>\n",
       "      <td>[cooper, holist, 3d, scene, understand, singl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>An Efficient Pruning Algorithm for Robust Isot...</td>\n",
       "      <td>[effici, prune, algorithm, robust, isoton, reg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PAC-learning in the presence of adversaries</td>\n",
       "      <td>[pac, learn, presenc, adversari, exist, evas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sparse DNNs with Improved Adversarial Robustness</td>\n",
       "      <td>[spars, dnn, improv, adversari, robust, deep, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Snap ML: A Hierarchical Framework for Machine ...</td>\n",
       "      <td>[snap, ml, hierarch, framework, machin, learn,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>See and Think: Disentangling Semantic Scene Co...</td>\n",
       "      <td>[see, think, disentangl, semant, scene, comple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chain of Reasoning for Visual Question Answering</td>\n",
       "      <td>[chain, reason, visual, question, answer, reas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sigsoftmax: Reanalysis of the Softmax Bottleneck</td>\n",
       "      <td>[sigsoftmax, reanalysi, softmax, bottleneck, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Deep Non-Blind Deconvolution via Generalized L...</td>\n",
       "      <td>[deep, non, blind, deconvolut, via, gener, low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Probabilistic Pose Graph Optimization via Bing...</td>\n",
       "      <td>[probabilist, pose, graph, optim, via, bingham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MetaAnchor: Learning to Detect Objects with Cu...</td>\n",
       "      <td>[metaanchor, learn, detect, object, custom, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Thermostat-assisted continuously-tempered Hami...</td>\n",
       "      <td>[thermostat, assist, continu, temper, hamilton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>Robust Subspace Approximation in a Stream</td>\n",
       "      <td>[robust, subspac, approxim, stream, studi, rob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Mean Field for the Stochastic Blockmodel: Opti...</td>\n",
       "      <td>[mean, field, stochast, blockmodel, optim, lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Analysis of Krylov Subspace Solutions of  Regu...</td>\n",
       "      <td>[analysi, krylov, subspac, solut, regular, non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Autoconj: Recognizing and Exploiting Conjugacy...</td>\n",
       "      <td>[autoconj, recogn, exploit, conjugaci, without...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>DropBlock: A regularization method for convolu...</td>\n",
       "      <td>[dropblock, regular, method, convolut, network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Forward Modeling for Partial Observation Strat...</td>\n",
       "      <td>[forward, model, partial, observ, strategi, ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>With Friends Like These, Who Needs Adversaries?</td>\n",
       "      <td>[friend, like, need, adversari, vulner, deep, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Decentralize and Randomize: Faster Algorithm f...</td>\n",
       "      <td>[decentr, random, faster, algorithm, wasserste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Joint Autoregressive and Hierarchical Priors f...</td>\n",
       "      <td>[joint, autoregress, hierarch, prior, learn, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Learning Temporal Point Processes via Reinforc...</td>\n",
       "      <td>[learn, tempor, point, process, via, reinforc,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Bias and Generalization in Deep Generative Mod...</td>\n",
       "      <td>[bia, gener, deep, gener, model, empir, studi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Fast and Effective Robustness Certification</td>\n",
       "      <td>[fast, effect, robust, certif, present, new, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Support Recovery for Orthogonal Matching Pursu...</td>\n",
       "      <td>[support, recoveri, orthogon, match, pursuit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Differentially Private Change-Point Detection</td>\n",
       "      <td>[differenti, privat, chang, point, detect, cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Multi-value Rule Sets for Interpretable Classi...</td>\n",
       "      <td>[multi, valu, rule, set, interpret, classif, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Domain Adaptation by Using Causal Inference to...</td>\n",
       "      <td>[domain, adapt, use, causal, infer, predict, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Smoothed Analysis of Discrete Tensor Decomposi...</td>\n",
       "      <td>[smooth, analysi, discret, tensor, decomposit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>MixLasso: Generalized Mixed Regression via Con...</td>\n",
       "      <td>[mixlasso, gener, mix, regress, via, convex, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>Semidefinite relaxations for certifying robust...</td>\n",
       "      <td>[semidefinit, relax, certifi, robust, adversar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Removing Hidden Confounding by Experimental Gr...</td>\n",
       "      <td>[remov, hidden, confound, experiment, ground, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Topkapi: Parallel and Fast Sketches for Findin...</td>\n",
       "      <td>[topkapi, parallel, fast, sketch, find, top, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>Contrastive Learning from Pairwise Measurements</td>\n",
       "      <td>[contrast, learn, pairwis, measur, learn, pair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>Point process latent variable models of freely...</td>\n",
       "      <td>[point, process, latent, variabl, model, freel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>Computationally and Statistically Efficient Le...</td>\n",
       "      <td>[comput, statist, effici, learn, bay, net, use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>Sparse PCA from Sparse Linear Regression</td>\n",
       "      <td>[spars, pca, spars, linear, regress, spars, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>Sequential Data Classification for Resource-co...</td>\n",
       "      <td>[sequenti, data, classif, resourc, constrain, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Transfer of Deep Reactive Policies for MDP Pla...</td>\n",
       "      <td>[transfer, deep, reactiv, polici, mdp, plan, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>The Price of Fair PCA: One Extra dimension</td>\n",
       "      <td>[price, fair, pca, one, extra, dimens, thi, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>GroupReduce: Block-Wise Low-Rank Approximation...</td>\n",
       "      <td>[groupreduc, block, wise, low, rank, approxim,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Paper Title  \\\n",
       "0     Efficient Algorithms for Non-convex Isotonic R...   \n",
       "1         Structure-Aware Convolutional Neural Networks   \n",
       "2                                  Kalman Normalization   \n",
       "3                     HOGWILD!-Gibbs can be PanAccurate   \n",
       "4     Text-Adaptive Generative Adversarial Networks:...   \n",
       "5     IntroVAE: Introspective Variational Autoencode...   \n",
       "6     Doubly Robust Bayesian Inference for Non-Stati...   \n",
       "7     Adapted Deep Embeddings: A Synthesis of Method...   \n",
       "8     Generalized Inverse Optimization through Onlin...   \n",
       "9     An Off-policy Policy Gradient Theorem Using Em...   \n",
       "10    Supervised autoencoders: Improving generalizat...   \n",
       "11    Visual Object Networks: Image Generation with ...   \n",
       "12    Understanding Weight Normalized Deep Neural Ne...   \n",
       "13    Learning Pipelines with Limited Data and Domai...   \n",
       "14    Learning long-range spatial dependencies with ...   \n",
       "15    Joint Sub-bands Learning with Clique Structure...   \n",
       "16    Fast Similarity Search via Optimal Sparse Lifting   \n",
       "17    Learning Deep Disentangled Embeddings With the...   \n",
       "18           Geometrically Coupled Monte Carlo Sampling   \n",
       "19    Cooperative Holistic 3D Scene Understanding fr...   \n",
       "20    An Efficient Pruning Algorithm for Robust Isot...   \n",
       "21          PAC-learning in the presence of adversaries   \n",
       "22     Sparse DNNs with Improved Adversarial Robustness   \n",
       "23    Snap ML: A Hierarchical Framework for Machine ...   \n",
       "24    See and Think: Disentangling Semantic Scene Co...   \n",
       "25     Chain of Reasoning for Visual Question Answering   \n",
       "26     Sigsoftmax: Reanalysis of the Softmax Bottleneck   \n",
       "27    Deep Non-Blind Deconvolution via Generalized L...   \n",
       "28    Probabilistic Pose Graph Optimization via Bing...   \n",
       "29    MetaAnchor: Learning to Detect Objects with Cu...   \n",
       "...                                                 ...   \n",
       "982   Thermostat-assisted continuously-tempered Hami...   \n",
       "983           Robust Subspace Approximation in a Stream   \n",
       "984   Mean Field for the Stochastic Blockmodel: Opti...   \n",
       "985   Analysis of Krylov Subspace Solutions of  Regu...   \n",
       "986   Autoconj: Recognizing and Exploiting Conjugacy...   \n",
       "987   DropBlock: A regularization method for convolu...   \n",
       "988   Forward Modeling for Partial Observation Strat...   \n",
       "989     With Friends Like These, Who Needs Adversaries?   \n",
       "990   Decentralize and Randomize: Faster Algorithm f...   \n",
       "991   Joint Autoregressive and Hierarchical Priors f...   \n",
       "992   Learning Temporal Point Processes via Reinforc...   \n",
       "993   Bias and Generalization in Deep Generative Mod...   \n",
       "994         Fast and Effective Robustness Certification   \n",
       "995   Support Recovery for Orthogonal Matching Pursu...   \n",
       "996       Differentially Private Change-Point Detection   \n",
       "997   Multi-value Rule Sets for Interpretable Classi...   \n",
       "998   Domain Adaptation by Using Causal Inference to...   \n",
       "999   Smoothed Analysis of Discrete Tensor Decomposi...   \n",
       "1000  MixLasso: Generalized Mixed Regression via Con...   \n",
       "1001  Semidefinite relaxations for certifying robust...   \n",
       "1002  Removing Hidden Confounding by Experimental Gr...   \n",
       "1003  Topkapi: Parallel and Fast Sketches for Findin...   \n",
       "1004    Contrastive Learning from Pairwise Measurements   \n",
       "1005  Point process latent variable models of freely...   \n",
       "1006  Computationally and Statistically Efficient Le...   \n",
       "1007           Sparse PCA from Sparse Linear Regression   \n",
       "1008  Sequential Data Classification for Resource-co...   \n",
       "1009  Transfer of Deep Reactive Policies for MDP Pla...   \n",
       "1010         The Price of Fair PCA: One Extra dimension   \n",
       "1011  GroupReduce: Block-Wise Low-Rank Approximation...   \n",
       "\n",
       "                                                    bow  \n",
       "0     [effici, algorithm, non, convex, isoton, regre...  \n",
       "1     [structur, awar, convolut, neural, network, co...  \n",
       "2     [kalman, normal, indispens, compon, batch, nor...  \n",
       "3     [hogwild, gibb, panaccur, asynchron, gibb, sam...  \n",
       "4     [text, adapt, gener, adversari, network, manip...  \n",
       "5     [introva, introspect, variat, autoencod, photo...  \n",
       "6     [doubli, robust, bayesian, infer, non, station...  \n",
       "7     [adapt, deep, embed, synthesi, method, shot, i...  \n",
       "8     [gener, invers, optim, onlin, learn, invers, o...  \n",
       "9     [polici, polici, gradient, theorem, use, empha...  \n",
       "10    [supervis, autoencod, improv, gener, perform, ...  \n",
       "11    [visual, object, network, imag, gener, disenta...  \n",
       "12    [understand, weight, normal, deep, neural, net...  \n",
       "13    [learn, pipelin, limit, data, domain, knowledg...  \n",
       "14    [learn, long, rang, spatial, depend, horizont,...  \n",
       "15    [joint, sub, band, learn, cliqu, structur, wav...  \n",
       "16    [fast, similar, search, via, optim, spars, lif...  \n",
       "17    [learn, deep, disentangl, embed, statist, loss...  \n",
       "18    [geometr, coupl, mont, carlo, sampl, mont, car...  \n",
       "19    [cooper, holist, 3d, scene, understand, singl,...  \n",
       "20    [effici, prune, algorithm, robust, isoton, reg...  \n",
       "21    [pac, learn, presenc, adversari, exist, evas, ...  \n",
       "22    [spars, dnn, improv, adversari, robust, deep, ...  \n",
       "23    [snap, ml, hierarch, framework, machin, learn,...  \n",
       "24    [see, think, disentangl, semant, scene, comple...  \n",
       "25    [chain, reason, visual, question, answer, reas...  \n",
       "26    [sigsoftmax, reanalysi, softmax, bottleneck, s...  \n",
       "27    [deep, non, blind, deconvolut, via, gener, low...  \n",
       "28    [probabilist, pose, graph, optim, via, bingham...  \n",
       "29    [metaanchor, learn, detect, object, custom, an...  \n",
       "...                                                 ...  \n",
       "982   [thermostat, assist, continu, temper, hamilton...  \n",
       "983   [robust, subspac, approxim, stream, studi, rob...  \n",
       "984   [mean, field, stochast, blockmodel, optim, lan...  \n",
       "985   [analysi, krylov, subspac, solut, regular, non...  \n",
       "986   [autoconj, recogn, exploit, conjugaci, without...  \n",
       "987   [dropblock, regular, method, convolut, network...  \n",
       "988   [forward, model, partial, observ, strategi, ga...  \n",
       "989   [friend, like, need, adversari, vulner, deep, ...  \n",
       "990   [decentr, random, faster, algorithm, wasserste...  \n",
       "991   [joint, autoregress, hierarch, prior, learn, i...  \n",
       "992   [learn, tempor, point, process, via, reinforc,...  \n",
       "993   [bia, gener, deep, gener, model, empir, studi,...  \n",
       "994   [fast, effect, robust, certif, present, new, m...  \n",
       "995   [support, recoveri, orthogon, match, pursuit, ...  \n",
       "996   [differenti, privat, chang, point, detect, cha...  \n",
       "997   [multi, valu, rule, set, interpret, classif, f...  \n",
       "998   [domain, adapt, use, causal, infer, predict, i...  \n",
       "999   [smooth, analysi, discret, tensor, decomposit,...  \n",
       "1000  [mixlasso, gener, mix, regress, via, convex, a...  \n",
       "1001  [semidefinit, relax, certifi, robust, adversar...  \n",
       "1002  [remov, hidden, confound, experiment, ground, ...  \n",
       "1003  [topkapi, parallel, fast, sketch, find, top, f...  \n",
       "1004  [contrast, learn, pairwis, measur, learn, pair...  \n",
       "1005  [point, process, latent, variabl, model, freel...  \n",
       "1006  [comput, statist, effici, learn, bay, net, use...  \n",
       "1007  [spars, pca, spars, linear, regress, spars, pr...  \n",
       "1008  [sequenti, data, classif, resourc, constrain, ...  \n",
       "1009  [transfer, deep, reactiv, polici, mdp, plan, d...  \n",
       "1010  [price, fair, pca, one, extra, dimens, thi, pa...  \n",
       "1011  [groupreduc, block, wise, low, rank, approxim,...  \n",
       "\n",
       "[1012 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# papers metadata and decision downloaded from: https://docs.google.com/spreadsheets/d/1KHytYGNwTWuBpr7MhxEc9HL_Bd9hE48VA9SOFE6EsO0/edit#gid=0\n",
    "papers_csv = 'Arangements.csv'\n",
    "\n",
    "papers_df = pd.read_csv(papers_csv, usecols=['Paper ID', 'Paper Title', 'Abstract', 'Subject Areas', 'Decision', 'Author Emails'], encoding='utf-8')\n",
    "papers_df['Paper Title'] = papers_df['Paper Title'].apply(lambda x: x.strip())\n",
    "papers_df['Abstract'] = papers_df['Abstract'].apply(lambda x: x.strip())\n",
    "papers_df['Primary Subject Area'] = papers_df['Subject Areas'].apply(lambda x: x.split(';')[0][:-1])\n",
    "papers_df['Top-level Primary Subject Area'] = papers_df['Primary Subject Area'].apply(lambda x: x.split('/')[0])\n",
    "papers_df[['Paper Title', 'Abstract']]\n",
    "papers_df['bow'] = papers_df[['Paper Title', 'Abstract']].apply(lambda x: bow(x[0]) + bow(x[1]), axis=1)\n",
    "# papers_df['bow'] = papers_df[['Paper Title', 'Abstract']].apply(lambda x: bow(x[0]) + bow(x[1]), axis=1)\n",
    "\n",
    "papers_df[['Paper Title', 'bow']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Top-level Primary Subject Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Efficient Algorithms for Non-convex Isotonic R...</td>\n",
       "      <td>Optimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Structure-Aware Convolutional Neural Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kalman Normalization</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOGWILD!-Gibbs can be PanAccurate</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Text-Adaptive Generative Adversarial Networks:...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IntroVAE: Introspective Variational Autoencode...</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Doubly Robust Bayesian Inference for Non-Stati...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adapted Deep Embeddings: A Synthesis of Method...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Generalized Inverse Optimization through Onlin...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>An Off-policy Policy Gradient Theorem Using Em...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Supervised autoencoders: Improving generalizat...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Visual Object Networks: Image Generation with ...</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Understanding Weight Normalized Deep Neural Ne...</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Learning Pipelines with Limited Data and Domai...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Learning long-range spatial dependencies with ...</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Joint Sub-bands Learning with Clique Structure...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fast Similarity Search via Optimal Sparse Lifting</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Learning Deep Disentangled Embeddings With the...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Geometrically Coupled Monte Carlo Sampling</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cooperative Holistic 3D Scene Understanding fr...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>An Efficient Pruning Algorithm for Robust Isot...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PAC-learning in the presence of adversaries</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sparse DNNs with Improved Adversarial Robustness</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Snap ML: A Hierarchical Framework for Machine ...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>See and Think: Disentangling Semantic Scene Co...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chain of Reasoning for Visual Question Answering</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sigsoftmax: Reanalysis of the Softmax Bottleneck</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Deep Non-Blind Deconvolution via Generalized L...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Probabilistic Pose Graph Optimization via Bing...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MetaAnchor: Learning to Detect Objects with Cu...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Thermostat-assisted continuously-tempered Hami...</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>Robust Subspace Approximation in a Stream</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Mean Field for the Stochastic Blockmodel: Opti...</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Analysis of Krylov Subspace Solutions of  Regu...</td>\n",
       "      <td>Optimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Autoconj: Recognizing and Exploiting Conjugacy...</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>DropBlock: A regularization method for convolu...</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Forward Modeling for Partial Observation Strat...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>With Friends Like These, Who Needs Adversaries?</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Decentralize and Randomize: Faster Algorithm f...</td>\n",
       "      <td>Optimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Joint Autoregressive and Hierarchical Priors f...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Learning Temporal Point Processes via Reinforc...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Bias and Generalization in Deep Generative Mod...</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Fast and Effective Robustness Certification</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Support Recovery for Orthogonal Matching Pursu...</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Differentially Private Change-Point Detection</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Multi-value Rule Sets for Interpretable Classi...</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Domain Adaptation by Using Causal Inference to...</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Smoothed Analysis of Discrete Tensor Decomposi...</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>MixLasso: Generalized Mixed Regression via Con...</td>\n",
       "      <td>Optimizatio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>Semidefinite relaxations for certifying robust...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Removing Hidden Confounding by Experimental Gr...</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Topkapi: Parallel and Fast Sketches for Findin...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>Contrastive Learning from Pairwise Measurements</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>Point process latent variable models of freely...</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>Computationally and Statistically Efficient Le...</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>Sparse PCA from Sparse Linear Regression</td>\n",
       "      <td>Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>Sequential Data Classification for Resource-co...</td>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Transfer of Deep Reactive Policies for MDP Pla...</td>\n",
       "      <td>Reinforcement Learning and Plannin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>The Price of Fair PCA: One Extra dimension</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>GroupReduce: Block-Wise Low-Rank Approximation...</td>\n",
       "      <td>Applications</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Paper Title  \\\n",
       "0     Efficient Algorithms for Non-convex Isotonic R...   \n",
       "1         Structure-Aware Convolutional Neural Networks   \n",
       "2                                  Kalman Normalization   \n",
       "3                     HOGWILD!-Gibbs can be PanAccurate   \n",
       "4     Text-Adaptive Generative Adversarial Networks:...   \n",
       "5     IntroVAE: Introspective Variational Autoencode...   \n",
       "6     Doubly Robust Bayesian Inference for Non-Stati...   \n",
       "7     Adapted Deep Embeddings: A Synthesis of Method...   \n",
       "8     Generalized Inverse Optimization through Onlin...   \n",
       "9     An Off-policy Policy Gradient Theorem Using Em...   \n",
       "10    Supervised autoencoders: Improving generalizat...   \n",
       "11    Visual Object Networks: Image Generation with ...   \n",
       "12    Understanding Weight Normalized Deep Neural Ne...   \n",
       "13    Learning Pipelines with Limited Data and Domai...   \n",
       "14    Learning long-range spatial dependencies with ...   \n",
       "15    Joint Sub-bands Learning with Clique Structure...   \n",
       "16    Fast Similarity Search via Optimal Sparse Lifting   \n",
       "17    Learning Deep Disentangled Embeddings With the...   \n",
       "18           Geometrically Coupled Monte Carlo Sampling   \n",
       "19    Cooperative Holistic 3D Scene Understanding fr...   \n",
       "20    An Efficient Pruning Algorithm for Robust Isot...   \n",
       "21          PAC-learning in the presence of adversaries   \n",
       "22     Sparse DNNs with Improved Adversarial Robustness   \n",
       "23    Snap ML: A Hierarchical Framework for Machine ...   \n",
       "24    See and Think: Disentangling Semantic Scene Co...   \n",
       "25     Chain of Reasoning for Visual Question Answering   \n",
       "26     Sigsoftmax: Reanalysis of the Softmax Bottleneck   \n",
       "27    Deep Non-Blind Deconvolution via Generalized L...   \n",
       "28    Probabilistic Pose Graph Optimization via Bing...   \n",
       "29    MetaAnchor: Learning to Detect Objects with Cu...   \n",
       "...                                                 ...   \n",
       "982   Thermostat-assisted continuously-tempered Hami...   \n",
       "983           Robust Subspace Approximation in a Stream   \n",
       "984   Mean Field for the Stochastic Blockmodel: Opti...   \n",
       "985   Analysis of Krylov Subspace Solutions of  Regu...   \n",
       "986   Autoconj: Recognizing and Exploiting Conjugacy...   \n",
       "987   DropBlock: A regularization method for convolu...   \n",
       "988   Forward Modeling for Partial Observation Strat...   \n",
       "989     With Friends Like These, Who Needs Adversaries?   \n",
       "990   Decentralize and Randomize: Faster Algorithm f...   \n",
       "991   Joint Autoregressive and Hierarchical Priors f...   \n",
       "992   Learning Temporal Point Processes via Reinforc...   \n",
       "993   Bias and Generalization in Deep Generative Mod...   \n",
       "994         Fast and Effective Robustness Certification   \n",
       "995   Support Recovery for Orthogonal Matching Pursu...   \n",
       "996       Differentially Private Change-Point Detection   \n",
       "997   Multi-value Rule Sets for Interpretable Classi...   \n",
       "998   Domain Adaptation by Using Causal Inference to...   \n",
       "999   Smoothed Analysis of Discrete Tensor Decomposi...   \n",
       "1000  MixLasso: Generalized Mixed Regression via Con...   \n",
       "1001  Semidefinite relaxations for certifying robust...   \n",
       "1002  Removing Hidden Confounding by Experimental Gr...   \n",
       "1003  Topkapi: Parallel and Fast Sketches for Findin...   \n",
       "1004    Contrastive Learning from Pairwise Measurements   \n",
       "1005  Point process latent variable models of freely...   \n",
       "1006  Computationally and Statistically Efficient Le...   \n",
       "1007           Sparse PCA from Sparse Linear Regression   \n",
       "1008  Sequential Data Classification for Resource-co...   \n",
       "1009  Transfer of Deep Reactive Policies for MDP Pla...   \n",
       "1010         The Price of Fair PCA: One Extra dimension   \n",
       "1011  GroupReduce: Block-Wise Low-Rank Approximation...   \n",
       "\n",
       "           Top-level Primary Subject Area  \n",
       "0                            Optimization  \n",
       "1                           Deep Learning  \n",
       "2                           Deep Learning  \n",
       "3                   Probabilistic Methods  \n",
       "4                            Applications  \n",
       "5                           Deep Learning  \n",
       "6                            Applications  \n",
       "7                              Algorithms  \n",
       "8                              Algorithms  \n",
       "9     Reinforcement Learning and Planning  \n",
       "10                             Algorithms  \n",
       "11                          Deep Learning  \n",
       "12                                 Theory  \n",
       "13                           Applications  \n",
       "14                          Deep Learning  \n",
       "15                           Applications  \n",
       "16                             Algorithms  \n",
       "17                             Algorithms  \n",
       "18                             Algorithms  \n",
       "19                           Applications  \n",
       "20                             Algorithms  \n",
       "21                                 Theory  \n",
       "22                          Deep Learning  \n",
       "23                           Applications  \n",
       "24                           Applications  \n",
       "25                           Applications  \n",
       "26                          Deep Learning  \n",
       "27                           Applications  \n",
       "28                           Applications  \n",
       "29                           Applications  \n",
       "...                                   ...  \n",
       "982                 Probabilistic Methods  \n",
       "983                            Algorithms  \n",
       "984                 Probabilistic Methods  \n",
       "985                          Optimization  \n",
       "986                 Probabilistic Methods  \n",
       "987                                Theory  \n",
       "988                          Applications  \n",
       "989                         Deep Learning  \n",
       "990                          Optimization  \n",
       "991                            Algorithms  \n",
       "992                          Applications  \n",
       "993                         Deep Learning  \n",
       "994                         Deep Learning  \n",
       "995                            Algorithms  \n",
       "996                          Applications  \n",
       "997                 Probabilistic Methods  \n",
       "998                 Probabilistic Methods  \n",
       "999                                Theory  \n",
       "1000                          Optimizatio  \n",
       "1001                         Applications  \n",
       "1002                Probabilistic Methods  \n",
       "1003                         Applications  \n",
       "1004                           Algorithms  \n",
       "1005                Probabilistic Methods  \n",
       "1006                               Theory  \n",
       "1007                           Algorithms  \n",
       "1008                        Deep Learning  \n",
       "1009   Reinforcement Learning and Plannin  \n",
       "1010                         Applications  \n",
       "1011                         Applications  \n",
       "\n",
       "[1012 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df[['Paper Title', 'Top-level Primary Subject Area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14535185), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1008), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TPMS scores downloaded from: https://cmt.research.microsoft.com/NIPS2017/Protected/Chair/ManageMetaReviewAssignmentsExport.aspx?data=externalmatching&view=cs&format=xml&serviceid=1)\n",
    "# tpms_df, rid2idx = paper2tmpsvec('../../data/assignment/rev_tpms.xml', set(papers_df['Paper ID']))\n",
    "\n",
    "tpms_df, rid2idx = paper2tmp('ReviewerTpmsScores_NIPS2018.csv', set(papers_df['Paper ID']))\n",
    "# paper2tmp('ReviewerTpmsScores_NIPS2018.csv')\n",
    "\n",
    "# print tpms_df\n",
    "# print rid2idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=papers_df, right=tpms_df, how='left', left_on='Paper ID', right_on='pid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project papers into one-dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jeshu\\pycharmprojects\\scheduler\\venv1\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in divide\n",
      "  \n",
      "c:\\users\\jeshu\\pycharmprojects\\scheduler\\venv1\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "TPMS = cosinesim(np.asarray(df.tpms.tolist()))\n",
    "TPSA = pairwise_equal(df['Top-level Primary Subject Area'])\n",
    "PSA = pairwise_equal(df['Primary Subject Area'])\n",
    "BOW = CountVectorizer('content', tokenizer=lambda x: x, lowercase=False, binary=True).fit_transform(df.bow).todense()\n",
    "BOW = np.asarray(BOW, dtype=float)\n",
    "BOW = cosinesim(BOW, znorm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dissim = np.clip(3. - TPSA - PSA - TPMS, a_min=0., a_max=3.)\n",
    "sims_all = [TPMS, TPSA, PSA, BOW]\n",
    "dissim_all = (float(len(sims_all)) - sum(sims_all)) / len(sims_all)\n",
    "dissim_all = np.clip(dissim_all, a_min=0., a_max=float(len(sims_all)))\n",
    "dissim_tpms = np.clip(1. - TPMS, a_min=0., a_max=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_all = TSNE(n_components=1, metric='precomputed').fit_transform(dissim_all)\n",
    "tsne_tpms = TSNE(n_components=1, metric='precomputed').fit_transform(dissim_tpms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tsne_all'] = tsne_all\n",
    "df['tsne_tpms'] = tsne_tpms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('pre_arrangement_final.csv', encoding='utf-8', index=False, columns=['Paper ID', 'Paper Title', 'Abstract', 'Subject Areas', \n",
    "#                                                                    'Primary Subject Area', 'Top-level Primary Subject Area',\n",
    "#                                                                    'tsne_all', 'tsne_tpms', 'Decision'])\n",
    "\n",
    "# df = pd.read_csv('pre_arrangement.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper ID</th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Emails</th>\n",
       "      <th>Subject Areas</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Primary Subject Area</th>\n",
       "      <th>Top-level Primary Subject Area</th>\n",
       "      <th>bow</th>\n",
       "      <th>pid</th>\n",
       "      <th>tpms</th>\n",
       "      <th>tsne_all</th>\n",
       "      <th>tsne_tpms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Efficient Algorithms for Non-convex Isotonic R...</td>\n",
       "      <td>We consider the minimization of submodular fun...</td>\n",
       "      <td>francis.bach@inria.fr</td>\n",
       "      <td>Optimization/Submodular Optimization*; Optimiz...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Optimization/Submodular Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[effici, algorithm, non, convex, isoton, regre...</td>\n",
       "      <td>29</td>\n",
       "      <td>[0.724210006, 0.547847061, 0.62121431, 0.69992...</td>\n",
       "      <td>-65.037216</td>\n",
       "      <td>43.380173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Structure-Aware Convolutional Neural Networks</td>\n",
       "      <td>Convolutional neural networks (CNNs) are inher...</td>\n",
       "      <td>jianlong.chang@nlpr.ia.ac.cn;jie.gu@nlpr.ia.ac...</td>\n",
       "      <td>Deep Learning*; Deep Learning/CNN Architecture...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[structur, awar, convolut, neural, network, co...</td>\n",
       "      <td>33</td>\n",
       "      <td>[0.722796601, 0.7524726279999999, 0.681080612,...</td>\n",
       "      <td>-27.842775</td>\n",
       "      <td>-41.931042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>Kalman Normalization</td>\n",
       "      <td>As an indispensable component, Batch Normaliza...</td>\n",
       "      <td>wanggrun@mail2.sysu.edu.cn;jiefengpeng@gmail.c...</td>\n",
       "      <td>Deep Learning/CNN Architectures*; Applications...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/CNN Architectures</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[kalman, normal, indispens, compon, batch, nor...</td>\n",
       "      <td>34</td>\n",
       "      <td>[0.605652029, 0.624528822, 0.5549479039999999,...</td>\n",
       "      <td>-45.000961</td>\n",
       "      <td>-22.988417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>HOGWILD!-Gibbs can be PanAccurate</td>\n",
       "      <td>Asynchronous Gibbs sampling has been recently ...</td>\n",
       "      <td>costis@csail.mit.edu;ndikkala@mit.edu;jayanti@...</td>\n",
       "      <td>Probabilistic Methods/Distributed Inference*; ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Distributed Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[hogwild, gibb, panaccur, asynchron, gibb, sam...</td>\n",
       "      <td>37</td>\n",
       "      <td>[0.6039084920000001, 0.571028136, 0.547187392,...</td>\n",
       "      <td>-86.396667</td>\n",
       "      <td>24.022959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>Text-Adaptive Generative Adversarial Networks:...</td>\n",
       "      <td>This paper addresses the problem of manipulati...</td>\n",
       "      <td>shnnam@yonsei.ac.kr;kim_yunji@yonsei.ac.kr;seo...</td>\n",
       "      <td>Applications/Computational Photography*; Appli...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Applications/Computational Photography</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[text, adapt, gener, adversari, network, manip...</td>\n",
       "      <td>40</td>\n",
       "      <td>[0.6074082789999999, 0.604121554, 0.5843663610...</td>\n",
       "      <td>10.959604</td>\n",
       "      <td>-44.323528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59</td>\n",
       "      <td>IntroVAE: Introspective Variational Autoencode...</td>\n",
       "      <td>We present a novel introspective variational a...</td>\n",
       "      <td>huaibo.huang@cripac.ia.ac.cn;zhihang.li@nlpr.i...</td>\n",
       "      <td>Deep Learning/Generative Models*; Deep Learnin...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Generative Models</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[introva, introspect, variat, autoencod, photo...</td>\n",
       "      <td>59</td>\n",
       "      <td>[0.554898813, 0.566786583, 0.514959909, 0.5606...</td>\n",
       "      <td>-52.689449</td>\n",
       "      <td>-14.038417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>Doubly Robust Bayesian Inference for Non-Stati...</td>\n",
       "      <td>We present the very first robust Bayesian Onli...</td>\n",
       "      <td>j.knoblauch@warwick.ac.uk;j.e.jewson@warwick.a...</td>\n",
       "      <td>Applications/Time Series Analysis*; Algorithms...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Time Series Analysis</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[doubli, robust, bayesian, infer, non, station...</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.811906661, 0.7286812490000001, 0.745909935,...</td>\n",
       "      <td>21.148312</td>\n",
       "      <td>-1.963071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>Adapted Deep Embeddings: A Synthesis of Method...</td>\n",
       "      <td>The focus in machine learning has branched bey...</td>\n",
       "      <td>tysc7237@colorado.edu;karl.ridgeway@colorado.e...</td>\n",
       "      <td>Algorithms/Multitask and Transfer Learning*; A...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Multitask and Transfer Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[adapt, deep, embed, synthesi, method, shot, i...</td>\n",
       "      <td>75</td>\n",
       "      <td>[0.7246898359999999, 0.74860931, 0.72164041200...</td>\n",
       "      <td>57.467770</td>\n",
       "      <td>-28.714304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>Generalized Inverse Optimization through Onlin...</td>\n",
       "      <td>Inverse optimization is a powerful paradigm fo...</td>\n",
       "      <td>chaosheng@pitt.edu;yiran.chen@duke.edu;bzeng@p...</td>\n",
       "      <td>Algorithms/Online Learning*; Applications/Quan...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Online Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[gener, invers, optim, onlin, learn, invers, o...</td>\n",
       "      <td>77</td>\n",
       "      <td>[0.8553071390000001, 0.729569048, 0.771284843,...</td>\n",
       "      <td>62.712032</td>\n",
       "      <td>38.852795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>85</td>\n",
       "      <td>An Off-policy Policy Gradient Theorem Using Em...</td>\n",
       "      <td>Policy gradient methods are widely used for co...</td>\n",
       "      <td>imani@ualberta.ca;graves@ualberta.ca;whitem@ua...</td>\n",
       "      <td>Reinforcement Learning and Planning/Reinforcem...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Reinforcement Learning and Planning/Reinforcem...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>[polici, polici, gradient, theorem, use, empha...</td>\n",
       "      <td>85</td>\n",
       "      <td>[0.5770863589999999, 0.523376441, 0.518179388,...</td>\n",
       "      <td>85.118027</td>\n",
       "      <td>6.052812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>88</td>\n",
       "      <td>Supervised autoencoders: Improving generalizat...</td>\n",
       "      <td>Generalization performance is a central goal i...</td>\n",
       "      <td>leile@iu.edu;andnpatt@iu.edu;whitem@ualberta.ca</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learnin</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[supervis, autoencod, improv, gener, perform, ...</td>\n",
       "      <td>88</td>\n",
       "      <td>[0.7831208590000001, 0.8086628229999999, 0.745...</td>\n",
       "      <td>52.941345</td>\n",
       "      <td>-26.562601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>92</td>\n",
       "      <td>Visual Object Networks: Image Generation with ...</td>\n",
       "      <td>Recent progress in deep generative models has ...</td>\n",
       "      <td>junyanz@mit.edu;ztzhang@mit.edu;ckzhang@mit.ed...</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[visual, object, network, imag, gener, disenta...</td>\n",
       "      <td>92</td>\n",
       "      <td>[0.622592223, 0.620137725, 0.574635252, 0.6193...</td>\n",
       "      <td>-48.542374</td>\n",
       "      <td>-46.703506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>95</td>\n",
       "      <td>Understanding Weight Normalized Deep Neural Ne...</td>\n",
       "      <td>This paper presents a general framework for no...</td>\n",
       "      <td>xu573@purdue.edu;wangxiao@purdue.edu</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theor</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[understand, weight, normal, deep, neural, net...</td>\n",
       "      <td>95</td>\n",
       "      <td>[0.644970711, 0.6021990779999999, 0.611452154,...</td>\n",
       "      <td>-4.153590</td>\n",
       "      <td>13.390891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>99</td>\n",
       "      <td>Learning Pipelines with Limited Data and Domai...</td>\n",
       "      <td>As machine learning becomes more widely used i...</td>\n",
       "      <td>mrinmayaster@gmail.com;avinava.dubey@gmail.com...</td>\n",
       "      <td>Applications*; Applications/Computer Vision</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[learn, pipelin, limit, data, domain, knowledg...</td>\n",
       "      <td>99</td>\n",
       "      <td>[0.825202962, 0.8357769540000001, 0.8245410609...</td>\n",
       "      <td>17.879139</td>\n",
       "      <td>-35.804531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>102</td>\n",
       "      <td>Learning long-range spatial dependencies with ...</td>\n",
       "      <td>Progress in deep learning has spawned great su...</td>\n",
       "      <td>drew_linsley@brown.edu;junkyung_kim@brown.edu;...</td>\n",
       "      <td>Deep Learning/Biologically Plausible Deep Netw...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Biologically Plausible Deep Netw...</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[learn, long, rang, spatial, depend, horizont,...</td>\n",
       "      <td>102</td>\n",
       "      <td>[0.753889782, 0.8060686090000001, 0.7139329390...</td>\n",
       "      <td>-37.060337</td>\n",
       "      <td>-39.884235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>110</td>\n",
       "      <td>Joint Sub-bands Learning with Clique Structure...</td>\n",
       "      <td>Convolutional neural networks (CNNs) have rece...</td>\n",
       "      <td>zszhong@pku.edu.cn;tianchengshen@pku.edu.cn;ib...</td>\n",
       "      <td>Applications/Computer Vision*; Deep Learning/C...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[joint, sub, band, learn, cliqu, structur, wav...</td>\n",
       "      <td>110</td>\n",
       "      <td>[0.665462302, 0.631348907, 0.61443569, 0.65938...</td>\n",
       "      <td>5.871789</td>\n",
       "      <td>-42.454613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>142</td>\n",
       "      <td>Fast Similarity Search via Optimal Sparse Lifting</td>\n",
       "      <td>Similarity search is a fundamental problem in ...</td>\n",
       "      <td>wyli@cuhk.edu.cn;216019005@link.cuhk.edu.cn;yi...</td>\n",
       "      <td>Algorithms/Sparse Coding and Dimensionality Ex...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Sparse Coding and Dimensionality Ex...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[fast, similar, search, via, optim, spars, lif...</td>\n",
       "      <td>142</td>\n",
       "      <td>[0.8577442009999999, 0.7920245159999999, 0.809...</td>\n",
       "      <td>51.363522</td>\n",
       "      <td>-17.461079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>145</td>\n",
       "      <td>Learning Deep Disentangled Embeddings With the...</td>\n",
       "      <td>Deep-embedding methods aim to discover represe...</td>\n",
       "      <td>karl.ridgeway@colorado.edu;mozer@colorado.edu</td>\n",
       "      <td>Algorithms/Representation Learning*; Algorithm...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[learn, deep, disentangl, embed, statist, loss...</td>\n",
       "      <td>145</td>\n",
       "      <td>[0.801685634, 0.791540459, 0.772199449, 0.8187...</td>\n",
       "      <td>54.186298</td>\n",
       "      <td>-28.578308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>153</td>\n",
       "      <td>Geometrically Coupled Monte Carlo Sampling</td>\n",
       "      <td>Monte Carlo sampling in high-dimensional, low-...</td>\n",
       "      <td>mr504@cam.ac.uk;kchoro@google.com;chalusf3@gma...</td>\n",
       "      <td>Algorithms/Stochastic Methods*; Reinforcement ...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Stochastic Methods</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[geometr, coupl, mont, carlo, sampl, mont, car...</td>\n",
       "      <td>153</td>\n",
       "      <td>[0.796080575, 0.669703717, 0.714382987, 0.7818...</td>\n",
       "      <td>43.549530</td>\n",
       "      <td>24.121429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>175</td>\n",
       "      <td>Cooperative Holistic 3D Scene Understanding fr...</td>\n",
       "      <td>Holistic 3D indoor scene understanding involve...</td>\n",
       "      <td>huangsiyuan@ucla.edu;syqi@cs.ucla.edu;yinxuex@...</td>\n",
       "      <td>Applications/Visual Scene Analysis and Interpr...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Visual Scene Analysis and Interpr...</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[cooper, holist, 3d, scene, understand, singl,...</td>\n",
       "      <td>175</td>\n",
       "      <td>[0.635211113, 0.587038424, 0.582188994, 0.6233...</td>\n",
       "      <td>9.757609</td>\n",
       "      <td>-47.380989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>177</td>\n",
       "      <td>An Efficient Pruning Algorithm for Robust Isot...</td>\n",
       "      <td>We study a generalization of the classic isoto...</td>\n",
       "      <td>clim9@wisc.edu</td>\n",
       "      <td>Algorithms/Regression</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Regressio</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[effici, prune, algorithm, robust, isoton, reg...</td>\n",
       "      <td>177</td>\n",
       "      <td>[0.8350809440000001, 0.641266087, 0.761110935,...</td>\n",
       "      <td>40.470722</td>\n",
       "      <td>43.279369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>178</td>\n",
       "      <td>PAC-learning in the presence of adversaries</td>\n",
       "      <td>The existence of evasion attacks during the te...</td>\n",
       "      <td>dcullina@princeton.edu;abhagoji@princeton.edu;...</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theor</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[pac, learn, presenc, adversari, exist, evas, ...</td>\n",
       "      <td>178</td>\n",
       "      <td>[0.5843463000000001, 0.563068797, 0.533589984,...</td>\n",
       "      <td>-4.154649</td>\n",
       "      <td>-19.239223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>182</td>\n",
       "      <td>Sparse DNNs with Improved Adversarial Robustness</td>\n",
       "      <td>Deep neural networks (DNNs) are computationall...</td>\n",
       "      <td>yiwen.guo@intel.com;pkuzc@pku.edu.cn;zcs@mail....</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Algorithm...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[spars, dnn, improv, adversari, robust, deep, ...</td>\n",
       "      <td>182</td>\n",
       "      <td>[0.666966905, 0.637015755, 0.638722607, 0.7032...</td>\n",
       "      <td>-48.874542</td>\n",
       "      <td>-19.332710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>185</td>\n",
       "      <td>Snap ML: A Hierarchical Framework for Machine ...</td>\n",
       "      <td>We describe a new software framework for fast ...</td>\n",
       "      <td>cdu@zurich.ibm.com;tpa@zurich.ibm.com;rig@zuri...</td>\n",
       "      <td>Applications/Hardware and Systems*; Data, Comp...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Hardware and Systems</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[snap, ml, hierarch, framework, machin, learn,...</td>\n",
       "      <td>185</td>\n",
       "      <td>[0.657971973, 0.853205806, 0.618791222, 0.6497...</td>\n",
       "      <td>19.205162</td>\n",
       "      <td>-23.840919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>186</td>\n",
       "      <td>See and Think: Disentangling Semantic Scene Co...</td>\n",
       "      <td>Semantic scene completion predicts volumetric ...</td>\n",
       "      <td>liushice@ict.ac.cn;huyu@ict.ac.cn;zengyiming@i...</td>\n",
       "      <td>Applications/Computer Vision*; Deep Learning/C...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[see, think, disentangl, semant, scene, comple...</td>\n",
       "      <td>186</td>\n",
       "      <td>[0.657856715, 0.632397676, 0.6396587229999999,...</td>\n",
       "      <td>6.809194</td>\n",
       "      <td>-47.239983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>187</td>\n",
       "      <td>Chain of Reasoning for Visual Question Answering</td>\n",
       "      <td>Reasoning plays an essential role in Visual Qu...</td>\n",
       "      <td>wuchenfei@bupt.edu.cn;liujinlai@bupt.edu.cn;xj...</td>\n",
       "      <td>Applications/Visual Question Answering*; Neuro...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Visual Question Answering</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[chain, reason, visual, question, answer, reas...</td>\n",
       "      <td>187</td>\n",
       "      <td>[0.632062365, 0.6729400529999999, 0.603445259,...</td>\n",
       "      <td>12.654006</td>\n",
       "      <td>-36.788307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>188</td>\n",
       "      <td>Sigsoftmax: Reanalysis of the Softmax Bottleneck</td>\n",
       "      <td>Softmax is an output activation function for m...</td>\n",
       "      <td>kanai.sekitoshi@lab.ntt.co.jp;fujiwara.yasuhir...</td>\n",
       "      <td>Deep Learning*; Deep Learning/Recurrent Networ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[sigsoftmax, reanalysi, softmax, bottleneck, s...</td>\n",
       "      <td>188</td>\n",
       "      <td>[0.692489644, 0.790134204, 0.660755629, 0.7194...</td>\n",
       "      <td>-27.241320</td>\n",
       "      <td>-24.413645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>191</td>\n",
       "      <td>Deep Non-Blind Deconvolution via Generalized L...</td>\n",
       "      <td>In this paper, we present a deep convolutional...</td>\n",
       "      <td>rwq.renwenqi@gmail.com;zhjw1988@gmail.com;fore...</td>\n",
       "      <td>Applications/Computer Vision*; Applications/De...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[deep, non, blind, deconvolut, via, gener, low...</td>\n",
       "      <td>191</td>\n",
       "      <td>[0.562258779, 0.5202836, 0.506214686, 0.550357...</td>\n",
       "      <td>5.565048</td>\n",
       "      <td>-42.852203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>192</td>\n",
       "      <td>Probabilistic Pose Graph Optimization via Bing...</td>\n",
       "      <td>We introduce Tempered Geodesic MCMC (TG-MCMC) ...</td>\n",
       "      <td>tolga.birdal@tum.de;umut.simsekli@telecom-pari...</td>\n",
       "      <td>Applications/Computer Vision*; Applications/Ro...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[probabilist, pose, graph, optim, via, bingham...</td>\n",
       "      <td>192</td>\n",
       "      <td>[0.9113688670000001, 0.7563436379999999, 0.820...</td>\n",
       "      <td>4.842010</td>\n",
       "      <td>29.373499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>207</td>\n",
       "      <td>MetaAnchor: Learning to Detect Objects with Cu...</td>\n",
       "      <td>We propose a novel and flexible anchor mechani...</td>\n",
       "      <td>yangt15@fudan.edu.cn;zhangxiangyu@megvii.com;l...</td>\n",
       "      <td>Applications/Object Detection</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Object Detectio</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[metaanchor, learn, detect, object, custom, an...</td>\n",
       "      <td>207</td>\n",
       "      <td>[0.620705712, 0.593533387, 0.572714624, 0.6164...</td>\n",
       "      <td>9.184333</td>\n",
       "      <td>-45.363842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>6787</td>\n",
       "      <td>Thermostat-assisted continuously-tempered Hami...</td>\n",
       "      <td>In this paper, we propose a novel sampling met...</td>\n",
       "      <td>r.luo@cs.ucl.ac.uk;jianhong.wang.17@ucl.ac.uk;...</td>\n",
       "      <td>Probabilistic Methods/MCMC</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/MCM</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[thermostat, assist, continu, temper, hamilton...</td>\n",
       "      <td>6787</td>\n",
       "      <td>[0.646289553, 0.620857109, 0.586481252, 0.6541...</td>\n",
       "      <td>-83.440186</td>\n",
       "      <td>-3.773678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>6793</td>\n",
       "      <td>Robust Subspace Approximation in a Stream</td>\n",
       "      <td>We study robust subspace estimation in the str...</td>\n",
       "      <td>roiel@cs.cmu.edu;asevekar@andrew.cmu.edu;dwood...</td>\n",
       "      <td>Algorithms*; Algorithms/Regression</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[robust, subspac, approxim, stream, studi, rob...</td>\n",
       "      <td>6793</td>\n",
       "      <td>[0.540987701, 0.441798132, 0.49352610399999997...</td>\n",
       "      <td>36.628849</td>\n",
       "      <td>33.431755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>6802</td>\n",
       "      <td>Mean Field for the Stochastic Blockmodel: Opti...</td>\n",
       "      <td>Variational approximation has been widely used...</td>\n",
       "      <td>soumendu041@gmail.com;purna.sarkar@austin.utex...</td>\n",
       "      <td>Probabilistic Methods/Variational Inference*; ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Variational Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[mean, field, stochast, blockmodel, optim, lan...</td>\n",
       "      <td>6802</td>\n",
       "      <td>[0.735002521, 0.627056098, 0.647996389, 0.7320...</td>\n",
       "      <td>-85.291252</td>\n",
       "      <td>23.962334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>6832</td>\n",
       "      <td>Analysis of Krylov Subspace Solutions of  Regu...</td>\n",
       "      <td>We provide convergence rates for Krylov subspa...</td>\n",
       "      <td>ycarmon@gmail.com;jduchi@stanford.edu</td>\n",
       "      <td>Optimization/Non-Convex Optimization*; Algorit...</td>\n",
       "      <td>Oral</td>\n",
       "      <td>Optimization/Non-Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[analysi, krylov, subspac, solut, regular, non...</td>\n",
       "      <td>6832</td>\n",
       "      <td>[0.644204279, 0.46829059700000003, 0.536020003...</td>\n",
       "      <td>-60.415810</td>\n",
       "      <td>45.334076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>6836</td>\n",
       "      <td>Autoconj: Recognizing and Exploiting Conjugacy...</td>\n",
       "      <td>Deriving conditional and marginal distribution...</td>\n",
       "      <td>mdhoffma@cs.princeton.edu;mattjj@google.com;tr...</td>\n",
       "      <td>Probabilistic Methods/Graphical Models*; Data,...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Graphical Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[autoconj, recogn, exploit, conjugaci, without...</td>\n",
       "      <td>6836</td>\n",
       "      <td>[0.644937403, 0.646330124, 0.606580474, 0.6317...</td>\n",
       "      <td>-88.951286</td>\n",
       "      <td>-2.032948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>6839</td>\n",
       "      <td>DropBlock: A regularization method for convolu...</td>\n",
       "      <td>Deep neural networks often work well when they...</td>\n",
       "      <td>golnazg@google.com;tsungyi@google.com;qvl@goog...</td>\n",
       "      <td>Theory/Regularization*; Deep Learning/CNN Arch...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Regularization</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[dropblock, regular, method, convolut, network...</td>\n",
       "      <td>6839</td>\n",
       "      <td>[0.602325926, 0.709435875, 0.611376699, 0.6140...</td>\n",
       "      <td>-13.005722</td>\n",
       "      <td>-40.898853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>6843</td>\n",
       "      <td>Forward Modeling for Partial Observation Strat...</td>\n",
       "      <td>We formulate the problem of \\emph{defogging} a...</td>\n",
       "      <td>gab@fb.com;zlin@fb.com;jgehring@fb.com;dangant...</td>\n",
       "      <td>Applications/Game Playing</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Game Playin</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[forward, model, partial, observ, strategi, ga...</td>\n",
       "      <td>6843</td>\n",
       "      <td>[0.64940197, 0.696797065, 0.612499372, 0.66309...</td>\n",
       "      <td>13.244852</td>\n",
       "      <td>-31.995758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>6847</td>\n",
       "      <td>With Friends Like These, Who Needs Adversaries?</td>\n",
       "      <td>The vulnerability of deep networks to adversar...</td>\n",
       "      <td>sjetley@robots.ox.ac.uk;nicklord@robots.ox.ac....</td>\n",
       "      <td>Deep Learning*; Algorithms/Classification; Alg...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[friend, like, need, adversari, vulner, deep, ...</td>\n",
       "      <td>6847</td>\n",
       "      <td>[0.596239485, 0.552854089, 0.56523045, 0.61261...</td>\n",
       "      <td>-28.122467</td>\n",
       "      <td>-20.176826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>6859</td>\n",
       "      <td>Decentralize and Randomize: Faster Algorithm f...</td>\n",
       "      <td>We study the problem of decentralized distribu...</td>\n",
       "      <td>pavel.dvurechensky@gmail.com;darina.dvinskikh@...</td>\n",
       "      <td>Optimization/Convex Optimization*; Algorithms/...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization/Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[decentr, random, faster, algorithm, wasserste...</td>\n",
       "      <td>6859</td>\n",
       "      <td>[0.649590907, 0.572511066, 0.579816594, 0.6330...</td>\n",
       "      <td>-67.124580</td>\n",
       "      <td>29.979273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>6863</td>\n",
       "      <td>Joint Autoregressive and Hierarchical Priors f...</td>\n",
       "      <td>Recent models for learned image compression ar...</td>\n",
       "      <td>dminnen@google.com;jballe@google.com;gtoderici...</td>\n",
       "      <td>Algorithms/Representation Learning*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[joint, autoregress, hierarch, prior, learn, i...</td>\n",
       "      <td>6863</td>\n",
       "      <td>[0.5645583710000001, 0.599846334, 0.522823875,...</td>\n",
       "      <td>54.194683</td>\n",
       "      <td>-14.596280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>6874</td>\n",
       "      <td>Learning Temporal Point Processes via Reinforc...</td>\n",
       "      <td>Many real world problems from sustainability, ...</td>\n",
       "      <td>sli370@gatech.edu;benjaminforever@sjtu.edu.cn;...</td>\n",
       "      <td>Applications/Time Series Analysis</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Applications/Time Series Analysi</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[learn, tempor, point, process, via, reinforc,...</td>\n",
       "      <td>6874</td>\n",
       "      <td>[0.6848055690000001, 0.606161123, 0.618028853,...</td>\n",
       "      <td>22.287842</td>\n",
       "      <td>6.262251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>6882</td>\n",
       "      <td>Bias and Generalization in Deep Generative Mod...</td>\n",
       "      <td>In high dimensional settings, density estimati...</td>\n",
       "      <td>sjzhao@stanford.edu;hyren@cs.stanford.edu;xfyu...</td>\n",
       "      <td>Deep Learning/Generative Models*; Deep Learnin...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning/Generative Models</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[bia, gener, deep, gener, model, empir, studi,...</td>\n",
       "      <td>6882</td>\n",
       "      <td>[0.825245676, 0.77820804, 0.764052464, 0.83451...</td>\n",
       "      <td>-52.453613</td>\n",
       "      <td>-39.021587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>6892</td>\n",
       "      <td>Fast and Effective Robustness Certification</td>\n",
       "      <td>We present a new method and system for certify...</td>\n",
       "      <td>gsingh@inf.ethz.ch;timon.gehr@inf.ethz.ch;matt...</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[fast, effect, robust, certif, present, new, m...</td>\n",
       "      <td>6892</td>\n",
       "      <td>[0.656920721, 0.7048807429999999, 0.624150393,...</td>\n",
       "      <td>-48.894798</td>\n",
       "      <td>-19.396210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>6901</td>\n",
       "      <td>Support Recovery for Orthogonal Matching Pursu...</td>\n",
       "      <td>This paper studies the problem of sparse regre...</td>\n",
       "      <td>raghavsomani1995@gmail.com;chiragpvg@gmail.com...</td>\n",
       "      <td>Algorithms/Sparsity and Compressed Sensing*; A...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Sparsity and Compressed Sensing</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[support, recoveri, orthogon, match, pursuit, ...</td>\n",
       "      <td>6901</td>\n",
       "      <td>[0.6322439089999999, 0.5179587760000001, 0.563...</td>\n",
       "      <td>41.317558</td>\n",
       "      <td>32.567497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>6905</td>\n",
       "      <td>Differentially Private Change-Point Detection</td>\n",
       "      <td>The change-point detection problem seeks to id...</td>\n",
       "      <td>krehbiel@richmond.edu;rachelc@gatech.edu;wanro...</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security*...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[differenti, privat, chang, point, detect, cha...</td>\n",
       "      <td>6905</td>\n",
       "      <td>[0.6977355690000001, 0.557927934, 0.63827413, ...</td>\n",
       "      <td>31.028465</td>\n",
       "      <td>36.121666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>6913</td>\n",
       "      <td>Multi-value Rule Sets for Interpretable Classi...</td>\n",
       "      <td>We present Multi-value Rule Sets (MRS) for int...</td>\n",
       "      <td>tong-wang@uiowa.edu</td>\n",
       "      <td>Probabilistic Methods/Hierarchical Models*; Ap...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Hierarchical Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[multi, valu, rule, set, interpret, classif, f...</td>\n",
       "      <td>6913</td>\n",
       "      <td>[0.823699588, 0.7256162290000001, 0.770973646,...</td>\n",
       "      <td>-87.882576</td>\n",
       "      <td>17.551443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6921</td>\n",
       "      <td>Domain Adaptation by Using Causal Inference to...</td>\n",
       "      <td>An important goal common to domain adaptation ...</td>\n",
       "      <td>sara.magliacane@gmail.com;thijsvanommen@gmail....</td>\n",
       "      <td>Probabilistic Methods/Causal Inference*; Deep ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Causal Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[domain, adapt, use, causal, infer, predict, i...</td>\n",
       "      <td>6921</td>\n",
       "      <td>[0.534160482, 0.482813768, 0.514349219, 0.5274...</td>\n",
       "      <td>-92.187416</td>\n",
       "      <td>15.178188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>6923</td>\n",
       "      <td>Smoothed Analysis of Discrete Tensor Decomposi...</td>\n",
       "      <td>We analyze linear independence of rank one ten...</td>\n",
       "      <td>anari.nima@gmail.com;costis@csail.mit.edu;maas...</td>\n",
       "      <td>Theory*; Algorithms/Components Analysis (e.g.,...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[smooth, analysi, discret, tensor, decomposit,...</td>\n",
       "      <td>6923</td>\n",
       "      <td>[0.693092713, 0.629186489, 0.656472765, 0.7012...</td>\n",
       "      <td>-10.954827</td>\n",
       "      <td>21.518019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>6961</td>\n",
       "      <td>MixLasso: Generalized Mixed Regression via Con...</td>\n",
       "      <td>We consider a generalization of mixed regressi...</td>\n",
       "      <td>eyan@cs.cmu.edu;b01902065@ntu.edu.tw;kaizhong8...</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Optimizatio</td>\n",
       "      <td>Optimizatio</td>\n",
       "      <td>[mixlasso, gener, mix, regress, via, convex, a...</td>\n",
       "      <td>6961</td>\n",
       "      <td>[0.791815187, 0.657667486, 0.70105964, 0.77798...</td>\n",
       "      <td>-3.057512</td>\n",
       "      <td>30.973089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>6968</td>\n",
       "      <td>Semidefinite relaxations for certifying robust...</td>\n",
       "      <td>Research on adversarial examples are evolved i...</td>\n",
       "      <td>aditir1994@gmail.com;jacob.steinhardt@gmail.co...</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Securit</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[semidefinit, relax, certifi, robust, adversar...</td>\n",
       "      <td>6968</td>\n",
       "      <td>[0.612903855, 0.584632164, 0.580678234, 0.6383...</td>\n",
       "      <td>29.588923</td>\n",
       "      <td>-18.780851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>6972</td>\n",
       "      <td>Removing Hidden Confounding by Experimental Gr...</td>\n",
       "      <td>Observational data is being increasingly used ...</td>\n",
       "      <td>kallus@cornell.edu;apm470@nyu.edu;urishalit@te...</td>\n",
       "      <td>Probabilistic Methods/Causal Inference*; Algor...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Probabilistic Methods/Causal Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[remov, hidden, confound, experiment, ground, ...</td>\n",
       "      <td>6972</td>\n",
       "      <td>[0.586181571, 0.490689461, 0.549189971, 0.5911...</td>\n",
       "      <td>-92.203499</td>\n",
       "      <td>15.671731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>6978</td>\n",
       "      <td>Topkapi: Parallel and Fast Sketches for Findin...</td>\n",
       "      <td>Identifying the top-K frequent items is one of...</td>\n",
       "      <td>ankush@gatech.edu;cary.jiang@rice.edu;anshumal...</td>\n",
       "      <td>Applications/Web Applications and Internet Dat...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Web Applications and Internet Data</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[topkapi, parallel, fast, sketch, find, top, f...</td>\n",
       "      <td>6978</td>\n",
       "      <td>[0.672761353, 0.6915534390000001, 0.673524338,...</td>\n",
       "      <td>26.572653</td>\n",
       "      <td>19.820202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>7985</td>\n",
       "      <td>Contrastive Learning from Pairwise Measurements</td>\n",
       "      <td>Learning from pairwise measurements naturally ...</td>\n",
       "      <td>yichen2016@u.northwestern.edu;zy6@princeton.ed...</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[contrast, learn, pairwis, measur, learn, pair...</td>\n",
       "      <td>7985</td>\n",
       "      <td>[0.801794205, 0.6445370810000001, 0.70768539, ...</td>\n",
       "      <td>42.427158</td>\n",
       "      <td>25.685112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>7992</td>\n",
       "      <td>Point process latent variable models of freely...</td>\n",
       "      <td>A fundamental goal of systems neuroscience is ...</td>\n",
       "      <td>as4529@columbia.edu;scott.linderman@columbia.e...</td>\n",
       "      <td>Probabilistic Methods/Latent Variable Models*;...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Probabilistic Methods/Latent Variable Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[point, process, latent, variabl, model, freel...</td>\n",
       "      <td>7992</td>\n",
       "      <td>[0.78844959, 0.730344946, 0.7138572390000001, ...</td>\n",
       "      <td>-80.002975</td>\n",
       "      <td>-5.024580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>7994</td>\n",
       "      <td>Computationally and Statistically Efficient Le...</td>\n",
       "      <td>Causal discovery from empirical data is a fund...</td>\n",
       "      <td>kbellome@purdue.edu;jhonorio@purdue.edu</td>\n",
       "      <td>Theory/Learning Theory*; Probabilistic Methods...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[comput, statist, effici, learn, bay, net, use...</td>\n",
       "      <td>7994</td>\n",
       "      <td>[0.442452024, 0.376913364, 0.45425219, 0.45383...</td>\n",
       "      <td>-0.688502</td>\n",
       "      <td>15.611752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>7997</td>\n",
       "      <td>Sparse PCA from Sparse Linear Regression</td>\n",
       "      <td>Sparse Principal Component Analysis (SPCA) and...</td>\n",
       "      <td>guy@mit.edu;sp765@mit.edu;mpersu@mit.edu</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[spars, pca, spars, linear, regress, spars, pr...</td>\n",
       "      <td>7997</td>\n",
       "      <td>[0.755127242, 0.609168548, 0.665014251, 0.7336...</td>\n",
       "      <td>42.023003</td>\n",
       "      <td>32.024750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>8002</td>\n",
       "      <td>Sequential Data Classification for Resource-co...</td>\n",
       "      <td>We study the problem of fast and efficient cla...</td>\n",
       "      <td>t-dodenn@microsoft.com;chiragramdas@gmail.com;...</td>\n",
       "      <td>Deep Learning/Efficient Inference Methods*; De...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Efficient Inference Methods</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[sequenti, data, classif, resourc, constrain, ...</td>\n",
       "      <td>8002</td>\n",
       "      <td>[0.849686171, 0.9341852970000001, 0.7916773859...</td>\n",
       "      <td>-39.611614</td>\n",
       "      <td>-27.079840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>8009</td>\n",
       "      <td>Transfer of Deep Reactive Policies for MDP Pla...</td>\n",
       "      <td>Domain-independent probabilistic planners inpu...</td>\n",
       "      <td>quantum.computing96@gmail.com;sankalp2621998@g...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Reinforcement Learning and Plannin</td>\n",
       "      <td>Reinforcement Learning and Plannin</td>\n",
       "      <td>[transfer, deep, reactiv, polici, mdp, plan, d...</td>\n",
       "      <td>8009</td>\n",
       "      <td>[0.7646644690000001, 0.7638223829999999, 0.729...</td>\n",
       "      <td>78.536331</td>\n",
       "      <td>3.035766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>8034</td>\n",
       "      <td>The Price of Fair PCA: One Extra dimension</td>\n",
       "      <td>In this paper, we investigate the possibility ...</td>\n",
       "      <td>s.samadi@gmail.com;tao@gatech.edu;jamiemor@cis...</td>\n",
       "      <td>Applications/Fairness, Accountability, and Tra...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Fairness, Accountability, and Tra...</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[price, fair, pca, one, extra, dimens, thi, pa...</td>\n",
       "      <td>8034</td>\n",
       "      <td>[0.7302362170000001, 0.631884585, 0.691013077,...</td>\n",
       "      <td>25.288885</td>\n",
       "      <td>27.855110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>8035</td>\n",
       "      <td>GroupReduce: Block-Wise Low-Rank Approximation...</td>\n",
       "      <td>Model compression is essential for serving lar...</td>\n",
       "      <td>phpchen@ucdavis.edu;sisidaisy@google.com;liyan...</td>\n",
       "      <td>Applications/Natural Language Processing</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Natural Language Processin</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[groupreduc, block, wise, low, rank, approxim,...</td>\n",
       "      <td>8035</td>\n",
       "      <td>[0.7068314809999999, 0.8144392220000001, 0.691...</td>\n",
       "      <td>16.285067</td>\n",
       "      <td>-24.585033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Paper ID                                        Paper Title  \\\n",
       "0           29  Efficient Algorithms for Non-convex Isotonic R...   \n",
       "1           33      Structure-Aware Convolutional Neural Networks   \n",
       "2           34                               Kalman Normalization   \n",
       "3           37                  HOGWILD!-Gibbs can be PanAccurate   \n",
       "4           40  Text-Adaptive Generative Adversarial Networks:...   \n",
       "5           59  IntroVAE: Introspective Variational Autoencode...   \n",
       "6           68  Doubly Robust Bayesian Inference for Non-Stati...   \n",
       "7           75  Adapted Deep Embeddings: A Synthesis of Method...   \n",
       "8           77  Generalized Inverse Optimization through Onlin...   \n",
       "9           85  An Off-policy Policy Gradient Theorem Using Em...   \n",
       "10          88  Supervised autoencoders: Improving generalizat...   \n",
       "11          92  Visual Object Networks: Image Generation with ...   \n",
       "12          95  Understanding Weight Normalized Deep Neural Ne...   \n",
       "13          99  Learning Pipelines with Limited Data and Domai...   \n",
       "14         102  Learning long-range spatial dependencies with ...   \n",
       "15         110  Joint Sub-bands Learning with Clique Structure...   \n",
       "16         142  Fast Similarity Search via Optimal Sparse Lifting   \n",
       "17         145  Learning Deep Disentangled Embeddings With the...   \n",
       "18         153         Geometrically Coupled Monte Carlo Sampling   \n",
       "19         175  Cooperative Holistic 3D Scene Understanding fr...   \n",
       "20         177  An Efficient Pruning Algorithm for Robust Isot...   \n",
       "21         178        PAC-learning in the presence of adversaries   \n",
       "22         182   Sparse DNNs with Improved Adversarial Robustness   \n",
       "23         185  Snap ML: A Hierarchical Framework for Machine ...   \n",
       "24         186  See and Think: Disentangling Semantic Scene Co...   \n",
       "25         187   Chain of Reasoning for Visual Question Answering   \n",
       "26         188   Sigsoftmax: Reanalysis of the Softmax Bottleneck   \n",
       "27         191  Deep Non-Blind Deconvolution via Generalized L...   \n",
       "28         192  Probabilistic Pose Graph Optimization via Bing...   \n",
       "29         207  MetaAnchor: Learning to Detect Objects with Cu...   \n",
       "...        ...                                                ...   \n",
       "982       6787  Thermostat-assisted continuously-tempered Hami...   \n",
       "983       6793          Robust Subspace Approximation in a Stream   \n",
       "984       6802  Mean Field for the Stochastic Blockmodel: Opti...   \n",
       "985       6832  Analysis of Krylov Subspace Solutions of  Regu...   \n",
       "986       6836  Autoconj: Recognizing and Exploiting Conjugacy...   \n",
       "987       6839  DropBlock: A regularization method for convolu...   \n",
       "988       6843  Forward Modeling for Partial Observation Strat...   \n",
       "989       6847    With Friends Like These, Who Needs Adversaries?   \n",
       "990       6859  Decentralize and Randomize: Faster Algorithm f...   \n",
       "991       6863  Joint Autoregressive and Hierarchical Priors f...   \n",
       "992       6874  Learning Temporal Point Processes via Reinforc...   \n",
       "993       6882  Bias and Generalization in Deep Generative Mod...   \n",
       "994       6892        Fast and Effective Robustness Certification   \n",
       "995       6901  Support Recovery for Orthogonal Matching Pursu...   \n",
       "996       6905      Differentially Private Change-Point Detection   \n",
       "997       6913  Multi-value Rule Sets for Interpretable Classi...   \n",
       "998       6921  Domain Adaptation by Using Causal Inference to...   \n",
       "999       6923  Smoothed Analysis of Discrete Tensor Decomposi...   \n",
       "1000      6961  MixLasso: Generalized Mixed Regression via Con...   \n",
       "1001      6968  Semidefinite relaxations for certifying robust...   \n",
       "1002      6972  Removing Hidden Confounding by Experimental Gr...   \n",
       "1003      6978  Topkapi: Parallel and Fast Sketches for Findin...   \n",
       "1004      7985    Contrastive Learning from Pairwise Measurements   \n",
       "1005      7992  Point process latent variable models of freely...   \n",
       "1006      7994  Computationally and Statistically Efficient Le...   \n",
       "1007      7997           Sparse PCA from Sparse Linear Regression   \n",
       "1008      8002  Sequential Data Classification for Resource-co...   \n",
       "1009      8009  Transfer of Deep Reactive Policies for MDP Pla...   \n",
       "1010      8034         The Price of Fair PCA: One Extra dimension   \n",
       "1011      8035  GroupReduce: Block-Wise Low-Rank Approximation...   \n",
       "\n",
       "                                               Abstract  \\\n",
       "0     We consider the minimization of submodular fun...   \n",
       "1     Convolutional neural networks (CNNs) are inher...   \n",
       "2     As an indispensable component, Batch Normaliza...   \n",
       "3     Asynchronous Gibbs sampling has been recently ...   \n",
       "4     This paper addresses the problem of manipulati...   \n",
       "5     We present a novel introspective variational a...   \n",
       "6     We present the very first robust Bayesian Onli...   \n",
       "7     The focus in machine learning has branched bey...   \n",
       "8     Inverse optimization is a powerful paradigm fo...   \n",
       "9     Policy gradient methods are widely used for co...   \n",
       "10    Generalization performance is a central goal i...   \n",
       "11    Recent progress in deep generative models has ...   \n",
       "12    This paper presents a general framework for no...   \n",
       "13    As machine learning becomes more widely used i...   \n",
       "14    Progress in deep learning has spawned great su...   \n",
       "15    Convolutional neural networks (CNNs) have rece...   \n",
       "16    Similarity search is a fundamental problem in ...   \n",
       "17    Deep-embedding methods aim to discover represe...   \n",
       "18    Monte Carlo sampling in high-dimensional, low-...   \n",
       "19    Holistic 3D indoor scene understanding involve...   \n",
       "20    We study a generalization of the classic isoto...   \n",
       "21    The existence of evasion attacks during the te...   \n",
       "22    Deep neural networks (DNNs) are computationall...   \n",
       "23    We describe a new software framework for fast ...   \n",
       "24    Semantic scene completion predicts volumetric ...   \n",
       "25    Reasoning plays an essential role in Visual Qu...   \n",
       "26    Softmax is an output activation function for m...   \n",
       "27    In this paper, we present a deep convolutional...   \n",
       "28    We introduce Tempered Geodesic MCMC (TG-MCMC) ...   \n",
       "29    We propose a novel and flexible anchor mechani...   \n",
       "...                                                 ...   \n",
       "982   In this paper, we propose a novel sampling met...   \n",
       "983   We study robust subspace estimation in the str...   \n",
       "984   Variational approximation has been widely used...   \n",
       "985   We provide convergence rates for Krylov subspa...   \n",
       "986   Deriving conditional and marginal distribution...   \n",
       "987   Deep neural networks often work well when they...   \n",
       "988   We formulate the problem of \\emph{defogging} a...   \n",
       "989   The vulnerability of deep networks to adversar...   \n",
       "990   We study the problem of decentralized distribu...   \n",
       "991   Recent models for learned image compression ar...   \n",
       "992   Many real world problems from sustainability, ...   \n",
       "993   In high dimensional settings, density estimati...   \n",
       "994   We present a new method and system for certify...   \n",
       "995   This paper studies the problem of sparse regre...   \n",
       "996   The change-point detection problem seeks to id...   \n",
       "997   We present Multi-value Rule Sets (MRS) for int...   \n",
       "998   An important goal common to domain adaptation ...   \n",
       "999   We analyze linear independence of rank one ten...   \n",
       "1000  We consider a generalization of mixed regressi...   \n",
       "1001  Research on adversarial examples are evolved i...   \n",
       "1002  Observational data is being increasingly used ...   \n",
       "1003  Identifying the top-K frequent items is one of...   \n",
       "1004  Learning from pairwise measurements naturally ...   \n",
       "1005  A fundamental goal of systems neuroscience is ...   \n",
       "1006  Causal discovery from empirical data is a fund...   \n",
       "1007  Sparse Principal Component Analysis (SPCA) and...   \n",
       "1008  We study the problem of fast and efficient cla...   \n",
       "1009  Domain-independent probabilistic planners inpu...   \n",
       "1010  In this paper, we investigate the possibility ...   \n",
       "1011  Model compression is essential for serving lar...   \n",
       "\n",
       "                                          Author Emails  \\\n",
       "0                                 francis.bach@inria.fr   \n",
       "1     jianlong.chang@nlpr.ia.ac.cn;jie.gu@nlpr.ia.ac...   \n",
       "2     wanggrun@mail2.sysu.edu.cn;jiefengpeng@gmail.c...   \n",
       "3     costis@csail.mit.edu;ndikkala@mit.edu;jayanti@...   \n",
       "4     shnnam@yonsei.ac.kr;kim_yunji@yonsei.ac.kr;seo...   \n",
       "5     huaibo.huang@cripac.ia.ac.cn;zhihang.li@nlpr.i...   \n",
       "6     j.knoblauch@warwick.ac.uk;j.e.jewson@warwick.a...   \n",
       "7     tysc7237@colorado.edu;karl.ridgeway@colorado.e...   \n",
       "8     chaosheng@pitt.edu;yiran.chen@duke.edu;bzeng@p...   \n",
       "9     imani@ualberta.ca;graves@ualberta.ca;whitem@ua...   \n",
       "10      leile@iu.edu;andnpatt@iu.edu;whitem@ualberta.ca   \n",
       "11    junyanz@mit.edu;ztzhang@mit.edu;ckzhang@mit.ed...   \n",
       "12                 xu573@purdue.edu;wangxiao@purdue.edu   \n",
       "13    mrinmayaster@gmail.com;avinava.dubey@gmail.com...   \n",
       "14    drew_linsley@brown.edu;junkyung_kim@brown.edu;...   \n",
       "15    zszhong@pku.edu.cn;tianchengshen@pku.edu.cn;ib...   \n",
       "16    wyli@cuhk.edu.cn;216019005@link.cuhk.edu.cn;yi...   \n",
       "17        karl.ridgeway@colorado.edu;mozer@colorado.edu   \n",
       "18    mr504@cam.ac.uk;kchoro@google.com;chalusf3@gma...   \n",
       "19    huangsiyuan@ucla.edu;syqi@cs.ucla.edu;yinxuex@...   \n",
       "20                                       clim9@wisc.edu   \n",
       "21    dcullina@princeton.edu;abhagoji@princeton.edu;...   \n",
       "22    yiwen.guo@intel.com;pkuzc@pku.edu.cn;zcs@mail....   \n",
       "23    cdu@zurich.ibm.com;tpa@zurich.ibm.com;rig@zuri...   \n",
       "24    liushice@ict.ac.cn;huyu@ict.ac.cn;zengyiming@i...   \n",
       "25    wuchenfei@bupt.edu.cn;liujinlai@bupt.edu.cn;xj...   \n",
       "26    kanai.sekitoshi@lab.ntt.co.jp;fujiwara.yasuhir...   \n",
       "27    rwq.renwenqi@gmail.com;zhjw1988@gmail.com;fore...   \n",
       "28    tolga.birdal@tum.de;umut.simsekli@telecom-pari...   \n",
       "29    yangt15@fudan.edu.cn;zhangxiangyu@megvii.com;l...   \n",
       "...                                                 ...   \n",
       "982   r.luo@cs.ucl.ac.uk;jianhong.wang.17@ucl.ac.uk;...   \n",
       "983   roiel@cs.cmu.edu;asevekar@andrew.cmu.edu;dwood...   \n",
       "984   soumendu041@gmail.com;purna.sarkar@austin.utex...   \n",
       "985               ycarmon@gmail.com;jduchi@stanford.edu   \n",
       "986   mdhoffma@cs.princeton.edu;mattjj@google.com;tr...   \n",
       "987   golnazg@google.com;tsungyi@google.com;qvl@goog...   \n",
       "988   gab@fb.com;zlin@fb.com;jgehring@fb.com;dangant...   \n",
       "989   sjetley@robots.ox.ac.uk;nicklord@robots.ox.ac....   \n",
       "990   pavel.dvurechensky@gmail.com;darina.dvinskikh@...   \n",
       "991   dminnen@google.com;jballe@google.com;gtoderici...   \n",
       "992   sli370@gatech.edu;benjaminforever@sjtu.edu.cn;...   \n",
       "993   sjzhao@stanford.edu;hyren@cs.stanford.edu;xfyu...   \n",
       "994   gsingh@inf.ethz.ch;timon.gehr@inf.ethz.ch;matt...   \n",
       "995   raghavsomani1995@gmail.com;chiragpvg@gmail.com...   \n",
       "996   krehbiel@richmond.edu;rachelc@gatech.edu;wanro...   \n",
       "997                                 tong-wang@uiowa.edu   \n",
       "998   sara.magliacane@gmail.com;thijsvanommen@gmail....   \n",
       "999   anari.nima@gmail.com;costis@csail.mit.edu;maas...   \n",
       "1000  eyan@cs.cmu.edu;b01902065@ntu.edu.tw;kaizhong8...   \n",
       "1001  aditir1994@gmail.com;jacob.steinhardt@gmail.co...   \n",
       "1002  kallus@cornell.edu;apm470@nyu.edu;urishalit@te...   \n",
       "1003  ankush@gatech.edu;cary.jiang@rice.edu;anshumal...   \n",
       "1004  yichen2016@u.northwestern.edu;zy6@princeton.ed...   \n",
       "1005  as4529@columbia.edu;scott.linderman@columbia.e...   \n",
       "1006            kbellome@purdue.edu;jhonorio@purdue.edu   \n",
       "1007           guy@mit.edu;sp765@mit.edu;mpersu@mit.edu   \n",
       "1008  t-dodenn@microsoft.com;chiragramdas@gmail.com;...   \n",
       "1009  quantum.computing96@gmail.com;sankalp2621998@g...   \n",
       "1010  s.samadi@gmail.com;tao@gatech.edu;jamiemor@cis...   \n",
       "1011  phpchen@ucdavis.edu;sisidaisy@google.com;liyan...   \n",
       "\n",
       "                                          Subject Areas   Decision  \\\n",
       "0     Optimization/Submodular Optimization*; Optimiz...     Poster   \n",
       "1     Deep Learning*; Deep Learning/CNN Architecture...     Poster   \n",
       "2     Deep Learning/CNN Architectures*; Applications...     Poster   \n",
       "3     Probabilistic Methods/Distributed Inference*; ...     Poster   \n",
       "4     Applications/Computational Photography*; Appli...  Spotlight   \n",
       "5     Deep Learning/Generative Models*; Deep Learnin...     Poster   \n",
       "6     Applications/Time Series Analysis*; Algorithms...     Poster   \n",
       "7     Algorithms/Multitask and Transfer Learning*; A...  Spotlight   \n",
       "8     Algorithms/Online Learning*; Applications/Quan...     Poster   \n",
       "9     Reinforcement Learning and Planning/Reinforcem...     Poster   \n",
       "10                   Algorithms/Representation Learning     Poster   \n",
       "11    Deep Learning/Adversarial Networks*; Applicati...     Poster   \n",
       "12                               Theory/Learning Theory     Poster   \n",
       "13          Applications*; Applications/Computer Vision     Poster   \n",
       "14    Deep Learning/Biologically Plausible Deep Netw...     Poster   \n",
       "15    Applications/Computer Vision*; Deep Learning/C...     Poster   \n",
       "16    Algorithms/Sparse Coding and Dimensionality Ex...     Poster   \n",
       "17    Algorithms/Representation Learning*; Algorithm...     Poster   \n",
       "18    Algorithms/Stochastic Methods*; Reinforcement ...  Spotlight   \n",
       "19    Applications/Visual Scene Analysis and Interpr...     Poster   \n",
       "20                                Algorithms/Regression     Poster   \n",
       "21                               Theory/Learning Theory     Poster   \n",
       "22    Deep Learning/Adversarial Networks*; Algorithm...     Poster   \n",
       "23    Applications/Hardware and Systems*; Data, Comp...     Poster   \n",
       "24    Applications/Computer Vision*; Deep Learning/C...     Poster   \n",
       "25    Applications/Visual Question Answering*; Neuro...     Poster   \n",
       "26    Deep Learning*; Deep Learning/Recurrent Networ...     Poster   \n",
       "27    Applications/Computer Vision*; Applications/De...     Poster   \n",
       "28    Applications/Computer Vision*; Applications/Ro...     Poster   \n",
       "29                        Applications/Object Detection     Poster   \n",
       "...                                                 ...        ...   \n",
       "982                          Probabilistic Methods/MCMC     Poster   \n",
       "983                  Algorithms*; Algorithms/Regression  Spotlight   \n",
       "984   Probabilistic Methods/Variational Inference*; ...     Poster   \n",
       "985   Optimization/Non-Convex Optimization*; Algorit...       Oral   \n",
       "986   Probabilistic Methods/Graphical Models*; Data,...     Poster   \n",
       "987   Theory/Regularization*; Deep Learning/CNN Arch...     Poster   \n",
       "988                           Applications/Game Playing     Poster   \n",
       "989   Deep Learning*; Algorithms/Classification; Alg...     Poster   \n",
       "990   Optimization/Convex Optimization*; Algorithms/...  Spotlight   \n",
       "991   Algorithms/Representation Learning*; Applicati...     Poster   \n",
       "992                   Applications/Time Series Analysis  Spotlight   \n",
       "993   Deep Learning/Generative Models*; Deep Learnin...  Spotlight   \n",
       "994   Deep Learning/Adversarial Networks*; Applicati...     Poster   \n",
       "995   Algorithms/Sparsity and Compressed Sensing*; A...  Spotlight   \n",
       "996   Applications/Privacy, Anonymity, and Security*...     Poster   \n",
       "997   Probabilistic Methods/Hierarchical Models*; Ap...     Poster   \n",
       "998   Probabilistic Methods/Causal Inference*; Deep ...     Poster   \n",
       "999   Theory*; Algorithms/Components Analysis (e.g.,...     Poster   \n",
       "1000                                       Optimization     Poster   \n",
       "1001      Applications/Privacy, Anonymity, and Security     Poster   \n",
       "1002  Probabilistic Methods/Causal Inference*; Algor...  Spotlight   \n",
       "1003  Applications/Web Applications and Internet Dat...     Poster   \n",
       "1004  Algorithms/Components Analysis (e.g., CCA, ICA...     Poster   \n",
       "1005  Probabilistic Methods/Latent Variable Models*;...  Spotlight   \n",
       "1006  Theory/Learning Theory*; Probabilistic Methods...     Poster   \n",
       "1007  Algorithms/Components Analysis (e.g., CCA, ICA...     Poster   \n",
       "1008  Deep Learning/Efficient Inference Methods*; De...     Poster   \n",
       "1009                Reinforcement Learning and Planning     Poster   \n",
       "1010  Applications/Fairness, Accountability, and Tra...     Poster   \n",
       "1011           Applications/Natural Language Processing     Poster   \n",
       "\n",
       "                                   Primary Subject Area  \\\n",
       "0                  Optimization/Submodular Optimization   \n",
       "1                                         Deep Learning   \n",
       "2                       Deep Learning/CNN Architectures   \n",
       "3           Probabilistic Methods/Distributed Inference   \n",
       "4                Applications/Computational Photography   \n",
       "5                       Deep Learning/Generative Models   \n",
       "6                     Applications/Time Series Analysis   \n",
       "7            Algorithms/Multitask and Transfer Learning   \n",
       "8                            Algorithms/Online Learning   \n",
       "9     Reinforcement Learning and Planning/Reinforcem...   \n",
       "10                    Algorithms/Representation Learnin   \n",
       "11                   Deep Learning/Adversarial Networks   \n",
       "12                                Theory/Learning Theor   \n",
       "13                                         Applications   \n",
       "14    Deep Learning/Biologically Plausible Deep Netw...   \n",
       "15                         Applications/Computer Vision   \n",
       "16    Algorithms/Sparse Coding and Dimensionality Ex...   \n",
       "17                   Algorithms/Representation Learning   \n",
       "18                        Algorithms/Stochastic Methods   \n",
       "19    Applications/Visual Scene Analysis and Interpr...   \n",
       "20                                 Algorithms/Regressio   \n",
       "21                                Theory/Learning Theor   \n",
       "22                   Deep Learning/Adversarial Networks   \n",
       "23                    Applications/Hardware and Systems   \n",
       "24                         Applications/Computer Vision   \n",
       "25               Applications/Visual Question Answering   \n",
       "26                                        Deep Learning   \n",
       "27                         Applications/Computer Vision   \n",
       "28                         Applications/Computer Vision   \n",
       "29                         Applications/Object Detectio   \n",
       "...                                                 ...   \n",
       "982                           Probabilistic Methods/MCM   \n",
       "983                                          Algorithms   \n",
       "984         Probabilistic Methods/Variational Inference   \n",
       "985                Optimization/Non-Convex Optimization   \n",
       "986              Probabilistic Methods/Graphical Models   \n",
       "987                               Theory/Regularization   \n",
       "988                            Applications/Game Playin   \n",
       "989                                       Deep Learning   \n",
       "990                    Optimization/Convex Optimization   \n",
       "991                  Algorithms/Representation Learning   \n",
       "992                    Applications/Time Series Analysi   \n",
       "993                     Deep Learning/Generative Models   \n",
       "994                  Deep Learning/Adversarial Networks   \n",
       "995          Algorithms/Sparsity and Compressed Sensing   \n",
       "996       Applications/Privacy, Anonymity, and Security   \n",
       "997           Probabilistic Methods/Hierarchical Models   \n",
       "998              Probabilistic Methods/Causal Inference   \n",
       "999                                              Theory   \n",
       "1000                                        Optimizatio   \n",
       "1001       Applications/Privacy, Anonymity, and Securit   \n",
       "1002             Probabilistic Methods/Causal Inference   \n",
       "1003    Applications/Web Applications and Internet Data   \n",
       "1004  Algorithms/Components Analysis (e.g., CCA, ICA...   \n",
       "1005       Probabilistic Methods/Latent Variable Models   \n",
       "1006                             Theory/Learning Theory   \n",
       "1007  Algorithms/Components Analysis (e.g., CCA, ICA...   \n",
       "1008          Deep Learning/Efficient Inference Methods   \n",
       "1009                 Reinforcement Learning and Plannin   \n",
       "1010  Applications/Fairness, Accountability, and Tra...   \n",
       "1011            Applications/Natural Language Processin   \n",
       "\n",
       "           Top-level Primary Subject Area  \\\n",
       "0                            Optimization   \n",
       "1                           Deep Learning   \n",
       "2                           Deep Learning   \n",
       "3                   Probabilistic Methods   \n",
       "4                            Applications   \n",
       "5                           Deep Learning   \n",
       "6                            Applications   \n",
       "7                              Algorithms   \n",
       "8                              Algorithms   \n",
       "9     Reinforcement Learning and Planning   \n",
       "10                             Algorithms   \n",
       "11                          Deep Learning   \n",
       "12                                 Theory   \n",
       "13                           Applications   \n",
       "14                          Deep Learning   \n",
       "15                           Applications   \n",
       "16                             Algorithms   \n",
       "17                             Algorithms   \n",
       "18                             Algorithms   \n",
       "19                           Applications   \n",
       "20                             Algorithms   \n",
       "21                                 Theory   \n",
       "22                          Deep Learning   \n",
       "23                           Applications   \n",
       "24                           Applications   \n",
       "25                           Applications   \n",
       "26                          Deep Learning   \n",
       "27                           Applications   \n",
       "28                           Applications   \n",
       "29                           Applications   \n",
       "...                                   ...   \n",
       "982                 Probabilistic Methods   \n",
       "983                            Algorithms   \n",
       "984                 Probabilistic Methods   \n",
       "985                          Optimization   \n",
       "986                 Probabilistic Methods   \n",
       "987                                Theory   \n",
       "988                          Applications   \n",
       "989                         Deep Learning   \n",
       "990                          Optimization   \n",
       "991                            Algorithms   \n",
       "992                          Applications   \n",
       "993                         Deep Learning   \n",
       "994                         Deep Learning   \n",
       "995                            Algorithms   \n",
       "996                          Applications   \n",
       "997                 Probabilistic Methods   \n",
       "998                 Probabilistic Methods   \n",
       "999                                Theory   \n",
       "1000                          Optimizatio   \n",
       "1001                         Applications   \n",
       "1002                Probabilistic Methods   \n",
       "1003                         Applications   \n",
       "1004                           Algorithms   \n",
       "1005                Probabilistic Methods   \n",
       "1006                               Theory   \n",
       "1007                           Algorithms   \n",
       "1008                        Deep Learning   \n",
       "1009   Reinforcement Learning and Plannin   \n",
       "1010                         Applications   \n",
       "1011                         Applications   \n",
       "\n",
       "                                                    bow   pid  \\\n",
       "0     [effici, algorithm, non, convex, isoton, regre...    29   \n",
       "1     [structur, awar, convolut, neural, network, co...    33   \n",
       "2     [kalman, normal, indispens, compon, batch, nor...    34   \n",
       "3     [hogwild, gibb, panaccur, asynchron, gibb, sam...    37   \n",
       "4     [text, adapt, gener, adversari, network, manip...    40   \n",
       "5     [introva, introspect, variat, autoencod, photo...    59   \n",
       "6     [doubli, robust, bayesian, infer, non, station...    68   \n",
       "7     [adapt, deep, embed, synthesi, method, shot, i...    75   \n",
       "8     [gener, invers, optim, onlin, learn, invers, o...    77   \n",
       "9     [polici, polici, gradient, theorem, use, empha...    85   \n",
       "10    [supervis, autoencod, improv, gener, perform, ...    88   \n",
       "11    [visual, object, network, imag, gener, disenta...    92   \n",
       "12    [understand, weight, normal, deep, neural, net...    95   \n",
       "13    [learn, pipelin, limit, data, domain, knowledg...    99   \n",
       "14    [learn, long, rang, spatial, depend, horizont,...   102   \n",
       "15    [joint, sub, band, learn, cliqu, structur, wav...   110   \n",
       "16    [fast, similar, search, via, optim, spars, lif...   142   \n",
       "17    [learn, deep, disentangl, embed, statist, loss...   145   \n",
       "18    [geometr, coupl, mont, carlo, sampl, mont, car...   153   \n",
       "19    [cooper, holist, 3d, scene, understand, singl,...   175   \n",
       "20    [effici, prune, algorithm, robust, isoton, reg...   177   \n",
       "21    [pac, learn, presenc, adversari, exist, evas, ...   178   \n",
       "22    [spars, dnn, improv, adversari, robust, deep, ...   182   \n",
       "23    [snap, ml, hierarch, framework, machin, learn,...   185   \n",
       "24    [see, think, disentangl, semant, scene, comple...   186   \n",
       "25    [chain, reason, visual, question, answer, reas...   187   \n",
       "26    [sigsoftmax, reanalysi, softmax, bottleneck, s...   188   \n",
       "27    [deep, non, blind, deconvolut, via, gener, low...   191   \n",
       "28    [probabilist, pose, graph, optim, via, bingham...   192   \n",
       "29    [metaanchor, learn, detect, object, custom, an...   207   \n",
       "...                                                 ...   ...   \n",
       "982   [thermostat, assist, continu, temper, hamilton...  6787   \n",
       "983   [robust, subspac, approxim, stream, studi, rob...  6793   \n",
       "984   [mean, field, stochast, blockmodel, optim, lan...  6802   \n",
       "985   [analysi, krylov, subspac, solut, regular, non...  6832   \n",
       "986   [autoconj, recogn, exploit, conjugaci, without...  6836   \n",
       "987   [dropblock, regular, method, convolut, network...  6839   \n",
       "988   [forward, model, partial, observ, strategi, ga...  6843   \n",
       "989   [friend, like, need, adversari, vulner, deep, ...  6847   \n",
       "990   [decentr, random, faster, algorithm, wasserste...  6859   \n",
       "991   [joint, autoregress, hierarch, prior, learn, i...  6863   \n",
       "992   [learn, tempor, point, process, via, reinforc,...  6874   \n",
       "993   [bia, gener, deep, gener, model, empir, studi,...  6882   \n",
       "994   [fast, effect, robust, certif, present, new, m...  6892   \n",
       "995   [support, recoveri, orthogon, match, pursuit, ...  6901   \n",
       "996   [differenti, privat, chang, point, detect, cha...  6905   \n",
       "997   [multi, valu, rule, set, interpret, classif, f...  6913   \n",
       "998   [domain, adapt, use, causal, infer, predict, i...  6921   \n",
       "999   [smooth, analysi, discret, tensor, decomposit,...  6923   \n",
       "1000  [mixlasso, gener, mix, regress, via, convex, a...  6961   \n",
       "1001  [semidefinit, relax, certifi, robust, adversar...  6968   \n",
       "1002  [remov, hidden, confound, experiment, ground, ...  6972   \n",
       "1003  [topkapi, parallel, fast, sketch, find, top, f...  6978   \n",
       "1004  [contrast, learn, pairwis, measur, learn, pair...  7985   \n",
       "1005  [point, process, latent, variabl, model, freel...  7992   \n",
       "1006  [comput, statist, effici, learn, bay, net, use...  7994   \n",
       "1007  [spars, pca, spars, linear, regress, spars, pr...  7997   \n",
       "1008  [sequenti, data, classif, resourc, constrain, ...  8002   \n",
       "1009  [transfer, deep, reactiv, polici, mdp, plan, d...  8009   \n",
       "1010  [price, fair, pca, one, extra, dimens, thi, pa...  8034   \n",
       "1011  [groupreduc, block, wise, low, rank, approxim,...  8035   \n",
       "\n",
       "                                                   tpms   tsne_all  tsne_tpms  \n",
       "0     [0.724210006, 0.547847061, 0.62121431, 0.69992... -65.037216  43.380173  \n",
       "1     [0.722796601, 0.7524726279999999, 0.681080612,... -27.842775 -41.931042  \n",
       "2     [0.605652029, 0.624528822, 0.5549479039999999,... -45.000961 -22.988417  \n",
       "3     [0.6039084920000001, 0.571028136, 0.547187392,... -86.396667  24.022959  \n",
       "4     [0.6074082789999999, 0.604121554, 0.5843663610...  10.959604 -44.323528  \n",
       "5     [0.554898813, 0.566786583, 0.514959909, 0.5606... -52.689449 -14.038417  \n",
       "6     [0.811906661, 0.7286812490000001, 0.745909935,...  21.148312  -1.963071  \n",
       "7     [0.7246898359999999, 0.74860931, 0.72164041200...  57.467770 -28.714304  \n",
       "8     [0.8553071390000001, 0.729569048, 0.771284843,...  62.712032  38.852795  \n",
       "9     [0.5770863589999999, 0.523376441, 0.518179388,...  85.118027   6.052812  \n",
       "10    [0.7831208590000001, 0.8086628229999999, 0.745...  52.941345 -26.562601  \n",
       "11    [0.622592223, 0.620137725, 0.574635252, 0.6193... -48.542374 -46.703506  \n",
       "12    [0.644970711, 0.6021990779999999, 0.611452154,...  -4.153590  13.390891  \n",
       "13    [0.825202962, 0.8357769540000001, 0.8245410609...  17.879139 -35.804531  \n",
       "14    [0.753889782, 0.8060686090000001, 0.7139329390... -37.060337 -39.884235  \n",
       "15    [0.665462302, 0.631348907, 0.61443569, 0.65938...   5.871789 -42.454613  \n",
       "16    [0.8577442009999999, 0.7920245159999999, 0.809...  51.363522 -17.461079  \n",
       "17    [0.801685634, 0.791540459, 0.772199449, 0.8187...  54.186298 -28.578308  \n",
       "18    [0.796080575, 0.669703717, 0.714382987, 0.7818...  43.549530  24.121429  \n",
       "19    [0.635211113, 0.587038424, 0.582188994, 0.6233...   9.757609 -47.380989  \n",
       "20    [0.8350809440000001, 0.641266087, 0.761110935,...  40.470722  43.279369  \n",
       "21    [0.5843463000000001, 0.563068797, 0.533589984,...  -4.154649 -19.239223  \n",
       "22    [0.666966905, 0.637015755, 0.638722607, 0.7032... -48.874542 -19.332710  \n",
       "23    [0.657971973, 0.853205806, 0.618791222, 0.6497...  19.205162 -23.840919  \n",
       "24    [0.657856715, 0.632397676, 0.6396587229999999,...   6.809194 -47.239983  \n",
       "25    [0.632062365, 0.6729400529999999, 0.603445259,...  12.654006 -36.788307  \n",
       "26    [0.692489644, 0.790134204, 0.660755629, 0.7194... -27.241320 -24.413645  \n",
       "27    [0.562258779, 0.5202836, 0.506214686, 0.550357...   5.565048 -42.852203  \n",
       "28    [0.9113688670000001, 0.7563436379999999, 0.820...   4.842010  29.373499  \n",
       "29    [0.620705712, 0.593533387, 0.572714624, 0.6164...   9.184333 -45.363842  \n",
       "...                                                 ...        ...        ...  \n",
       "982   [0.646289553, 0.620857109, 0.586481252, 0.6541... -83.440186  -3.773678  \n",
       "983   [0.540987701, 0.441798132, 0.49352610399999997...  36.628849  33.431755  \n",
       "984   [0.735002521, 0.627056098, 0.647996389, 0.7320... -85.291252  23.962334  \n",
       "985   [0.644204279, 0.46829059700000003, 0.536020003... -60.415810  45.334076  \n",
       "986   [0.644937403, 0.646330124, 0.606580474, 0.6317... -88.951286  -2.032948  \n",
       "987   [0.602325926, 0.709435875, 0.611376699, 0.6140... -13.005722 -40.898853  \n",
       "988   [0.64940197, 0.696797065, 0.612499372, 0.66309...  13.244852 -31.995758  \n",
       "989   [0.596239485, 0.552854089, 0.56523045, 0.61261... -28.122467 -20.176826  \n",
       "990   [0.649590907, 0.572511066, 0.579816594, 0.6330... -67.124580  29.979273  \n",
       "991   [0.5645583710000001, 0.599846334, 0.522823875,...  54.194683 -14.596280  \n",
       "992   [0.6848055690000001, 0.606161123, 0.618028853,...  22.287842   6.262251  \n",
       "993   [0.825245676, 0.77820804, 0.764052464, 0.83451... -52.453613 -39.021587  \n",
       "994   [0.656920721, 0.7048807429999999, 0.624150393,... -48.894798 -19.396210  \n",
       "995   [0.6322439089999999, 0.5179587760000001, 0.563...  41.317558  32.567497  \n",
       "996   [0.6977355690000001, 0.557927934, 0.63827413, ...  31.028465  36.121666  \n",
       "997   [0.823699588, 0.7256162290000001, 0.770973646,... -87.882576  17.551443  \n",
       "998   [0.534160482, 0.482813768, 0.514349219, 0.5274... -92.187416  15.178188  \n",
       "999   [0.693092713, 0.629186489, 0.656472765, 0.7012... -10.954827  21.518019  \n",
       "1000  [0.791815187, 0.657667486, 0.70105964, 0.77798...  -3.057512  30.973089  \n",
       "1001  [0.612903855, 0.584632164, 0.580678234, 0.6383...  29.588923 -18.780851  \n",
       "1002  [0.586181571, 0.490689461, 0.549189971, 0.5911... -92.203499  15.671731  \n",
       "1003  [0.672761353, 0.6915534390000001, 0.673524338,...  26.572653  19.820202  \n",
       "1004  [0.801794205, 0.6445370810000001, 0.70768539, ...  42.427158  25.685112  \n",
       "1005  [0.78844959, 0.730344946, 0.7138572390000001, ... -80.002975  -5.024580  \n",
       "1006  [0.442452024, 0.376913364, 0.45425219, 0.45383...  -0.688502  15.611752  \n",
       "1007  [0.755127242, 0.609168548, 0.665014251, 0.7336...  42.023003  32.024750  \n",
       "1008  [0.849686171, 0.9341852970000001, 0.7916773859... -39.611614 -27.079840  \n",
       "1009  [0.7646644690000001, 0.7638223829999999, 0.729...  78.536331   3.035766  \n",
       "1010  [0.7302362170000001, 0.631884585, 0.691013077,...  25.288885  27.855110  \n",
       "1011  [0.7068314809999999, 0.8144392220000001, 0.691...  16.285067 -24.585033  \n",
       "\n",
       "[1012 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Algorithms                                           207\n",
       "Deep Learning                                        194\n",
       "Applications                                         193\n",
       "Probabilistic Methods                                106\n",
       "Theory                                                97\n",
       "Reinforcement Learning and Planning                   85\n",
       "Optimization                                          80\n",
       "Neuroscience and Cognitive Science                    33\n",
       "Deep Learnin                                           7\n",
       "Data, Competitions, Implementations, and Software      6\n",
       "Application                                            2\n",
       "Optimizatio                                            1\n",
       "Reinforcement Learning and Plannin                     1\n",
       "Name: Top-level Primary Subject Area, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Top-level Primary Subject Area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20.000000\n",
       "mean     77.250687\n",
       "std       8.525471\n",
       "min      64.499245\n",
       "25%      69.843943\n",
       "50%      77.044952\n",
       "75%      82.516861\n",
       "max      91.969955\n",
       "Name: tsne_all, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df[df['Top-level Primary Subject Area'] == 'Deep Learning'].sample(20).tsne_all.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20.000000\n",
       "mean    -14.494806\n",
       "std       6.922783\n",
       "min     -28.435780\n",
       "25%     -19.532537\n",
       "50%     -14.800924\n",
       "75%      -8.996397\n",
       "max      -3.179419\n",
       "Name: tsne_all, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Top-level Primary Subject Area'] == 'Applications'].sample(20).tsne_all.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20.000000\n",
       "mean     48.934467\n",
       "std       0.504604\n",
       "min      48.104179\n",
       "25%      48.520535\n",
       "50%      48.901932\n",
       "75%      49.327170\n",
       "max      49.699711\n",
       "Name: tsne_all, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Primary Subject Area'] == 'Reinforcement Learning and Planning/Reinforcement Learning'].sample(20).tsne_all.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Spotlight paper-session assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 1\n",
    "# 10:05-10:45 3 tracks (1 oral, 2 spotlights, 1 oral in each)\n",
    "# 3:30-5 3 tracks (4 spotlights, 1 oral, 4 spotlights, 1 oral, 4 spotlights in each)\n",
    "\n",
    "# Day 2\n",
    "# 9:45-10:45 3 tracks (4 spotlights, 1 oral, 5 spotlights in each)\n",
    "# 3:30-5 3 tracks (4 spotlights, 1 oral, 4 spotlights, 1 oral, 4 spotlights in each)\n",
    "\n",
    "# Day 3\n",
    "# 9:45-10:45 3 tracks (4 spotlights, 1 oral, 5 spotlights in each)\n",
    "# 3:30-5 3 tracks (4 spotlights, 1 oral, 4 spotlights, 1 oral, 4 spotlights in each)\n",
    "\n",
    "# set by Program Chairs\n",
    "# Day_Session_Time = Size\n",
    "sess_size = dict(\n",
    "D1_S1_T1=2,\n",
    "D1_S1_T2=2,\n",
    "D1_S1_T3=2,\n",
    "D1_S2_T1=12,\n",
    "D1_S2_T2=12,\n",
    "D1_S2_T3=12,\n",
    "D2_S1_T1=9,\n",
    "D2_S1_T2=9,\n",
    "D2_S1_T3=9,\n",
    "D2_S2_T1=12,\n",
    "D2_S2_T2=12,\n",
    "D2_S2_T3=12,\n",
    "D3_S1_T1=9,\n",
    "D3_S1_T2=9,\n",
    "D3_S1_T3=9,\n",
    "D3_S2_T1=12,\n",
    "D3_S2_T2=12,\n",
    "D3_S2_T3=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sess_size.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oral paper-session assignments set by Program Chairs\n",
    "# for appending: orals done manually. \n",
    "# cur_sess_asgn = pd.read_csv('/Users/choonhui/Downloads/session_arrangement.20170927_rob.csv')\n",
    "# orals = cur_sess_asgn[cur_sess_asgn.Decision == 'Oral'][['Paper ID', 'Oral Session']]\n",
    "# newdf = df.merge(orals, on='Paper ID', how='left', suffixes=('','_'))\n",
    "\n",
    "cur_sess_asgn = pd.read_csv('Oral_Arrange.csv', encoding='utf-8')\n",
    "orals = cur_sess_asgn[['Paper ID', 'Session']]\n",
    "newdf = df.merge(orals, on='Paper ID', how='left', suffixes=('','_'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper ID</th>\n",
       "      <th>Session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>431</td>\n",
       "      <td>D2_S1_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>496</td>\n",
       "      <td>D1_S1_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1026</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1143</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1147</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1242</td>\n",
       "      <td>D2_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1246</td>\n",
       "      <td>D1_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1319</td>\n",
       "      <td>D2_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1446</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1520</td>\n",
       "      <td>D2_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1737</td>\n",
       "      <td>D1_S1_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2077</td>\n",
       "      <td>D3_S1_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2257</td>\n",
       "      <td>D2_S1_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2613</td>\n",
       "      <td>D2_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2774</td>\n",
       "      <td>D3_S1_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3310</td>\n",
       "      <td>D1_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3518</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3534</td>\n",
       "      <td>D1_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3826</td>\n",
       "      <td>D1_S1_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4952</td>\n",
       "      <td>D2_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5026</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5133</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5269</td>\n",
       "      <td>D1_S1_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5327</td>\n",
       "      <td>D2_S1_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5491</td>\n",
       "      <td>D1_S1_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5855</td>\n",
       "      <td>D3_S1_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6460</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6491</td>\n",
       "      <td>D1_S1_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6603</td>\n",
       "      <td>D1_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6832</td>\n",
       "      <td>D2_S2_T3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Paper ID   Session\n",
       "0        431  D2_S1_T2\n",
       "1        496  D1_S1_T2\n",
       "2       1026  D3_S2_T2\n",
       "3       1143  D3_S2_T2\n",
       "4       1147  D3_S2_T3\n",
       "5       1242  D2_S2_T1\n",
       "6       1246  D1_S2_T2\n",
       "7       1319  D2_S2_T2\n",
       "8       1446  D3_S2_T3\n",
       "9       1520  D2_S2_T3\n",
       "10      1737  D1_S1_T3\n",
       "11      2077  D3_S1_T1\n",
       "12      2257  D2_S1_T3\n",
       "13      2613  D2_S2_T1\n",
       "14      2774  D3_S1_T2\n",
       "15      3310  D1_S2_T2\n",
       "16      3518  D1_S2_T1\n",
       "17      3534  D1_S2_T3\n",
       "18      3826  D1_S1_T1\n",
       "19      4952  D2_S2_T2\n",
       "20      5026  D3_S2_T1\n",
       "21      5133  D1_S2_T1\n",
       "22      5269  D1_S1_T1\n",
       "23      5327  D2_S1_T1\n",
       "24      5491  D1_S1_T3\n",
       "25      5855  D3_S1_T3\n",
       "26      6460  D3_S2_T1\n",
       "27      6491  D1_S1_T2\n",
       "28      6603  D1_S2_T3\n",
       "29      6832  D2_S2_T3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Spotlight-to-oral-session similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "oral_sess = newdf[newdf.Decision == 'Oral']['Session']\n",
    "oral_idx = newdf[newdf.Decision == 'Oral'].index\n",
    "spot_idx = newdf[newdf.Decision == 'Spotlight'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigns orals to groups\n",
    "groups = {}\n",
    "for g, idx in zip(oral_sess, oral_idx):\n",
    "    if g not in groups:\n",
    "        groups[g] = []\n",
    "    groups[g].append(idx)\n",
    "groups = sorted(groups.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'D1_S1_T1', [714L, 805L]),\n",
       " (u'D1_S1_T2', [82L, 925L]),\n",
       " (u'D1_S1_T3', [315L, 843L]),\n",
       " (u'D1_S2_T1', [653L, 783L]),\n",
       " (u'D1_S2_T2', [229L, 607L]),\n",
       " (u'D1_S2_T3', [656L, 949L]),\n",
       " (u'D2_S1_T1', [819L]),\n",
       " (u'D2_S1_T2', [71L]),\n",
       " (u'D2_S1_T3', [428L]),\n",
       " (u'D2_S2_T1', [226L, 503L]),\n",
       " (u'D2_S2_T2', [241L, 741L]),\n",
       " (u'D2_S2_T3', [268L, 985L]),\n",
       " (u'D3_S1_T1', [391L]),\n",
       " (u'D3_S1_T2', [531L]),\n",
       " (u'D3_S1_T3', [884L]),\n",
       " (u'D3_S2_T1', [759L, 916L]),\n",
       " (u'D3_S2_T2', [190L, 208L]),\n",
       " (u'D3_S2_T3', [210L, 253L])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168L, 18L)\n"
     ]
    }
   ],
   "source": [
    "# for the spotlight\n",
    "# \n",
    "TPMS_s2g = np.zeros((len(spot_idx), len(groups)))\n",
    "TPSA_s2g = np.zeros((len(spot_idx), len(groups)))\n",
    "PSA_s2g = np.zeros((len(spot_idx), len(groups)))\n",
    "BOW_s2g = np.zeros((len(spot_idx), len(groups)))\n",
    "\n",
    "for i, si in enumerate(spot_idx):\n",
    "    for j, (g, ois) in enumerate(groups):\n",
    "        max_tpms = max(TPMS[si][ois])\n",
    "        TPMS_s2g[i,j] = max_tpms\n",
    "        \n",
    "        max_tpsa = max(TPSA[si][ois])\n",
    "        TPSA_s2g[i,j] = max_tpsa\n",
    "\n",
    "        max_psa = max(PSA[si][ois])\n",
    "        PSA_s2g[i,j] = max_psa\n",
    "\n",
    "        max_bow = max(BOW[si][ois])\n",
    "        BOW_s2g[i,j] = max_bow\n",
    "\n",
    "sim_tpms_tpsa_psa_bow = TPMS_s2g + TPSA_s2g + PSA_s2g + BOW_s2g\n",
    "print(sim_tpms_tpsa_psa_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78987471, 1.99515441, 0.6408277 , ..., 0.72701925, 2.11745715,\n",
       "        0.32900658],\n",
       "       [0.88371475, 1.04764761, 1.63510003, ..., 0.84653585, 0.99328952,\n",
       "        0.35412792],\n",
       "       [0.90716266, 0.86574053, 2.1539758 , ..., 0.95200101, 0.52260961,\n",
       "        0.9137021 ],\n",
       "       ...,\n",
       "       [0.87563601, 0.73612839, 3.12871888, ..., 0.79650968, 0.36631355,\n",
       "        1.14169679],\n",
       "       [0.71338357, 0.80920969, 0.71997002, ..., 0.81354574, 0.58068742,\n",
       "        0.54964782],\n",
       "       [0.8442645 , 0.78832288, 0.7234235 , ..., 0.91279386, 0.65770574,\n",
       "        0.55635297]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_tpms_tpsa_psa_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integer programming for finding best spotlight session assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_spotlights(similarities, constraints):\n",
    "    solver = pywraplp.Solver('solver', pywraplp.Solver.CBC_MIXED_INTEGER_PROGRAMMING)\n",
    "    \n",
    "    print solver\n",
    "    \n",
    "    num_spots, num_groups = similarities.shape\n",
    "    spots = range(num_spots)\n",
    "    groups = range(num_groups)\n",
    "    \n",
    "    # defind variables\n",
    "    x = {}\n",
    "    for i in spots:\n",
    "        for j in groups:\n",
    "            x[i, j] = solver.BoolVar('x[%i,%i]'%(i,j))\n",
    "    \n",
    "    # define objective\n",
    "    solver.Maximize(solver.Sum(similarities[i,j]*x[i,j] for i in spots for j in groups))\n",
    "    \n",
    "    # define constraints per group\n",
    "    for j in groups:\n",
    "        solver.Add(solver.Sum(x[i,j] for i in spots) == constraints[j])\n",
    "                \n",
    "    # define constraints per spot\n",
    "    for i in spots:\n",
    "        solver.Add(solver.Sum(x[i,j] for j in groups) == 1)\n",
    "        \n",
    "    sol = solver.Solve()\n",
    "    \n",
    "    print 'objective:', solver.Objective().Value()\n",
    "    \n",
    "    assigned_groups = {}\n",
    "    for j in groups:\n",
    "        assigned_groups[j] = []\n",
    "        for i in spots:\n",
    "            if x[i,j].solution_value() > 0:\n",
    "                assigned_groups[j].append(i)\n",
    "                \n",
    "    #assignments = [(i,j) for i in spots for j in groups if x[i,j].solution_value() > 0]\n",
    "    return assigned_groups\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 12, 12, 12, 9, 9, 9, 12, 12, 12, 9, 9, 9, 12, 12, 12]\n"
     ]
    }
   ],
   "source": [
    "constraints = [sess_size[g] for g, ois in groups]\n",
    "print(constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ortools.linear_solver.pywraplp.Solver; proxy of <Swig Object of type 'operations_research::MPSolver *' at 0x00000000D05DA960> >\n",
      "objective: 334.728593321\n"
     ]
    }
   ],
   "source": [
    "# should be larger than random\n",
    "assgn_tpms_tpsa_psa_bow = assign_spotlights(sim_tpms_tpsa_psa_bow, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_assignment(assgn, session_topic_only=False):    \n",
    "    pid_session = []\n",
    "    for g in assgn:           \n",
    "        output = []\n",
    "        psa = defaultdict(int)\n",
    "        for oi in groups[g][1]:            \n",
    "            record = newdf.iloc[oi]\n",
    "            psa[record['Primary Subject Area']] += 1\n",
    "            output.append('  [Oral] %4s : %s' % (record['Paper ID'], record['Paper Title']))\n",
    "            pid_session.append((int(record['Paper ID']), groups[g][0]))\n",
    "            \n",
    "        for i in assgn[g]:\n",
    "            record = newdf.iloc[spot_idx[i]]\n",
    "            psa[record['Primary Subject Area']] += 1\n",
    "            output.append('  [Spot] %4s : %s' % (record['Paper ID'], record['Paper Title']))\n",
    "            pid_session.append((int(record['Paper ID']), groups[g][0]))\n",
    "            \n",
    "        print 'Session: ', groups[g][0], sorted(psa.items(), key=lambda x: x[1], reverse=True)\n",
    "        if not session_topic_only:\n",
    "            print '\\n'.join(output)\n",
    "        print\n",
    "    return pd.DataFrame.from_records(pid_session, columns=['Paper ID', 'Session'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session:  D1_S1_T1 [(u'Theory', 3), (u'Neuroscience and Cognitive Science/Plasticity and Adaptation', 1)]\n",
      "  [Oral] 3826 : On Neuronal Capacity\n",
      "  [Oral] 5269 : Dendritic cortical microcircuits approximate the backpropagation algorithm\n",
      "  [Spot] 3213 : Size-Noise Tradeoffs in Generative Networks\n",
      "  [Spot] 3300 : On Coresets for Logistic Regression\n",
      "\n",
      "Session:  D1_S1_T2 [(u'Applications/Natural Language Processing', 2), (u'Deep Learning/Embedding Approaches', 1), (u'Deep Learning/Program Inductio', 1)]\n",
      "  [Oral]  496 : On Word Embedding Dimensionality\n",
      "  [Oral] 6491 : A Retrieve-and-Edit Framework for Predicting Structured Outputs\n",
      "  [Spot] 3765 : Diffusion Maps for Textual Network Embedding\n",
      "  [Spot] 4859 : Learning Libraries of Subroutines for Neurally–Guided Bayesian Program Learning\n",
      "\n",
      "Session:  D1_S1_T3 [(u'Algorithms/Sparsity and Compressed Sensing', 3), (u'Theory/Learning Theory', 1)]\n",
      "  [Oral] 1737 : Nearly tight sample complexity bounds for learning mixtures of Gaussians via sample compression schemes\n",
      "  [Oral] 5491 : Phase Retrieval Under a Generative Prior\n",
      "  [Spot]  602 : Global Geometry of Multichannel Sparse Blind Deconvolution on the Sphere\n",
      "  [Spot] 5436 : Theoretical Linear Convergence of Unfolded ISTA and Its Practical Weights and Thresholds\n",
      "\n",
      "Session:  D1_S2_T1 [(u'Theory/Statistical Physics of Learning', 2), (u'Algorithms/Unsupervised Learning', 2), (u'Algorithms/Semi-Supervised Learnin', 1), (u'Deep Learning/Program Inductio', 1), (u'Theory/Information Theory', 1), (u'Probabilistic Methods/Gaussian Processes', 1), (u'Theory/Regularization', 1), (u'Neuroscience and Cognitive Science/Neural Coding', 1), (u'Neuroscience and Cognitive Science', 1), (u'Probabilistic Methods/Gaussian Processe', 1), (u'Probabilistic Methods/Latent Variable Models', 1), (u'Algorithms/Relational Learning', 1)]\n",
      "  [Oral] 3518 : A probabilistic population code based on neural samples\n",
      "  [Oral] 5133 : Generalisation of structural knowledge in the Hippocampal-Entorhinal system\n",
      "  [Spot]  360 : Removing the Feature Correlation Effect of Multiplicative Noise\n",
      "  [Spot]  425 : Sparse Covariance Modeling in High Dimensions with Gaussian Processes\n",
      "  [Spot]  920 : Entropy and mutual information in models of deep neural networks\n",
      "  [Spot] 1640 : The committee machine: Computational to statistical gaps in learning a two-layers neural network\n",
      "  [Spot] 1878 : DeepProbLog:  Neural Probabilistic Logic Programming\n",
      "  [Spot] 2413 : Supervising Unsupervised Learning\n",
      "  [Spot] 2861 : Binary Classification from Positive-Confidence Data\n",
      "  [Spot] 2974 : Learning to Infer Graphics Programs from Hand-Drawn Images\n",
      "  [Spot] 3368 : Heterogeneous Multi-output Gaussian Process Prediction\n",
      "  [Spot] 5172 : A statistical model for graph partitioning with high-dimensional covariates\n",
      "  [Spot] 6432 : Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies\n",
      "  [Spot] 7992 : Point process latent variable models of freely swimming larval zebrafish\n",
      "\n",
      "Session:  D1_S2_T2 [(u'Deep Learning', 5), (u'Deep Learning/Optimization for Deep Networks', 3), (u'Deep Learning/Optimization for Deep Network', 1), (u'Deep Learning/Efficient Training Methods', 1), (u'Deep Learning/Generative Models', 1), (u'Deep Learning/Visualization or Exposition Techniques for Deep Network', 1), (u'Deep Learning/Supervised Deep Networks', 1), (u'Deep Learning/CNN Architectures', 1)]\n",
      "  [Oral] 1246 : How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)\n",
      "  [Oral] 3310 : Neural Ordinary Differential Equations\n",
      "  [Spot] 1099 : Norm matters: efficient and accurate normalization schemes in deep networks\n",
      "  [Spot] 1146 : BourGAN: Generative Networks with Metric Embeddings\n",
      "  [Spot] 1767 : Step Size Matters in Deep Learning\n",
      "  [Spot] 2233 : Towards Robust Detection of Adversarial Examples\n",
      "  [Spot] 2332 : Hierarchical Graph Representation Learning with Differentiable Pooling\n",
      "  [Spot] 2562 : Hyperbolic Neural Networks\n",
      "  [Spot] 2893 : Constructing Fast Network through Deconstruction of Convolution\n",
      "  [Spot] 3035 : ResNet with one-neuron hidden layers is a Universal Approximator\n",
      "  [Spot] 3356 : Training Neural Networks Using Features Replay\n",
      "  [Spot] 5153 : Neural Tangent Kernel: Convergence and Generalization in Neural Networks\n",
      "  [Spot] 5780 : Sanity Checks for Saliency Maps\n",
      "  [Spot] 5841 : To What Extent Do Different Neural Networks Learn the Same Representation: A Neuron Activation Subspace Match Approach\n",
      "\n",
      "Session:  D1_S2_T3 [(u'Theory/Learning Theory', 7), (u'Applications', 4), (u'Applications/Privacy, Anonymity, and Security', 1), (u'Theory/Learning Theor', 1), (u'Theory/Game Theory and Computational Economics', 1)]\n",
      "  [Oral] 3534 : Model-Agnostic Private Learning\n",
      "  [Oral] 6603 : Learning to solve SMT formulas\n",
      "  [Spot]  745 : On Oracle-Efficient PAC RL with Rich Observations\n",
      "  [Spot]  766 : A loss framework for calibrated anomaly detection\n",
      "  [Spot]  980 : Virtual Class Enhanced Discriminative Embedding Learning\n",
      "  [Spot] 1380 : Minimax Statistical Learning with Wasserstein distances\n",
      "  [Spot] 1717 : Learning to Optimize Tensor Programs\n",
      "  [Spot] 2434 : Adversarially Robust Generalization Requires More Data\n",
      "  [Spot] 3043 : Sharp Bounds for Generalized Uniformity Testing\n",
      "  [Spot] 3440 : Differentially Private Testing of Identity and Closeness of Discrete Distributions\n",
      "  [Spot] 3695 : Constant Regret, Generalized Mixability, and Mirror Descent\n",
      "  [Spot] 3818 : Attacks Meet Interpretability: Attribute-steered Detection of Adversarial Samples\n",
      "  [Spot] 4999 : Learning Overparameterized Neural Networks via Stochastic Gradient Descent on Structured Data\n",
      "  [Spot] 6693 : Bounded-Loss Private Prediction Markets\n",
      "\n",
      "Session:  D2_S1_T1 [(u'Reinforcement Learning and Planning', 2), (u'Algorithms/Bandit Algorithms', 2), (u'Theory/Information Theory', 1), (u'Theory/Learning Theor', 1), (u'Theory/Game Theory and Computational Economics', 1), (u'Theory/Game Theory and Computational Economic', 1), (u'Algorithms/Similarity and Distance Learning', 1), (u'Theory/Information Theor', 1)]\n",
      "  [Oral] 5327 : Exploration in Structured Reinforcement Learning\n",
      "  [Spot]  466 : Solving Large Sequential Games with the Excessive Gap Technique\n",
      "  [Spot] 1123 : A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem\n",
      "  [Spot] 1560 : Near Optimal Exploration-Exploitation in Non-Communicating Markov Decision Processes\n",
      "  [Spot] 1614 : The Nearest Neighbor Information Estimator is Adaptively Near Minimax Rate-Optimal\n",
      "  [Spot] 3690 : Revisiting $(\\epsilon, \\gamma, \\tau)$-similarity learning for domain adaptation\n",
      "  [Spot] 5106 : Almost Optimal Algorithms for Linear Stochastic Bandits with Heavy-Tailed Payoffs\n",
      "  [Spot] 6396 : Generalization Bounds for Uniformly Stable Algorithms\n",
      "  [Spot] 6406 : Entropy Rate Estimation for Markov Chains with Large State Space\n",
      "  [Spot] 6666 : Convex Elicitation of Continuous Properties\n",
      "\n",
      "Session:  D2_S1_T2 [(u'Applications/Time Series Analysis', 2), (u'Applications/Privacy, Anonymity, and Security', 2), (u'Applications/Computer Visio', 1), (u'Applications/Computational Biology and Bioinformatics', 1), (u'Applications/Computational Biology and Bioinformatic', 1), (u'Applications/Matrix and Tensor Factorization', 1), (u'Applications/Fairness, Accountability, and Transparency', 1), (u'Applications/Time Series Analysi', 1)]\n",
      "  [Oral]  431 : Visual Memory for Robust Path Following\n",
      "  [Spot]  750 : Generalizing Tree Probability Estimation via Bayesian Networks\n",
      "  [Spot]  968 : Precision and Recall for Time Series\n",
      "  [Spot] 1212 : Local Differential Privacy for Evolving Data\n",
      "  [Spot] 2600 : Differentially Private k-Means with Constant Multiplicative Error\n",
      "  [Spot] 5189 : A Likelihood-Free Inference Framework for Population Genetic Data using Exchangeable Neural Networks\n",
      "  [Spot] 5299 : Legendre Decomposition for Tensors\n",
      "  [Spot] 6512 : Bayesian Nonparametric Spectral Estimation\n",
      "  [Spot] 6531 : Human-in-the-Loop Interpretability Prior\n",
      "  [Spot] 6874 : Learning Temporal Point Processes via Reinforcement Learning\n",
      "\n",
      "Session:  D2_S1_T3 [(u'Algorithms/Online Learning', 3), (u'Algorithms/Kernel Methods', 2), (u'Algorithms/Regression', 1), (u'Algorithms/Similarity and Distance Learning', 1), (u'Algorithms', 1), (u'Algorithms/Clustering', 1), (u'Algorithms/Active Learning', 1)]\n",
      "  [Oral] 2257 : Spectral Filtering for General Linear Dynamical Systems\n",
      "  [Spot]  597 : Interactive Structure Learning with Structural Query-by-Committee\n",
      "  [Spot] 1249 : Leveraged volume sampling for linear regression\n",
      "  [Spot] 1896 : Acceleration through Optimistic No-Regret Dynamics\n",
      "  [Spot] 2001 : KONG: Kernels for ordered-neighborhood graphs\n",
      "  [Spot] 2582 : Fully Understanding The Hashing Trick\n",
      "  [Spot] 5033 : Efficient Online Portfolio with Logarithmic Regret\n",
      "  [Spot] 5500 : Quadrature-based features for kernel approximation\n",
      "  [Spot] 5707 : Statistical and Computational Trade-Offs in Kernel K-Means\n",
      "  [Spot] 6490 : Scalable Laplacian K-modes\n",
      "\n",
      "Session:  D2_S2_T1 [(u'Reinforcement Learning and Planning/Reinforcement Learning', 4), (u'Reinforcement Learning and Planning/Decision and Control', 1), (u'Reinforcement Learning and Planning', 1), (u'Deep Learning', 1), (u'Deep Learnin', 1), (u'Algorithms/Stochastic Methods', 1), (u'Neuroscience and Cognitive Science', 1), (u'Algorithms/Active Learnin', 1), (u'Algorithms/Multitask and Transfer Learning', 1), (u'Algorithms/AutoML', 1), (u'Deep Learning/Program Induction', 1)]\n",
      "  [Oral] 1242 : Recurrent World Models Facilitate Policy Evolution\n",
      "  [Oral] 2613 : Policy Optimization via Importance Sampling\n",
      "  [Spot]  153 : Geometrically Coupled Monte Carlo Sampling\n",
      "  [Spot]  576 : Efficient nonmyopic batch active search\n",
      "  [Spot]  610 : Synthesize Policies for Transfer and Adaptation across Environments and Tasks\n",
      "  [Spot] 1012 : Neural Architecture Search with Bayesian Optimisation and Optimal Transport\n",
      "  [Spot] 1533 : Playing hard exploration games by watching YouTube\n",
      "  [Spot] 2533 : Meta-Reinforcement Learning of Structured Exploration Strategies\n",
      "  [Spot] 2567 : Breaking the Curse of Horizon: Infinite-Horizon Off-policy Estimation\n",
      "  [Spot] 3551 : A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks\n",
      "  [Spot] 3572 : End-to-End Differentiable Physics for Learning and Control\n",
      "  [Spot] 3698 : A Bayesian Approach to Generative Adversarial Imitation Learning\n",
      "  [Spot] 3833 : Learning Loop Invariants for Program Verification\n",
      "  [Spot] 5839 : Learning convex bounds for linear quadratic control policy synthesis\n",
      "\n",
      "Session:  D2_S2_T2 [(u'Deep Learning/Generative Models', 7), (u'Probabilistic Methods/Graphical Models', 2), (u'Deep Learning/Few-Shot Learning Approaches', 1), (u'Probabilistic Methods/Bayesian Nonparametrics', 1), (u'Probabilistic Methods/Causal Inferenc', 1), (u'Probabilistic Methods/Causal Inference', 1), (u'Probabilistic Methods', 1)]\n",
      "  [Oral] 1319 : Isolating Sources of Disentanglement in Variational Autoencoders\n",
      "  [Oral] 4952 : Approximate Knowledge Compilation by Online Collapsed Importance Sampling\n",
      "  [Spot] 1493 : Delta-encoder: an effective sample synthesis method for few-shot object recognition\n",
      "  [Spot] 1997 : Probabilistic Neural Programmed Networks for Scene Generation\n",
      "  [Spot] 2822 : On GANs and GMMs\n",
      "  [Spot] 3436 : Stochastic Nonparametric Event-Tensor Decomposition\n",
      "  [Spot] 3470 : Causal Inference via Kernel Deviance Measures\n",
      "  [Spot] 3497 : GILBO: One Metric to Measure Them All\n",
      "  [Spot] 4984 : Proximal Graphical Event Models\n",
      "  [Spot] 5214 : Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects\n",
      "  [Spot] 5729 : Identification and Estimation of Causal Effects from Dependent Data\n",
      "  [Spot] 6431 : Dynamic Network Model from Partial Observations\n",
      "  [Spot] 6588 : Robustness of conditional GANs to noisy labels\n",
      "  [Spot] 6882 : Bias and Generalization in Deep Generative Models: An Empirical Study\n",
      "\n",
      "Session:  D2_S2_T3 [(u'Optimization/Non-Convex Optimization', 4), (u'Optimization/Non-Convex Optimizatio', 4), (u'Algorithms/Missing Data', 1), (u'Algorithms/Kernel Methods', 1), (u'Theory/Information Theory', 1), (u'Algorithms/Sparsity and Compressed Sensing', 1), (u'Algorithms', 1), (u'Probabilistic Methods/MCMC', 1)]\n",
      "  [Oral] 1520 : Stochastic Cubic Regularization for Fast Nonconvex Optimization\n",
      "  [Oral] 6832 : Analysis of Krylov Subspace Solutions of  Regularized Non-Convex Quadratic Problems\n",
      "  [Spot]  395 : Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator\n",
      "  [Spot] 1376 : Natasha 2: Faster Non-Convex Optimization Than SGD\n",
      "  [Spot] 1598 : Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization\n",
      "  [Spot] 1830 : Escaping Saddle Points in Constrained Optimization\n",
      "  [Spot] 1883 : Sublinear Time Low-Rank Approximation of Distance Matrices\n",
      "  [Spot] 1937 : Stochastic Nested Variance Reduced Gradient Descent for Nonconvex Optimization\n",
      "  [Spot] 2380 : On the Local Minima of the Empirical Risk\n",
      "  [Spot] 2641 : Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames\n",
      "  [Spot] 2671 : How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?\n",
      "  [Spot] 6487 : Blind Deconvolutional Phase Retrieval via Convex Programming\n",
      "  [Spot] 6538 : Learning with SGD and Random Features\n",
      "  [Spot] 6901 : Support Recovery for Orthogonal Matching Pursuit: Upper and Lower bounds\n",
      "\n",
      "Session:  D3_S1_T1 [(u'Algorithms/Representation Learning', 1), (u'Neuroscience and Cognitive Science/Neuroscience', 1), (u'Data, Competitions, Implementations, and Software/Benchmarks', 1), (u'Algorithms/Multitask and Transfer Learning', 1), (u'Deep Learnin', 1), (u'Algorithms/Boosting and Ensemble Methods', 1), (u'Data, Competitions, Implementations, and Software/Software Toolkits', 1), (u'Neuroscience and Cognitive Science/Cognitive Science', 1), (u'Neuroscience and Cognitive Science/Reasoning', 1), (u'Probabilistic Methods/Causal Inference', 1)]\n",
      "  [Oral] 2077 : Integrated accounts of behavioral and neuroimaging data using flexible recurrent neural network models\n",
      "  [Spot]   75 : Adapted Deep Embeddings: A Synthesis of Methods for k-Shot Inductive Transfer Learning\n",
      "  [Spot]  554 : Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding\n",
      "  [Spot] 1645 : Realistic Evaluation of Deep Semi-Supervised Learning Algorithms\n",
      "  [Spot] 3784 : Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding\n",
      "  [Spot] 5277 : Automatic differentiation in ML: Where we are and where we should be going\n",
      "  [Spot] 5291 : Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs\n",
      "  [Spot] 5345 : Improving Neural Program Synthesis with Inferred Execution Traces\n",
      "  [Spot] 5501 : Reducing Network Agnostophobia\n",
      "  [Spot] 6972 : Removing Hidden Confounding by Experimental Grounding\n",
      "\n",
      "Session:  D3_S1_T2 [(u'Probabilistic Methods/Variational Inferenc', 3), (u'Probabilistic Methods/Gaussian Processes', 2), (u'Probabilistic Methods/Variational Inference', 1), (u'Probabilistic Methods/MCM', 1), (u'Probabilistic Methods/Graphical Model', 1), (u'Probabilistic Methods/Gaussian Processe', 1), (u'Probabilistic Methods', 1)]\n",
      "  [Oral] 2774 : Variational Inference with Tail Adapted f-Divergence\n",
      "  [Spot]  280 : Implicit Reparameterization Gradients\n",
      "  [Spot] 1499 : Mirrored Langevin Dynamics\n",
      "  [Spot] 1726 : Boosting Black Box Variational Inference\n",
      "  [Spot] 3760 : Blackbox Matrix×Matrix Gaussian Process Inference\n",
      "  [Spot] 5007 : Sequential Monte Carlo for probabilistic graphical models via twisted targets\n",
      "  [Spot] 5390 : Efficient High Dimensional Bayesian Optimization with Additivity and Quadrature Fourier Features\n",
      "  [Spot] 5750 : DAGs with NO TEARS: Continuous Optimization for Structure Learning\n",
      "  [Spot] 6704 : Discretely Relaxing Continuous Variables for tractable Variational Inference\n",
      "  [Spot] 6720 : Regret bounds for meta Bayesian optimization with an unknown Gaussian process prior\n",
      "\n",
      "Session:  D3_S1_T3 [(u'Optimization/Submodular Optimization', 3), (u'Theory/Information Theory', 1), (u'Probabilistic Methods/Gaussian Processes', 1), (u'Optimization/Combinatorial Optimization', 1), (u'Algorithms/Model Selection and Structure Learning', 1), (u'Algorithms', 1), (u'Algorithms/Clustering', 1), (u'Theory/Frequentist Statistics', 1)]\n",
      "  [Oral] 5855 : Optimal Algorithms for Continuous   Non-monotone Submodular and DR-Submodular Maximization\n",
      "  [Spot]  418 : Do Less, Get More: Streaming Submodular Maximization with Subsampling\n",
      "  [Spot] 1080 : Overlapping Clustering, and One (class) SVM to Bind Them All\n",
      "  [Spot] 2272 : Boolean Decision Rules via Column Generation\n",
      "  [Spot] 2297 : Fast greedy algorithms for dictionary selection with generalized sparsity constraints\n",
      "  [Spot] 2782 : Adversarially Robust Optimization with Gaussian Processes\n",
      "  [Spot] 3751 : cpSGD: Communication-efficient and differentially-private distributed SGD\n",
      "  [Spot] 5045 : Bilevel learning of the Group Lasso structure\n",
      "  [Spot] 6782 : Data-Driven Clustering via Parameterized Lloyd's Families\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Spot] 6793 : Robust Subspace Approximation in a Stream\n",
      "\n",
      "Session:  D3_S2_T1 [(u'Reinforcement Learning and Planning/Reinforcement Learning', 4), (u'Algorithms/Classification', 2), (u'Reinforcement Learning and Planning/Model-Based R', 1), (u'Deep Learning/Meta-Learning', 1), (u'Reinforcement Learning and Planning', 1), (u'Reinforcement Learning and Planning/Decision and Contro', 1), (u'Reinforcement Learning and Planning/Model-Based RL', 1), (u'Deep Learning/Meta-Learnin', 1), (u'Theory/Regularization', 1), (u'Reinforcement Learning and Planning/Exploration', 1)]\n",
      "  [Oral] 5026 : Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion\n",
      "  [Oral] 6460 : Non-delusional Q-learning and Value-iteration\n",
      "  [Spot]  454 : Connectionist Temporal Classification with Maximum Entropy Regularization\n",
      "  [Spot] 2298 : Data-Efficient Model-based Reinforcement Learning with Deep Probabilistic Dynamics Models\n",
      "  [Spot] 2491 : Contour location via entropy reduction leveraging multiple information sources\n",
      "  [Spot] 2501 : Multiple-Step Greedy Policies in Approximate and Online Reinforcement Learning\n",
      "  [Spot] 2590 : Evolved Policy Gradients\n",
      "  [Spot] 3162 : Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation\n",
      "  [Spot] 3652 : Bayesian Model-Agnostic Meta-Learning\n",
      "  [Spot] 5217 : Randomized Prior Functions for Deep Reinforcement Learning\n",
      "  [Spot] 5289 : Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels\n",
      "  [Spot] 5356 : Policy-Conditioned Uncertainty Sets for Robust Markov Decision Processes\n",
      "  [Spot] 5535 : Visual Goal-Conditioned Reinforcement Learning by Representation Learning\n",
      "  [Spot] 6474 : Memory Augmented Policy Optimization for Program Synthesis and Semantic Parsing\n",
      "\n",
      "Session:  D3_S2_T2 [(u'Applications/Computer Vision', 3), (u'Applications/Audio and Speech Processing', 2), (u'Applications/Image Segmentation', 1), (u'Applications/Computer Visio', 1), (u'Applications/Dialog- or Communication-Based Learning', 1), (u'Applications/Network Analysis', 1), (u'Applications/Computational Biology and Bioinformatics', 1), (u'Applications/Computational Photography', 1), (u'Applications/Privacy, Anonymity, and Security', 1), (u'Applications/Object Recognition', 1), (u'Applications/Fairness, Accountability, and Transparenc', 1)]\n",
      "  [Oral] 1026 : Discovery of Latent 3D Keypoints via End-to-end Geometric Reasoning\n",
      "  [Oral] 1143 : Learning to Reconstruct Shapes from Unseen Categories\n",
      "  [Spot]   40 : Text-Adaptive Generative Adversarial Networks: Manipulating Images with Natural Language\n",
      "  [Spot]  722 : Geometry Based Data Generation\n",
      "  [Spot]  839 : Neighbourhood Consensus Networks\n",
      "  [Spot] 1289 : Answerer in Questioner's Mind: Information Theoretic Approach to Goal-Oriented Visual Dialog\n",
      "  [Spot] 1807 : Why Is My Classifier Discriminatory?\n",
      "  [Spot] 2478 : Link Prediction Based on Graph Neural Networks\n",
      "  [Spot] 3020 : Recurrent Transformer Networks for Semantic Correspondence\n",
      "  [Spot] 3455 : A Probabilistic U-Net for Segmentation of Ambiguous Images\n",
      "  [Spot] 3666 : Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces\n",
      "  [Spot] 5104 : Deep Network for the Integrated 3D Sensing of Multiple People in Natural Images\n",
      "  [Spot] 6483 : Neural Voice Cloning with a Few Samples\n",
      "  [Spot] 6514 : A Spectral View of Adversarially Robust Features\n",
      "\n",
      "Session:  D3_S2_T3 [(u'Optimization', 7), (u'Optimization/Convex Optimization', 7)]\n",
      "  [Oral] 1147 : Smoothed analysis of the low-rank approach for smooth semidefinite programs\n",
      "  [Oral] 1446 : Optimal Algorithms for Non-Smooth Distributed Optimization in Networks\n",
      "  [Spot]  267 : (Probably) Concave Graph Matching\n",
      "  [Spot] 1881 : Convergence of Cubic Regularization for Nonconvex Optimization under KL Property\n",
      "  [Spot] 1920 : Direct Runge-Kutta Discretization Achieves Acceleration\n",
      "  [Spot] 2171 : Limited Memory Kelley's Method Converges for Composite Convex and Submodular Objectives\n",
      "  [Spot] 2440 : LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning\n",
      "  [Spot] 2665 : A Simple Proximal Stochastic Gradient Method for Nonsmooth Nonconvex Optimization\n",
      "  [Spot] 3682 : Stochastic Chebyshev Gradient Descent for Spectral Optimization\n",
      "  [Spot] 4880 : Distributed $k$-Clustering for Data with Heavy Noise\n",
      "  [Spot] 4901 : Robust Hypothesis Testing Using Wasserstein Uncertainty Sets\n",
      "  [Spot] 5129 : Wasserstein Distributionally Robust Kalman Filtering\n",
      "  [Spot] 5135 : Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization\n",
      "  [Spot] 6859 : Decentralize and Randomize: Faster Algorithm for Wasserstein Barycenters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spot_df = print_assignment(assgn_tpms_tpsa_psa_bow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper ID</th>\n",
       "      <th>Session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3826</td>\n",
       "      <td>D1_S1_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5269</td>\n",
       "      <td>D1_S1_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3213</td>\n",
       "      <td>D1_S1_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3300</td>\n",
       "      <td>D1_S1_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496</td>\n",
       "      <td>D1_S1_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6491</td>\n",
       "      <td>D1_S1_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3765</td>\n",
       "      <td>D1_S1_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4859</td>\n",
       "      <td>D1_S1_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1737</td>\n",
       "      <td>D1_S1_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5491</td>\n",
       "      <td>D1_S1_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>602</td>\n",
       "      <td>D1_S1_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5436</td>\n",
       "      <td>D1_S1_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3518</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5133</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>425</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>920</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1640</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1878</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2413</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2861</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2974</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3368</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5172</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6432</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7992</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1246</td>\n",
       "      <td>D1_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3310</td>\n",
       "      <td>D1_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1099</td>\n",
       "      <td>D1_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1146</td>\n",
       "      <td>D1_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>5535</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>6474</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1026</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1143</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>40</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>722</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>839</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1289</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1807</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2478</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>3020</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>3455</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>3666</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>5104</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>6483</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>6514</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1147</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1446</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>267</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1881</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1920</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2171</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2440</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2665</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>3682</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>4880</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>4901</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>5129</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5135</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>6859</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paper ID   Session\n",
       "0        3826  D1_S1_T1\n",
       "1        5269  D1_S1_T1\n",
       "2        3213  D1_S1_T1\n",
       "3        3300  D1_S1_T1\n",
       "4         496  D1_S1_T2\n",
       "5        6491  D1_S1_T2\n",
       "6        3765  D1_S1_T2\n",
       "7        4859  D1_S1_T2\n",
       "8        1737  D1_S1_T3\n",
       "9        5491  D1_S1_T3\n",
       "10        602  D1_S1_T3\n",
       "11       5436  D1_S1_T3\n",
       "12       3518  D1_S2_T1\n",
       "13       5133  D1_S2_T1\n",
       "14        360  D1_S2_T1\n",
       "15        425  D1_S2_T1\n",
       "16        920  D1_S2_T1\n",
       "17       1640  D1_S2_T1\n",
       "18       1878  D1_S2_T1\n",
       "19       2413  D1_S2_T1\n",
       "20       2861  D1_S2_T1\n",
       "21       2974  D1_S2_T1\n",
       "22       3368  D1_S2_T1\n",
       "23       5172  D1_S2_T1\n",
       "24       6432  D1_S2_T1\n",
       "25       7992  D1_S2_T1\n",
       "26       1246  D1_S2_T2\n",
       "27       3310  D1_S2_T2\n",
       "28       1099  D1_S2_T2\n",
       "29       1146  D1_S2_T2\n",
       "..        ...       ...\n",
       "168      5535  D3_S2_T1\n",
       "169      6474  D3_S2_T1\n",
       "170      1026  D3_S2_T2\n",
       "171      1143  D3_S2_T2\n",
       "172        40  D3_S2_T2\n",
       "173       722  D3_S2_T2\n",
       "174       839  D3_S2_T2\n",
       "175      1289  D3_S2_T2\n",
       "176      1807  D3_S2_T2\n",
       "177      2478  D3_S2_T2\n",
       "178      3020  D3_S2_T2\n",
       "179      3455  D3_S2_T2\n",
       "180      3666  D3_S2_T2\n",
       "181      5104  D3_S2_T2\n",
       "182      6483  D3_S2_T2\n",
       "183      6514  D3_S2_T2\n",
       "184      1147  D3_S2_T3\n",
       "185      1446  D3_S2_T3\n",
       "186       267  D3_S2_T3\n",
       "187      1881  D3_S2_T3\n",
       "188      1920  D3_S2_T3\n",
       "189      2171  D3_S2_T3\n",
       "190      2440  D3_S2_T3\n",
       "191      2665  D3_S2_T3\n",
       "192      3682  D3_S2_T3\n",
       "193      4880  D3_S2_T3\n",
       "194      4901  D3_S2_T3\n",
       "195      5129  D3_S2_T3\n",
       "196      5135  D3_S2_T3\n",
       "197      6859  D3_S2_T3\n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for papers with overlapping authors across parallel tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_parallel_track_conficts(assgn):\n",
    "    # group sessions by track number and order by day and session\n",
    "    T1s = sorted([g for g in assgn if groups[g][0].endswith('T1')])\n",
    "    T2s = sorted([g for g in assgn if groups[g][0].endswith('T2')])\n",
    "    clashes = {}\n",
    "    for g1, g2 in zip(T1s, T2s):        \n",
    "        session = 'Sessions: %s vs %s' % (groups[g1][0], groups[g2][0])        \n",
    "        t1data = []\n",
    "        t1_idx = groups[g1][1] + [spot_idx[i] for i in assgn[g1]]\n",
    "        for i in t1_idx:\n",
    "            record = newdf.iloc[i]\n",
    "            t1data.append((\n",
    "                record['Paper ID'],\n",
    "                record['Paper Title'],\n",
    "                set([e.lower() for e in record['Author Emails'].split(';')])\n",
    "            ))\n",
    "\n",
    "        t2data = []\n",
    "        t2_idx = groups[g2][1] + [spot_idx[i] for i in assgn[g2]]\n",
    "        for i in t2_idx:\n",
    "            record = newdf.iloc[i]\n",
    "            t2data.append((\n",
    "                record['Paper ID'],\n",
    "                record['Paper Title'],\n",
    "                set([e.lower() for e in record['Author Emails'].split(';')])\n",
    "            ))\n",
    "\n",
    "        for pid1, title1, emails1 in t1data:\n",
    "            for pid2, title2, emails2 in t2data:\n",
    "                conflicts = emails1.intersection(emails2)\n",
    "                if len(conflicts) > 0:\n",
    "                    if session not in clashes:\n",
    "                        clashes[session] = []\n",
    "                    clashes[session].append((pid1, pid2, conflicts))\n",
    "            break\n",
    "    \n",
    "    if len(clashes) > 0:\n",
    "        print clashes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_parallel_track_conficts(assgn_tpms_tpsa_psa_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper ID</th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Emails</th>\n",
       "      <th>Subject Areas</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Primary Subject Area</th>\n",
       "      <th>Top-level Primary Subject Area</th>\n",
       "      <th>bow</th>\n",
       "      <th>pid</th>\n",
       "      <th>tpms</th>\n",
       "      <th>tsne_all</th>\n",
       "      <th>tsne_tpms</th>\n",
       "      <th>Session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Efficient Algorithms for Non-convex Isotonic R...</td>\n",
       "      <td>We consider the minimization of submodular fun...</td>\n",
       "      <td>francis.bach@inria.fr</td>\n",
       "      <td>Optimization/Submodular Optimization*; Optimiz...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Optimization/Submodular Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[effici, algorithm, non, convex, isoton, regre...</td>\n",
       "      <td>29</td>\n",
       "      <td>[0.724210006, 0.547847061, 0.62121431, 0.69992...</td>\n",
       "      <td>-65.037216</td>\n",
       "      <td>43.380173</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Structure-Aware Convolutional Neural Networks</td>\n",
       "      <td>Convolutional neural networks (CNNs) are inher...</td>\n",
       "      <td>jianlong.chang@nlpr.ia.ac.cn;jie.gu@nlpr.ia.ac...</td>\n",
       "      <td>Deep Learning*; Deep Learning/CNN Architecture...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[structur, awar, convolut, neural, network, co...</td>\n",
       "      <td>33</td>\n",
       "      <td>[0.722796601, 0.7524726279999999, 0.681080612,...</td>\n",
       "      <td>-27.842775</td>\n",
       "      <td>-41.931042</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>Kalman Normalization</td>\n",
       "      <td>As an indispensable component, Batch Normaliza...</td>\n",
       "      <td>wanggrun@mail2.sysu.edu.cn;jiefengpeng@gmail.c...</td>\n",
       "      <td>Deep Learning/CNN Architectures*; Applications...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/CNN Architectures</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[kalman, normal, indispens, compon, batch, nor...</td>\n",
       "      <td>34</td>\n",
       "      <td>[0.605652029, 0.624528822, 0.5549479039999999,...</td>\n",
       "      <td>-45.000961</td>\n",
       "      <td>-22.988417</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>HOGWILD!-Gibbs can be PanAccurate</td>\n",
       "      <td>Asynchronous Gibbs sampling has been recently ...</td>\n",
       "      <td>costis@csail.mit.edu;ndikkala@mit.edu;jayanti@...</td>\n",
       "      <td>Probabilistic Methods/Distributed Inference*; ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Distributed Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[hogwild, gibb, panaccur, asynchron, gibb, sam...</td>\n",
       "      <td>37</td>\n",
       "      <td>[0.6039084920000001, 0.571028136, 0.547187392,...</td>\n",
       "      <td>-86.396667</td>\n",
       "      <td>24.022959</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>Text-Adaptive Generative Adversarial Networks:...</td>\n",
       "      <td>This paper addresses the problem of manipulati...</td>\n",
       "      <td>shnnam@yonsei.ac.kr;kim_yunji@yonsei.ac.kr;seo...</td>\n",
       "      <td>Applications/Computational Photography*; Appli...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Applications/Computational Photography</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[text, adapt, gener, adversari, network, manip...</td>\n",
       "      <td>40</td>\n",
       "      <td>[0.6074082789999999, 0.604121554, 0.5843663610...</td>\n",
       "      <td>10.959604</td>\n",
       "      <td>-44.323528</td>\n",
       "      <td>D2_S1_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59</td>\n",
       "      <td>IntroVAE: Introspective Variational Autoencode...</td>\n",
       "      <td>We present a novel introspective variational a...</td>\n",
       "      <td>huaibo.huang@cripac.ia.ac.cn;zhihang.li@nlpr.i...</td>\n",
       "      <td>Deep Learning/Generative Models*; Deep Learnin...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Generative Models</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[introva, introspect, variat, autoencod, photo...</td>\n",
       "      <td>59</td>\n",
       "      <td>[0.554898813, 0.566786583, 0.514959909, 0.5606...</td>\n",
       "      <td>-52.689449</td>\n",
       "      <td>-14.038417</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>Doubly Robust Bayesian Inference for Non-Stati...</td>\n",
       "      <td>We present the very first robust Bayesian Onli...</td>\n",
       "      <td>j.knoblauch@warwick.ac.uk;j.e.jewson@warwick.a...</td>\n",
       "      <td>Applications/Time Series Analysis*; Algorithms...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Time Series Analysis</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[doubli, robust, bayesian, infer, non, station...</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.811906661, 0.7286812490000001, 0.745909935,...</td>\n",
       "      <td>21.148312</td>\n",
       "      <td>-1.963071</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>Adapted Deep Embeddings: A Synthesis of Method...</td>\n",
       "      <td>The focus in machine learning has branched bey...</td>\n",
       "      <td>tysc7237@colorado.edu;karl.ridgeway@colorado.e...</td>\n",
       "      <td>Algorithms/Multitask and Transfer Learning*; A...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Multitask and Transfer Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[adapt, deep, embed, synthesi, method, shot, i...</td>\n",
       "      <td>75</td>\n",
       "      <td>[0.7246898359999999, 0.74860931, 0.72164041200...</td>\n",
       "      <td>57.467770</td>\n",
       "      <td>-28.714304</td>\n",
       "      <td>D1_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>Generalized Inverse Optimization through Onlin...</td>\n",
       "      <td>Inverse optimization is a powerful paradigm fo...</td>\n",
       "      <td>chaosheng@pitt.edu;yiran.chen@duke.edu;bzeng@p...</td>\n",
       "      <td>Algorithms/Online Learning*; Applications/Quan...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Online Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[gener, invers, optim, onlin, learn, invers, o...</td>\n",
       "      <td>77</td>\n",
       "      <td>[0.8553071390000001, 0.729569048, 0.771284843,...</td>\n",
       "      <td>62.712032</td>\n",
       "      <td>38.852795</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>85</td>\n",
       "      <td>An Off-policy Policy Gradient Theorem Using Em...</td>\n",
       "      <td>Policy gradient methods are widely used for co...</td>\n",
       "      <td>imani@ualberta.ca;graves@ualberta.ca;whitem@ua...</td>\n",
       "      <td>Reinforcement Learning and Planning/Reinforcem...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Reinforcement Learning and Planning/Reinforcem...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>[polici, polici, gradient, theorem, use, empha...</td>\n",
       "      <td>85</td>\n",
       "      <td>[0.5770863589999999, 0.523376441, 0.518179388,...</td>\n",
       "      <td>85.118027</td>\n",
       "      <td>6.052812</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>88</td>\n",
       "      <td>Supervised autoencoders: Improving generalizat...</td>\n",
       "      <td>Generalization performance is a central goal i...</td>\n",
       "      <td>leile@iu.edu;andnpatt@iu.edu;whitem@ualberta.ca</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learnin</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[supervis, autoencod, improv, gener, perform, ...</td>\n",
       "      <td>88</td>\n",
       "      <td>[0.7831208590000001, 0.8086628229999999, 0.745...</td>\n",
       "      <td>52.941345</td>\n",
       "      <td>-26.562601</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>92</td>\n",
       "      <td>Visual Object Networks: Image Generation with ...</td>\n",
       "      <td>Recent progress in deep generative models has ...</td>\n",
       "      <td>junyanz@mit.edu;ztzhang@mit.edu;ckzhang@mit.ed...</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[visual, object, network, imag, gener, disenta...</td>\n",
       "      <td>92</td>\n",
       "      <td>[0.622592223, 0.620137725, 0.574635252, 0.6193...</td>\n",
       "      <td>-48.542374</td>\n",
       "      <td>-46.703506</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>95</td>\n",
       "      <td>Understanding Weight Normalized Deep Neural Ne...</td>\n",
       "      <td>This paper presents a general framework for no...</td>\n",
       "      <td>xu573@purdue.edu;wangxiao@purdue.edu</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theor</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[understand, weight, normal, deep, neural, net...</td>\n",
       "      <td>95</td>\n",
       "      <td>[0.644970711, 0.6021990779999999, 0.611452154,...</td>\n",
       "      <td>-4.153590</td>\n",
       "      <td>13.390891</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>99</td>\n",
       "      <td>Learning Pipelines with Limited Data and Domai...</td>\n",
       "      <td>As machine learning becomes more widely used i...</td>\n",
       "      <td>mrinmayaster@gmail.com;avinava.dubey@gmail.com...</td>\n",
       "      <td>Applications*; Applications/Computer Vision</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[learn, pipelin, limit, data, domain, knowledg...</td>\n",
       "      <td>99</td>\n",
       "      <td>[0.825202962, 0.8357769540000001, 0.8245410609...</td>\n",
       "      <td>17.879139</td>\n",
       "      <td>-35.804531</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>102</td>\n",
       "      <td>Learning long-range spatial dependencies with ...</td>\n",
       "      <td>Progress in deep learning has spawned great su...</td>\n",
       "      <td>drew_linsley@brown.edu;junkyung_kim@brown.edu;...</td>\n",
       "      <td>Deep Learning/Biologically Plausible Deep Netw...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Biologically Plausible Deep Netw...</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[learn, long, rang, spatial, depend, horizont,...</td>\n",
       "      <td>102</td>\n",
       "      <td>[0.753889782, 0.8060686090000001, 0.7139329390...</td>\n",
       "      <td>-37.060337</td>\n",
       "      <td>-39.884235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>110</td>\n",
       "      <td>Joint Sub-bands Learning with Clique Structure...</td>\n",
       "      <td>Convolutional neural networks (CNNs) have rece...</td>\n",
       "      <td>zszhong@pku.edu.cn;tianchengshen@pku.edu.cn;ib...</td>\n",
       "      <td>Applications/Computer Vision*; Deep Learning/C...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[joint, sub, band, learn, cliqu, structur, wav...</td>\n",
       "      <td>110</td>\n",
       "      <td>[0.665462302, 0.631348907, 0.61443569, 0.65938...</td>\n",
       "      <td>5.871789</td>\n",
       "      <td>-42.454613</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>142</td>\n",
       "      <td>Fast Similarity Search via Optimal Sparse Lifting</td>\n",
       "      <td>Similarity search is a fundamental problem in ...</td>\n",
       "      <td>wyli@cuhk.edu.cn;216019005@link.cuhk.edu.cn;yi...</td>\n",
       "      <td>Algorithms/Sparse Coding and Dimensionality Ex...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Sparse Coding and Dimensionality Ex...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[fast, similar, search, via, optim, spars, lif...</td>\n",
       "      <td>142</td>\n",
       "      <td>[0.8577442009999999, 0.7920245159999999, 0.809...</td>\n",
       "      <td>51.363522</td>\n",
       "      <td>-17.461079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>145</td>\n",
       "      <td>Learning Deep Disentangled Embeddings With the...</td>\n",
       "      <td>Deep-embedding methods aim to discover represe...</td>\n",
       "      <td>karl.ridgeway@colorado.edu;mozer@colorado.edu</td>\n",
       "      <td>Algorithms/Representation Learning*; Algorithm...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[learn, deep, disentangl, embed, statist, loss...</td>\n",
       "      <td>145</td>\n",
       "      <td>[0.801685634, 0.791540459, 0.772199449, 0.8187...</td>\n",
       "      <td>54.186298</td>\n",
       "      <td>-28.578308</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>153</td>\n",
       "      <td>Geometrically Coupled Monte Carlo Sampling</td>\n",
       "      <td>Monte Carlo sampling in high-dimensional, low-...</td>\n",
       "      <td>mr504@cam.ac.uk;kchoro@google.com;chalusf3@gma...</td>\n",
       "      <td>Algorithms/Stochastic Methods*; Reinforcement ...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Stochastic Methods</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[geometr, coupl, mont, carlo, sampl, mont, car...</td>\n",
       "      <td>153</td>\n",
       "      <td>[0.796080575, 0.669703717, 0.714382987, 0.7818...</td>\n",
       "      <td>43.549530</td>\n",
       "      <td>24.121429</td>\n",
       "      <td>D2_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>175</td>\n",
       "      <td>Cooperative Holistic 3D Scene Understanding fr...</td>\n",
       "      <td>Holistic 3D indoor scene understanding involve...</td>\n",
       "      <td>huangsiyuan@ucla.edu;syqi@cs.ucla.edu;yinxuex@...</td>\n",
       "      <td>Applications/Visual Scene Analysis and Interpr...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Visual Scene Analysis and Interpr...</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[cooper, holist, 3d, scene, understand, singl,...</td>\n",
       "      <td>175</td>\n",
       "      <td>[0.635211113, 0.587038424, 0.582188994, 0.6233...</td>\n",
       "      <td>9.757609</td>\n",
       "      <td>-47.380989</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>177</td>\n",
       "      <td>An Efficient Pruning Algorithm for Robust Isot...</td>\n",
       "      <td>We study a generalization of the classic isoto...</td>\n",
       "      <td>clim9@wisc.edu</td>\n",
       "      <td>Algorithms/Regression</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Regressio</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[effici, prune, algorithm, robust, isoton, reg...</td>\n",
       "      <td>177</td>\n",
       "      <td>[0.8350809440000001, 0.641266087, 0.761110935,...</td>\n",
       "      <td>40.470722</td>\n",
       "      <td>43.279369</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>178</td>\n",
       "      <td>PAC-learning in the presence of adversaries</td>\n",
       "      <td>The existence of evasion attacks during the te...</td>\n",
       "      <td>dcullina@princeton.edu;abhagoji@princeton.edu;...</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theor</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[pac, learn, presenc, adversari, exist, evas, ...</td>\n",
       "      <td>178</td>\n",
       "      <td>[0.5843463000000001, 0.563068797, 0.533589984,...</td>\n",
       "      <td>-4.154649</td>\n",
       "      <td>-19.239223</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>182</td>\n",
       "      <td>Sparse DNNs with Improved Adversarial Robustness</td>\n",
       "      <td>Deep neural networks (DNNs) are computationall...</td>\n",
       "      <td>yiwen.guo@intel.com;pkuzc@pku.edu.cn;zcs@mail....</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Algorithm...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[spars, dnn, improv, adversari, robust, deep, ...</td>\n",
       "      <td>182</td>\n",
       "      <td>[0.666966905, 0.637015755, 0.638722607, 0.7032...</td>\n",
       "      <td>-48.874542</td>\n",
       "      <td>-19.332710</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>185</td>\n",
       "      <td>Snap ML: A Hierarchical Framework for Machine ...</td>\n",
       "      <td>We describe a new software framework for fast ...</td>\n",
       "      <td>cdu@zurich.ibm.com;tpa@zurich.ibm.com;rig@zuri...</td>\n",
       "      <td>Applications/Hardware and Systems*; Data, Comp...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Hardware and Systems</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[snap, ml, hierarch, framework, machin, learn,...</td>\n",
       "      <td>185</td>\n",
       "      <td>[0.657971973, 0.853205806, 0.618791222, 0.6497...</td>\n",
       "      <td>19.205162</td>\n",
       "      <td>-23.840919</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>186</td>\n",
       "      <td>See and Think: Disentangling Semantic Scene Co...</td>\n",
       "      <td>Semantic scene completion predicts volumetric ...</td>\n",
       "      <td>liushice@ict.ac.cn;huyu@ict.ac.cn;zengyiming@i...</td>\n",
       "      <td>Applications/Computer Vision*; Deep Learning/C...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[see, think, disentangl, semant, scene, comple...</td>\n",
       "      <td>186</td>\n",
       "      <td>[0.657856715, 0.632397676, 0.6396587229999999,...</td>\n",
       "      <td>6.809194</td>\n",
       "      <td>-47.239983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>187</td>\n",
       "      <td>Chain of Reasoning for Visual Question Answering</td>\n",
       "      <td>Reasoning plays an essential role in Visual Qu...</td>\n",
       "      <td>wuchenfei@bupt.edu.cn;liujinlai@bupt.edu.cn;xj...</td>\n",
       "      <td>Applications/Visual Question Answering*; Neuro...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Visual Question Answering</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[chain, reason, visual, question, answer, reas...</td>\n",
       "      <td>187</td>\n",
       "      <td>[0.632062365, 0.6729400529999999, 0.603445259,...</td>\n",
       "      <td>12.654006</td>\n",
       "      <td>-36.788307</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>188</td>\n",
       "      <td>Sigsoftmax: Reanalysis of the Softmax Bottleneck</td>\n",
       "      <td>Softmax is an output activation function for m...</td>\n",
       "      <td>kanai.sekitoshi@lab.ntt.co.jp;fujiwara.yasuhir...</td>\n",
       "      <td>Deep Learning*; Deep Learning/Recurrent Networ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[sigsoftmax, reanalysi, softmax, bottleneck, s...</td>\n",
       "      <td>188</td>\n",
       "      <td>[0.692489644, 0.790134204, 0.660755629, 0.7194...</td>\n",
       "      <td>-27.241320</td>\n",
       "      <td>-24.413645</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>191</td>\n",
       "      <td>Deep Non-Blind Deconvolution via Generalized L...</td>\n",
       "      <td>In this paper, we present a deep convolutional...</td>\n",
       "      <td>rwq.renwenqi@gmail.com;zhjw1988@gmail.com;fore...</td>\n",
       "      <td>Applications/Computer Vision*; Applications/De...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[deep, non, blind, deconvolut, via, gener, low...</td>\n",
       "      <td>191</td>\n",
       "      <td>[0.562258779, 0.5202836, 0.506214686, 0.550357...</td>\n",
       "      <td>5.565048</td>\n",
       "      <td>-42.852203</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>192</td>\n",
       "      <td>Probabilistic Pose Graph Optimization via Bing...</td>\n",
       "      <td>We introduce Tempered Geodesic MCMC (TG-MCMC) ...</td>\n",
       "      <td>tolga.birdal@tum.de;umut.simsekli@telecom-pari...</td>\n",
       "      <td>Applications/Computer Vision*; Applications/Ro...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[probabilist, pose, graph, optim, via, bingham...</td>\n",
       "      <td>192</td>\n",
       "      <td>[0.9113688670000001, 0.7563436379999999, 0.820...</td>\n",
       "      <td>4.842010</td>\n",
       "      <td>29.373499</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>207</td>\n",
       "      <td>MetaAnchor: Learning to Detect Objects with Cu...</td>\n",
       "      <td>We propose a novel and flexible anchor mechani...</td>\n",
       "      <td>yangt15@fudan.edu.cn;zhangxiangyu@megvii.com;l...</td>\n",
       "      <td>Applications/Object Detection</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Object Detectio</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[metaanchor, learn, detect, object, custom, an...</td>\n",
       "      <td>207</td>\n",
       "      <td>[0.620705712, 0.593533387, 0.572714624, 0.6164...</td>\n",
       "      <td>9.184333</td>\n",
       "      <td>-45.363842</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>6787</td>\n",
       "      <td>Thermostat-assisted continuously-tempered Hami...</td>\n",
       "      <td>In this paper, we propose a novel sampling met...</td>\n",
       "      <td>r.luo@cs.ucl.ac.uk;jianhong.wang.17@ucl.ac.uk;...</td>\n",
       "      <td>Probabilistic Methods/MCMC</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/MCM</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[thermostat, assist, continu, temper, hamilton...</td>\n",
       "      <td>6787</td>\n",
       "      <td>[0.646289553, 0.620857109, 0.586481252, 0.6541...</td>\n",
       "      <td>-83.440186</td>\n",
       "      <td>-3.773678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>6793</td>\n",
       "      <td>Robust Subspace Approximation in a Stream</td>\n",
       "      <td>We study robust subspace estimation in the str...</td>\n",
       "      <td>roiel@cs.cmu.edu;asevekar@andrew.cmu.edu;dwood...</td>\n",
       "      <td>Algorithms*; Algorithms/Regression</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[robust, subspac, approxim, stream, studi, rob...</td>\n",
       "      <td>6793</td>\n",
       "      <td>[0.540987701, 0.441798132, 0.49352610399999997...</td>\n",
       "      <td>36.628849</td>\n",
       "      <td>33.431755</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>6802</td>\n",
       "      <td>Mean Field for the Stochastic Blockmodel: Opti...</td>\n",
       "      <td>Variational approximation has been widely used...</td>\n",
       "      <td>soumendu041@gmail.com;purna.sarkar@austin.utex...</td>\n",
       "      <td>Probabilistic Methods/Variational Inference*; ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Variational Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[mean, field, stochast, blockmodel, optim, lan...</td>\n",
       "      <td>6802</td>\n",
       "      <td>[0.735002521, 0.627056098, 0.647996389, 0.7320...</td>\n",
       "      <td>-85.291252</td>\n",
       "      <td>23.962334</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>6832</td>\n",
       "      <td>Analysis of Krylov Subspace Solutions of  Regu...</td>\n",
       "      <td>We provide convergence rates for Krylov subspa...</td>\n",
       "      <td>ycarmon@gmail.com;jduchi@stanford.edu</td>\n",
       "      <td>Optimization/Non-Convex Optimization*; Algorit...</td>\n",
       "      <td>Oral</td>\n",
       "      <td>Optimization/Non-Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[analysi, krylov, subspac, solut, regular, non...</td>\n",
       "      <td>6832</td>\n",
       "      <td>[0.644204279, 0.46829059700000003, 0.536020003...</td>\n",
       "      <td>-60.415810</td>\n",
       "      <td>45.334076</td>\n",
       "      <td>D2_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>6836</td>\n",
       "      <td>Autoconj: Recognizing and Exploiting Conjugacy...</td>\n",
       "      <td>Deriving conditional and marginal distribution...</td>\n",
       "      <td>mdhoffma@cs.princeton.edu;mattjj@google.com;tr...</td>\n",
       "      <td>Probabilistic Methods/Graphical Models*; Data,...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Graphical Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[autoconj, recogn, exploit, conjugaci, without...</td>\n",
       "      <td>6836</td>\n",
       "      <td>[0.644937403, 0.646330124, 0.606580474, 0.6317...</td>\n",
       "      <td>-88.951286</td>\n",
       "      <td>-2.032948</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>6839</td>\n",
       "      <td>DropBlock: A regularization method for convolu...</td>\n",
       "      <td>Deep neural networks often work well when they...</td>\n",
       "      <td>golnazg@google.com;tsungyi@google.com;qvl@goog...</td>\n",
       "      <td>Theory/Regularization*; Deep Learning/CNN Arch...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Regularization</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[dropblock, regular, method, convolut, network...</td>\n",
       "      <td>6839</td>\n",
       "      <td>[0.602325926, 0.709435875, 0.611376699, 0.6140...</td>\n",
       "      <td>-13.005722</td>\n",
       "      <td>-40.898853</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>6843</td>\n",
       "      <td>Forward Modeling for Partial Observation Strat...</td>\n",
       "      <td>We formulate the problem of \\emph{defogging} a...</td>\n",
       "      <td>gab@fb.com;zlin@fb.com;jgehring@fb.com;dangant...</td>\n",
       "      <td>Applications/Game Playing</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Game Playin</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[forward, model, partial, observ, strategi, ga...</td>\n",
       "      <td>6843</td>\n",
       "      <td>[0.64940197, 0.696797065, 0.612499372, 0.66309...</td>\n",
       "      <td>13.244852</td>\n",
       "      <td>-31.995758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>6847</td>\n",
       "      <td>With Friends Like These, Who Needs Adversaries?</td>\n",
       "      <td>The vulnerability of deep networks to adversar...</td>\n",
       "      <td>sjetley@robots.ox.ac.uk;nicklord@robots.ox.ac....</td>\n",
       "      <td>Deep Learning*; Algorithms/Classification; Alg...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[friend, like, need, adversari, vulner, deep, ...</td>\n",
       "      <td>6847</td>\n",
       "      <td>[0.596239485, 0.552854089, 0.56523045, 0.61261...</td>\n",
       "      <td>-28.122467</td>\n",
       "      <td>-20.176826</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>6859</td>\n",
       "      <td>Decentralize and Randomize: Faster Algorithm f...</td>\n",
       "      <td>We study the problem of decentralized distribu...</td>\n",
       "      <td>pavel.dvurechensky@gmail.com;darina.dvinskikh@...</td>\n",
       "      <td>Optimization/Convex Optimization*; Algorithms/...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization/Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[decentr, random, faster, algorithm, wasserste...</td>\n",
       "      <td>6859</td>\n",
       "      <td>[0.649590907, 0.572511066, 0.579816594, 0.6330...</td>\n",
       "      <td>-67.124580</td>\n",
       "      <td>29.979273</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>6863</td>\n",
       "      <td>Joint Autoregressive and Hierarchical Priors f...</td>\n",
       "      <td>Recent models for learned image compression ar...</td>\n",
       "      <td>dminnen@google.com;jballe@google.com;gtoderici...</td>\n",
       "      <td>Algorithms/Representation Learning*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[joint, autoregress, hierarch, prior, learn, i...</td>\n",
       "      <td>6863</td>\n",
       "      <td>[0.5645583710000001, 0.599846334, 0.522823875,...</td>\n",
       "      <td>54.194683</td>\n",
       "      <td>-14.596280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>6874</td>\n",
       "      <td>Learning Temporal Point Processes via Reinforc...</td>\n",
       "      <td>Many real world problems from sustainability, ...</td>\n",
       "      <td>sli370@gatech.edu;benjaminforever@sjtu.edu.cn;...</td>\n",
       "      <td>Applications/Time Series Analysis</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Applications/Time Series Analysi</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[learn, tempor, point, process, via, reinforc,...</td>\n",
       "      <td>6874</td>\n",
       "      <td>[0.6848055690000001, 0.606161123, 0.618028853,...</td>\n",
       "      <td>22.287842</td>\n",
       "      <td>6.262251</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>6882</td>\n",
       "      <td>Bias and Generalization in Deep Generative Mod...</td>\n",
       "      <td>In high dimensional settings, density estimati...</td>\n",
       "      <td>sjzhao@stanford.edu;hyren@cs.stanford.edu;xfyu...</td>\n",
       "      <td>Deep Learning/Generative Models*; Deep Learnin...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning/Generative Models</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[bia, gener, deep, gener, model, empir, studi,...</td>\n",
       "      <td>6882</td>\n",
       "      <td>[0.825245676, 0.77820804, 0.764052464, 0.83451...</td>\n",
       "      <td>-52.453613</td>\n",
       "      <td>-39.021587</td>\n",
       "      <td>D1_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>6892</td>\n",
       "      <td>Fast and Effective Robustness Certification</td>\n",
       "      <td>We present a new method and system for certify...</td>\n",
       "      <td>gsingh@inf.ethz.ch;timon.gehr@inf.ethz.ch;matt...</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[fast, effect, robust, certif, present, new, m...</td>\n",
       "      <td>6892</td>\n",
       "      <td>[0.656920721, 0.7048807429999999, 0.624150393,...</td>\n",
       "      <td>-48.894798</td>\n",
       "      <td>-19.396210</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>6901</td>\n",
       "      <td>Support Recovery for Orthogonal Matching Pursu...</td>\n",
       "      <td>This paper studies the problem of sparse regre...</td>\n",
       "      <td>raghavsomani1995@gmail.com;chiragpvg@gmail.com...</td>\n",
       "      <td>Algorithms/Sparsity and Compressed Sensing*; A...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Sparsity and Compressed Sensing</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[support, recoveri, orthogon, match, pursuit, ...</td>\n",
       "      <td>6901</td>\n",
       "      <td>[0.6322439089999999, 0.5179587760000001, 0.563...</td>\n",
       "      <td>41.317558</td>\n",
       "      <td>32.567497</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>6905</td>\n",
       "      <td>Differentially Private Change-Point Detection</td>\n",
       "      <td>The change-point detection problem seeks to id...</td>\n",
       "      <td>krehbiel@richmond.edu;rachelc@gatech.edu;wanro...</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security*...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[differenti, privat, chang, point, detect, cha...</td>\n",
       "      <td>6905</td>\n",
       "      <td>[0.6977355690000001, 0.557927934, 0.63827413, ...</td>\n",
       "      <td>31.028465</td>\n",
       "      <td>36.121666</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>6913</td>\n",
       "      <td>Multi-value Rule Sets for Interpretable Classi...</td>\n",
       "      <td>We present Multi-value Rule Sets (MRS) for int...</td>\n",
       "      <td>tong-wang@uiowa.edu</td>\n",
       "      <td>Probabilistic Methods/Hierarchical Models*; Ap...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Hierarchical Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[multi, valu, rule, set, interpret, classif, f...</td>\n",
       "      <td>6913</td>\n",
       "      <td>[0.823699588, 0.7256162290000001, 0.770973646,...</td>\n",
       "      <td>-87.882576</td>\n",
       "      <td>17.551443</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6921</td>\n",
       "      <td>Domain Adaptation by Using Causal Inference to...</td>\n",
       "      <td>An important goal common to domain adaptation ...</td>\n",
       "      <td>sara.magliacane@gmail.com;thijsvanommen@gmail....</td>\n",
       "      <td>Probabilistic Methods/Causal Inference*; Deep ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Causal Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[domain, adapt, use, causal, infer, predict, i...</td>\n",
       "      <td>6921</td>\n",
       "      <td>[0.534160482, 0.482813768, 0.514349219, 0.5274...</td>\n",
       "      <td>-92.187416</td>\n",
       "      <td>15.178188</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>6923</td>\n",
       "      <td>Smoothed Analysis of Discrete Tensor Decomposi...</td>\n",
       "      <td>We analyze linear independence of rank one ten...</td>\n",
       "      <td>anari.nima@gmail.com;costis@csail.mit.edu;maas...</td>\n",
       "      <td>Theory*; Algorithms/Components Analysis (e.g.,...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[smooth, analysi, discret, tensor, decomposit,...</td>\n",
       "      <td>6923</td>\n",
       "      <td>[0.693092713, 0.629186489, 0.656472765, 0.7012...</td>\n",
       "      <td>-10.954827</td>\n",
       "      <td>21.518019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>6961</td>\n",
       "      <td>MixLasso: Generalized Mixed Regression via Con...</td>\n",
       "      <td>We consider a generalization of mixed regressi...</td>\n",
       "      <td>eyan@cs.cmu.edu;b01902065@ntu.edu.tw;kaizhong8...</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Optimizatio</td>\n",
       "      <td>Optimizatio</td>\n",
       "      <td>[mixlasso, gener, mix, regress, via, convex, a...</td>\n",
       "      <td>6961</td>\n",
       "      <td>[0.791815187, 0.657667486, 0.70105964, 0.77798...</td>\n",
       "      <td>-3.057512</td>\n",
       "      <td>30.973089</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>6968</td>\n",
       "      <td>Semidefinite relaxations for certifying robust...</td>\n",
       "      <td>Research on adversarial examples are evolved i...</td>\n",
       "      <td>aditir1994@gmail.com;jacob.steinhardt@gmail.co...</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Securit</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[semidefinit, relax, certifi, robust, adversar...</td>\n",
       "      <td>6968</td>\n",
       "      <td>[0.612903855, 0.584632164, 0.580678234, 0.6383...</td>\n",
       "      <td>29.588923</td>\n",
       "      <td>-18.780851</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>6972</td>\n",
       "      <td>Removing Hidden Confounding by Experimental Gr...</td>\n",
       "      <td>Observational data is being increasingly used ...</td>\n",
       "      <td>kallus@cornell.edu;apm470@nyu.edu;urishalit@te...</td>\n",
       "      <td>Probabilistic Methods/Causal Inference*; Algor...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Probabilistic Methods/Causal Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[remov, hidden, confound, experiment, ground, ...</td>\n",
       "      <td>6972</td>\n",
       "      <td>[0.586181571, 0.490689461, 0.549189971, 0.5911...</td>\n",
       "      <td>-92.203499</td>\n",
       "      <td>15.671731</td>\n",
       "      <td>D3_S1_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>6978</td>\n",
       "      <td>Topkapi: Parallel and Fast Sketches for Findin...</td>\n",
       "      <td>Identifying the top-K frequent items is one of...</td>\n",
       "      <td>ankush@gatech.edu;cary.jiang@rice.edu;anshumal...</td>\n",
       "      <td>Applications/Web Applications and Internet Dat...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Web Applications and Internet Data</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[topkapi, parallel, fast, sketch, find, top, f...</td>\n",
       "      <td>6978</td>\n",
       "      <td>[0.672761353, 0.6915534390000001, 0.673524338,...</td>\n",
       "      <td>26.572653</td>\n",
       "      <td>19.820202</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>7985</td>\n",
       "      <td>Contrastive Learning from Pairwise Measurements</td>\n",
       "      <td>Learning from pairwise measurements naturally ...</td>\n",
       "      <td>yichen2016@u.northwestern.edu;zy6@princeton.ed...</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[contrast, learn, pairwis, measur, learn, pair...</td>\n",
       "      <td>7985</td>\n",
       "      <td>[0.801794205, 0.6445370810000001, 0.70768539, ...</td>\n",
       "      <td>42.427158</td>\n",
       "      <td>25.685112</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>7992</td>\n",
       "      <td>Point process latent variable models of freely...</td>\n",
       "      <td>A fundamental goal of systems neuroscience is ...</td>\n",
       "      <td>as4529@columbia.edu;scott.linderman@columbia.e...</td>\n",
       "      <td>Probabilistic Methods/Latent Variable Models*;...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Probabilistic Methods/Latent Variable Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[point, process, latent, variabl, model, freel...</td>\n",
       "      <td>7992</td>\n",
       "      <td>[0.78844959, 0.730344946, 0.7138572390000001, ...</td>\n",
       "      <td>-80.002975</td>\n",
       "      <td>-5.024580</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>7994</td>\n",
       "      <td>Computationally and Statistically Efficient Le...</td>\n",
       "      <td>Causal discovery from empirical data is a fund...</td>\n",
       "      <td>kbellome@purdue.edu;jhonorio@purdue.edu</td>\n",
       "      <td>Theory/Learning Theory*; Probabilistic Methods...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[comput, statist, effici, learn, bay, net, use...</td>\n",
       "      <td>7994</td>\n",
       "      <td>[0.442452024, 0.376913364, 0.45425219, 0.45383...</td>\n",
       "      <td>-0.688502</td>\n",
       "      <td>15.611752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>7997</td>\n",
       "      <td>Sparse PCA from Sparse Linear Regression</td>\n",
       "      <td>Sparse Principal Component Analysis (SPCA) and...</td>\n",
       "      <td>guy@mit.edu;sp765@mit.edu;mpersu@mit.edu</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[spars, pca, spars, linear, regress, spars, pr...</td>\n",
       "      <td>7997</td>\n",
       "      <td>[0.755127242, 0.609168548, 0.665014251, 0.7336...</td>\n",
       "      <td>42.023003</td>\n",
       "      <td>32.024750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>8002</td>\n",
       "      <td>Sequential Data Classification for Resource-co...</td>\n",
       "      <td>We study the problem of fast and efficient cla...</td>\n",
       "      <td>t-dodenn@microsoft.com;chiragramdas@gmail.com;...</td>\n",
       "      <td>Deep Learning/Efficient Inference Methods*; De...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Efficient Inference Methods</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[sequenti, data, classif, resourc, constrain, ...</td>\n",
       "      <td>8002</td>\n",
       "      <td>[0.849686171, 0.9341852970000001, 0.7916773859...</td>\n",
       "      <td>-39.611614</td>\n",
       "      <td>-27.079840</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>8009</td>\n",
       "      <td>Transfer of Deep Reactive Policies for MDP Pla...</td>\n",
       "      <td>Domain-independent probabilistic planners inpu...</td>\n",
       "      <td>quantum.computing96@gmail.com;sankalp2621998@g...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Reinforcement Learning and Plannin</td>\n",
       "      <td>Reinforcement Learning and Plannin</td>\n",
       "      <td>[transfer, deep, reactiv, polici, mdp, plan, d...</td>\n",
       "      <td>8009</td>\n",
       "      <td>[0.7646644690000001, 0.7638223829999999, 0.729...</td>\n",
       "      <td>78.536331</td>\n",
       "      <td>3.035766</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>8034</td>\n",
       "      <td>The Price of Fair PCA: One Extra dimension</td>\n",
       "      <td>In this paper, we investigate the possibility ...</td>\n",
       "      <td>s.samadi@gmail.com;tao@gatech.edu;jamiemor@cis...</td>\n",
       "      <td>Applications/Fairness, Accountability, and Tra...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Fairness, Accountability, and Tra...</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[price, fair, pca, one, extra, dimens, thi, pa...</td>\n",
       "      <td>8034</td>\n",
       "      <td>[0.7302362170000001, 0.631884585, 0.691013077,...</td>\n",
       "      <td>25.288885</td>\n",
       "      <td>27.855110</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>8035</td>\n",
       "      <td>GroupReduce: Block-Wise Low-Rank Approximation...</td>\n",
       "      <td>Model compression is essential for serving lar...</td>\n",
       "      <td>phpchen@ucdavis.edu;sisidaisy@google.com;liyan...</td>\n",
       "      <td>Applications/Natural Language Processing</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Natural Language Processin</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[groupreduc, block, wise, low, rank, approxim,...</td>\n",
       "      <td>8035</td>\n",
       "      <td>[0.7068314809999999, 0.8144392220000001, 0.691...</td>\n",
       "      <td>16.285067</td>\n",
       "      <td>-24.585033</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Paper ID                                        Paper Title  \\\n",
       "0           29  Efficient Algorithms for Non-convex Isotonic R...   \n",
       "1           33      Structure-Aware Convolutional Neural Networks   \n",
       "2           34                               Kalman Normalization   \n",
       "3           37                  HOGWILD!-Gibbs can be PanAccurate   \n",
       "4           40  Text-Adaptive Generative Adversarial Networks:...   \n",
       "5           59  IntroVAE: Introspective Variational Autoencode...   \n",
       "6           68  Doubly Robust Bayesian Inference for Non-Stati...   \n",
       "7           75  Adapted Deep Embeddings: A Synthesis of Method...   \n",
       "8           77  Generalized Inverse Optimization through Onlin...   \n",
       "9           85  An Off-policy Policy Gradient Theorem Using Em...   \n",
       "10          88  Supervised autoencoders: Improving generalizat...   \n",
       "11          92  Visual Object Networks: Image Generation with ...   \n",
       "12          95  Understanding Weight Normalized Deep Neural Ne...   \n",
       "13          99  Learning Pipelines with Limited Data and Domai...   \n",
       "14         102  Learning long-range spatial dependencies with ...   \n",
       "15         110  Joint Sub-bands Learning with Clique Structure...   \n",
       "16         142  Fast Similarity Search via Optimal Sparse Lifting   \n",
       "17         145  Learning Deep Disentangled Embeddings With the...   \n",
       "18         153         Geometrically Coupled Monte Carlo Sampling   \n",
       "19         175  Cooperative Holistic 3D Scene Understanding fr...   \n",
       "20         177  An Efficient Pruning Algorithm for Robust Isot...   \n",
       "21         178        PAC-learning in the presence of adversaries   \n",
       "22         182   Sparse DNNs with Improved Adversarial Robustness   \n",
       "23         185  Snap ML: A Hierarchical Framework for Machine ...   \n",
       "24         186  See and Think: Disentangling Semantic Scene Co...   \n",
       "25         187   Chain of Reasoning for Visual Question Answering   \n",
       "26         188   Sigsoftmax: Reanalysis of the Softmax Bottleneck   \n",
       "27         191  Deep Non-Blind Deconvolution via Generalized L...   \n",
       "28         192  Probabilistic Pose Graph Optimization via Bing...   \n",
       "29         207  MetaAnchor: Learning to Detect Objects with Cu...   \n",
       "...        ...                                                ...   \n",
       "982       6787  Thermostat-assisted continuously-tempered Hami...   \n",
       "983       6793          Robust Subspace Approximation in a Stream   \n",
       "984       6802  Mean Field for the Stochastic Blockmodel: Opti...   \n",
       "985       6832  Analysis of Krylov Subspace Solutions of  Regu...   \n",
       "986       6836  Autoconj: Recognizing and Exploiting Conjugacy...   \n",
       "987       6839  DropBlock: A regularization method for convolu...   \n",
       "988       6843  Forward Modeling for Partial Observation Strat...   \n",
       "989       6847    With Friends Like These, Who Needs Adversaries?   \n",
       "990       6859  Decentralize and Randomize: Faster Algorithm f...   \n",
       "991       6863  Joint Autoregressive and Hierarchical Priors f...   \n",
       "992       6874  Learning Temporal Point Processes via Reinforc...   \n",
       "993       6882  Bias and Generalization in Deep Generative Mod...   \n",
       "994       6892        Fast and Effective Robustness Certification   \n",
       "995       6901  Support Recovery for Orthogonal Matching Pursu...   \n",
       "996       6905      Differentially Private Change-Point Detection   \n",
       "997       6913  Multi-value Rule Sets for Interpretable Classi...   \n",
       "998       6921  Domain Adaptation by Using Causal Inference to...   \n",
       "999       6923  Smoothed Analysis of Discrete Tensor Decomposi...   \n",
       "1000      6961  MixLasso: Generalized Mixed Regression via Con...   \n",
       "1001      6968  Semidefinite relaxations for certifying robust...   \n",
       "1002      6972  Removing Hidden Confounding by Experimental Gr...   \n",
       "1003      6978  Topkapi: Parallel and Fast Sketches for Findin...   \n",
       "1004      7985    Contrastive Learning from Pairwise Measurements   \n",
       "1005      7992  Point process latent variable models of freely...   \n",
       "1006      7994  Computationally and Statistically Efficient Le...   \n",
       "1007      7997           Sparse PCA from Sparse Linear Regression   \n",
       "1008      8002  Sequential Data Classification for Resource-co...   \n",
       "1009      8009  Transfer of Deep Reactive Policies for MDP Pla...   \n",
       "1010      8034         The Price of Fair PCA: One Extra dimension   \n",
       "1011      8035  GroupReduce: Block-Wise Low-Rank Approximation...   \n",
       "\n",
       "                                               Abstract  \\\n",
       "0     We consider the minimization of submodular fun...   \n",
       "1     Convolutional neural networks (CNNs) are inher...   \n",
       "2     As an indispensable component, Batch Normaliza...   \n",
       "3     Asynchronous Gibbs sampling has been recently ...   \n",
       "4     This paper addresses the problem of manipulati...   \n",
       "5     We present a novel introspective variational a...   \n",
       "6     We present the very first robust Bayesian Onli...   \n",
       "7     The focus in machine learning has branched bey...   \n",
       "8     Inverse optimization is a powerful paradigm fo...   \n",
       "9     Policy gradient methods are widely used for co...   \n",
       "10    Generalization performance is a central goal i...   \n",
       "11    Recent progress in deep generative models has ...   \n",
       "12    This paper presents a general framework for no...   \n",
       "13    As machine learning becomes more widely used i...   \n",
       "14    Progress in deep learning has spawned great su...   \n",
       "15    Convolutional neural networks (CNNs) have rece...   \n",
       "16    Similarity search is a fundamental problem in ...   \n",
       "17    Deep-embedding methods aim to discover represe...   \n",
       "18    Monte Carlo sampling in high-dimensional, low-...   \n",
       "19    Holistic 3D indoor scene understanding involve...   \n",
       "20    We study a generalization of the classic isoto...   \n",
       "21    The existence of evasion attacks during the te...   \n",
       "22    Deep neural networks (DNNs) are computationall...   \n",
       "23    We describe a new software framework for fast ...   \n",
       "24    Semantic scene completion predicts volumetric ...   \n",
       "25    Reasoning plays an essential role in Visual Qu...   \n",
       "26    Softmax is an output activation function for m...   \n",
       "27    In this paper, we present a deep convolutional...   \n",
       "28    We introduce Tempered Geodesic MCMC (TG-MCMC) ...   \n",
       "29    We propose a novel and flexible anchor mechani...   \n",
       "...                                                 ...   \n",
       "982   In this paper, we propose a novel sampling met...   \n",
       "983   We study robust subspace estimation in the str...   \n",
       "984   Variational approximation has been widely used...   \n",
       "985   We provide convergence rates for Krylov subspa...   \n",
       "986   Deriving conditional and marginal distribution...   \n",
       "987   Deep neural networks often work well when they...   \n",
       "988   We formulate the problem of \\emph{defogging} a...   \n",
       "989   The vulnerability of deep networks to adversar...   \n",
       "990   We study the problem of decentralized distribu...   \n",
       "991   Recent models for learned image compression ar...   \n",
       "992   Many real world problems from sustainability, ...   \n",
       "993   In high dimensional settings, density estimati...   \n",
       "994   We present a new method and system for certify...   \n",
       "995   This paper studies the problem of sparse regre...   \n",
       "996   The change-point detection problem seeks to id...   \n",
       "997   We present Multi-value Rule Sets (MRS) for int...   \n",
       "998   An important goal common to domain adaptation ...   \n",
       "999   We analyze linear independence of rank one ten...   \n",
       "1000  We consider a generalization of mixed regressi...   \n",
       "1001  Research on adversarial examples are evolved i...   \n",
       "1002  Observational data is being increasingly used ...   \n",
       "1003  Identifying the top-K frequent items is one of...   \n",
       "1004  Learning from pairwise measurements naturally ...   \n",
       "1005  A fundamental goal of systems neuroscience is ...   \n",
       "1006  Causal discovery from empirical data is a fund...   \n",
       "1007  Sparse Principal Component Analysis (SPCA) and...   \n",
       "1008  We study the problem of fast and efficient cla...   \n",
       "1009  Domain-independent probabilistic planners inpu...   \n",
       "1010  In this paper, we investigate the possibility ...   \n",
       "1011  Model compression is essential for serving lar...   \n",
       "\n",
       "                                          Author Emails  \\\n",
       "0                                 francis.bach@inria.fr   \n",
       "1     jianlong.chang@nlpr.ia.ac.cn;jie.gu@nlpr.ia.ac...   \n",
       "2     wanggrun@mail2.sysu.edu.cn;jiefengpeng@gmail.c...   \n",
       "3     costis@csail.mit.edu;ndikkala@mit.edu;jayanti@...   \n",
       "4     shnnam@yonsei.ac.kr;kim_yunji@yonsei.ac.kr;seo...   \n",
       "5     huaibo.huang@cripac.ia.ac.cn;zhihang.li@nlpr.i...   \n",
       "6     j.knoblauch@warwick.ac.uk;j.e.jewson@warwick.a...   \n",
       "7     tysc7237@colorado.edu;karl.ridgeway@colorado.e...   \n",
       "8     chaosheng@pitt.edu;yiran.chen@duke.edu;bzeng@p...   \n",
       "9     imani@ualberta.ca;graves@ualberta.ca;whitem@ua...   \n",
       "10      leile@iu.edu;andnpatt@iu.edu;whitem@ualberta.ca   \n",
       "11    junyanz@mit.edu;ztzhang@mit.edu;ckzhang@mit.ed...   \n",
       "12                 xu573@purdue.edu;wangxiao@purdue.edu   \n",
       "13    mrinmayaster@gmail.com;avinava.dubey@gmail.com...   \n",
       "14    drew_linsley@brown.edu;junkyung_kim@brown.edu;...   \n",
       "15    zszhong@pku.edu.cn;tianchengshen@pku.edu.cn;ib...   \n",
       "16    wyli@cuhk.edu.cn;216019005@link.cuhk.edu.cn;yi...   \n",
       "17        karl.ridgeway@colorado.edu;mozer@colorado.edu   \n",
       "18    mr504@cam.ac.uk;kchoro@google.com;chalusf3@gma...   \n",
       "19    huangsiyuan@ucla.edu;syqi@cs.ucla.edu;yinxuex@...   \n",
       "20                                       clim9@wisc.edu   \n",
       "21    dcullina@princeton.edu;abhagoji@princeton.edu;...   \n",
       "22    yiwen.guo@intel.com;pkuzc@pku.edu.cn;zcs@mail....   \n",
       "23    cdu@zurich.ibm.com;tpa@zurich.ibm.com;rig@zuri...   \n",
       "24    liushice@ict.ac.cn;huyu@ict.ac.cn;zengyiming@i...   \n",
       "25    wuchenfei@bupt.edu.cn;liujinlai@bupt.edu.cn;xj...   \n",
       "26    kanai.sekitoshi@lab.ntt.co.jp;fujiwara.yasuhir...   \n",
       "27    rwq.renwenqi@gmail.com;zhjw1988@gmail.com;fore...   \n",
       "28    tolga.birdal@tum.de;umut.simsekli@telecom-pari...   \n",
       "29    yangt15@fudan.edu.cn;zhangxiangyu@megvii.com;l...   \n",
       "...                                                 ...   \n",
       "982   r.luo@cs.ucl.ac.uk;jianhong.wang.17@ucl.ac.uk;...   \n",
       "983   roiel@cs.cmu.edu;asevekar@andrew.cmu.edu;dwood...   \n",
       "984   soumendu041@gmail.com;purna.sarkar@austin.utex...   \n",
       "985               ycarmon@gmail.com;jduchi@stanford.edu   \n",
       "986   mdhoffma@cs.princeton.edu;mattjj@google.com;tr...   \n",
       "987   golnazg@google.com;tsungyi@google.com;qvl@goog...   \n",
       "988   gab@fb.com;zlin@fb.com;jgehring@fb.com;dangant...   \n",
       "989   sjetley@robots.ox.ac.uk;nicklord@robots.ox.ac....   \n",
       "990   pavel.dvurechensky@gmail.com;darina.dvinskikh@...   \n",
       "991   dminnen@google.com;jballe@google.com;gtoderici...   \n",
       "992   sli370@gatech.edu;benjaminforever@sjtu.edu.cn;...   \n",
       "993   sjzhao@stanford.edu;hyren@cs.stanford.edu;xfyu...   \n",
       "994   gsingh@inf.ethz.ch;timon.gehr@inf.ethz.ch;matt...   \n",
       "995   raghavsomani1995@gmail.com;chiragpvg@gmail.com...   \n",
       "996   krehbiel@richmond.edu;rachelc@gatech.edu;wanro...   \n",
       "997                                 tong-wang@uiowa.edu   \n",
       "998   sara.magliacane@gmail.com;thijsvanommen@gmail....   \n",
       "999   anari.nima@gmail.com;costis@csail.mit.edu;maas...   \n",
       "1000  eyan@cs.cmu.edu;b01902065@ntu.edu.tw;kaizhong8...   \n",
       "1001  aditir1994@gmail.com;jacob.steinhardt@gmail.co...   \n",
       "1002  kallus@cornell.edu;apm470@nyu.edu;urishalit@te...   \n",
       "1003  ankush@gatech.edu;cary.jiang@rice.edu;anshumal...   \n",
       "1004  yichen2016@u.northwestern.edu;zy6@princeton.ed...   \n",
       "1005  as4529@columbia.edu;scott.linderman@columbia.e...   \n",
       "1006            kbellome@purdue.edu;jhonorio@purdue.edu   \n",
       "1007           guy@mit.edu;sp765@mit.edu;mpersu@mit.edu   \n",
       "1008  t-dodenn@microsoft.com;chiragramdas@gmail.com;...   \n",
       "1009  quantum.computing96@gmail.com;sankalp2621998@g...   \n",
       "1010  s.samadi@gmail.com;tao@gatech.edu;jamiemor@cis...   \n",
       "1011  phpchen@ucdavis.edu;sisidaisy@google.com;liyan...   \n",
       "\n",
       "                                          Subject Areas   Decision  \\\n",
       "0     Optimization/Submodular Optimization*; Optimiz...     Poster   \n",
       "1     Deep Learning*; Deep Learning/CNN Architecture...     Poster   \n",
       "2     Deep Learning/CNN Architectures*; Applications...     Poster   \n",
       "3     Probabilistic Methods/Distributed Inference*; ...     Poster   \n",
       "4     Applications/Computational Photography*; Appli...  Spotlight   \n",
       "5     Deep Learning/Generative Models*; Deep Learnin...     Poster   \n",
       "6     Applications/Time Series Analysis*; Algorithms...     Poster   \n",
       "7     Algorithms/Multitask and Transfer Learning*; A...  Spotlight   \n",
       "8     Algorithms/Online Learning*; Applications/Quan...     Poster   \n",
       "9     Reinforcement Learning and Planning/Reinforcem...     Poster   \n",
       "10                   Algorithms/Representation Learning     Poster   \n",
       "11    Deep Learning/Adversarial Networks*; Applicati...     Poster   \n",
       "12                               Theory/Learning Theory     Poster   \n",
       "13          Applications*; Applications/Computer Vision     Poster   \n",
       "14    Deep Learning/Biologically Plausible Deep Netw...     Poster   \n",
       "15    Applications/Computer Vision*; Deep Learning/C...     Poster   \n",
       "16    Algorithms/Sparse Coding and Dimensionality Ex...     Poster   \n",
       "17    Algorithms/Representation Learning*; Algorithm...     Poster   \n",
       "18    Algorithms/Stochastic Methods*; Reinforcement ...  Spotlight   \n",
       "19    Applications/Visual Scene Analysis and Interpr...     Poster   \n",
       "20                                Algorithms/Regression     Poster   \n",
       "21                               Theory/Learning Theory     Poster   \n",
       "22    Deep Learning/Adversarial Networks*; Algorithm...     Poster   \n",
       "23    Applications/Hardware and Systems*; Data, Comp...     Poster   \n",
       "24    Applications/Computer Vision*; Deep Learning/C...     Poster   \n",
       "25    Applications/Visual Question Answering*; Neuro...     Poster   \n",
       "26    Deep Learning*; Deep Learning/Recurrent Networ...     Poster   \n",
       "27    Applications/Computer Vision*; Applications/De...     Poster   \n",
       "28    Applications/Computer Vision*; Applications/Ro...     Poster   \n",
       "29                        Applications/Object Detection     Poster   \n",
       "...                                                 ...        ...   \n",
       "982                          Probabilistic Methods/MCMC     Poster   \n",
       "983                  Algorithms*; Algorithms/Regression  Spotlight   \n",
       "984   Probabilistic Methods/Variational Inference*; ...     Poster   \n",
       "985   Optimization/Non-Convex Optimization*; Algorit...       Oral   \n",
       "986   Probabilistic Methods/Graphical Models*; Data,...     Poster   \n",
       "987   Theory/Regularization*; Deep Learning/CNN Arch...     Poster   \n",
       "988                           Applications/Game Playing     Poster   \n",
       "989   Deep Learning*; Algorithms/Classification; Alg...     Poster   \n",
       "990   Optimization/Convex Optimization*; Algorithms/...  Spotlight   \n",
       "991   Algorithms/Representation Learning*; Applicati...     Poster   \n",
       "992                   Applications/Time Series Analysis  Spotlight   \n",
       "993   Deep Learning/Generative Models*; Deep Learnin...  Spotlight   \n",
       "994   Deep Learning/Adversarial Networks*; Applicati...     Poster   \n",
       "995   Algorithms/Sparsity and Compressed Sensing*; A...  Spotlight   \n",
       "996   Applications/Privacy, Anonymity, and Security*...     Poster   \n",
       "997   Probabilistic Methods/Hierarchical Models*; Ap...     Poster   \n",
       "998   Probabilistic Methods/Causal Inference*; Deep ...     Poster   \n",
       "999   Theory*; Algorithms/Components Analysis (e.g.,...     Poster   \n",
       "1000                                       Optimization     Poster   \n",
       "1001      Applications/Privacy, Anonymity, and Security     Poster   \n",
       "1002  Probabilistic Methods/Causal Inference*; Algor...  Spotlight   \n",
       "1003  Applications/Web Applications and Internet Dat...     Poster   \n",
       "1004  Algorithms/Components Analysis (e.g., CCA, ICA...     Poster   \n",
       "1005  Probabilistic Methods/Latent Variable Models*;...  Spotlight   \n",
       "1006  Theory/Learning Theory*; Probabilistic Methods...     Poster   \n",
       "1007  Algorithms/Components Analysis (e.g., CCA, ICA...     Poster   \n",
       "1008  Deep Learning/Efficient Inference Methods*; De...     Poster   \n",
       "1009                Reinforcement Learning and Planning     Poster   \n",
       "1010  Applications/Fairness, Accountability, and Tra...     Poster   \n",
       "1011           Applications/Natural Language Processing     Poster   \n",
       "\n",
       "                                   Primary Subject Area  \\\n",
       "0                  Optimization/Submodular Optimization   \n",
       "1                                         Deep Learning   \n",
       "2                       Deep Learning/CNN Architectures   \n",
       "3           Probabilistic Methods/Distributed Inference   \n",
       "4                Applications/Computational Photography   \n",
       "5                       Deep Learning/Generative Models   \n",
       "6                     Applications/Time Series Analysis   \n",
       "7            Algorithms/Multitask and Transfer Learning   \n",
       "8                            Algorithms/Online Learning   \n",
       "9     Reinforcement Learning and Planning/Reinforcem...   \n",
       "10                    Algorithms/Representation Learnin   \n",
       "11                   Deep Learning/Adversarial Networks   \n",
       "12                                Theory/Learning Theor   \n",
       "13                                         Applications   \n",
       "14    Deep Learning/Biologically Plausible Deep Netw...   \n",
       "15                         Applications/Computer Vision   \n",
       "16    Algorithms/Sparse Coding and Dimensionality Ex...   \n",
       "17                   Algorithms/Representation Learning   \n",
       "18                        Algorithms/Stochastic Methods   \n",
       "19    Applications/Visual Scene Analysis and Interpr...   \n",
       "20                                 Algorithms/Regressio   \n",
       "21                                Theory/Learning Theor   \n",
       "22                   Deep Learning/Adversarial Networks   \n",
       "23                    Applications/Hardware and Systems   \n",
       "24                         Applications/Computer Vision   \n",
       "25               Applications/Visual Question Answering   \n",
       "26                                        Deep Learning   \n",
       "27                         Applications/Computer Vision   \n",
       "28                         Applications/Computer Vision   \n",
       "29                         Applications/Object Detectio   \n",
       "...                                                 ...   \n",
       "982                           Probabilistic Methods/MCM   \n",
       "983                                          Algorithms   \n",
       "984         Probabilistic Methods/Variational Inference   \n",
       "985                Optimization/Non-Convex Optimization   \n",
       "986              Probabilistic Methods/Graphical Models   \n",
       "987                               Theory/Regularization   \n",
       "988                            Applications/Game Playin   \n",
       "989                                       Deep Learning   \n",
       "990                    Optimization/Convex Optimization   \n",
       "991                  Algorithms/Representation Learning   \n",
       "992                    Applications/Time Series Analysi   \n",
       "993                     Deep Learning/Generative Models   \n",
       "994                  Deep Learning/Adversarial Networks   \n",
       "995          Algorithms/Sparsity and Compressed Sensing   \n",
       "996       Applications/Privacy, Anonymity, and Security   \n",
       "997           Probabilistic Methods/Hierarchical Models   \n",
       "998              Probabilistic Methods/Causal Inference   \n",
       "999                                              Theory   \n",
       "1000                                        Optimizatio   \n",
       "1001       Applications/Privacy, Anonymity, and Securit   \n",
       "1002             Probabilistic Methods/Causal Inference   \n",
       "1003    Applications/Web Applications and Internet Data   \n",
       "1004  Algorithms/Components Analysis (e.g., CCA, ICA...   \n",
       "1005       Probabilistic Methods/Latent Variable Models   \n",
       "1006                             Theory/Learning Theory   \n",
       "1007  Algorithms/Components Analysis (e.g., CCA, ICA...   \n",
       "1008          Deep Learning/Efficient Inference Methods   \n",
       "1009                 Reinforcement Learning and Plannin   \n",
       "1010  Applications/Fairness, Accountability, and Tra...   \n",
       "1011            Applications/Natural Language Processin   \n",
       "\n",
       "           Top-level Primary Subject Area  \\\n",
       "0                            Optimization   \n",
       "1                           Deep Learning   \n",
       "2                           Deep Learning   \n",
       "3                   Probabilistic Methods   \n",
       "4                            Applications   \n",
       "5                           Deep Learning   \n",
       "6                            Applications   \n",
       "7                              Algorithms   \n",
       "8                              Algorithms   \n",
       "9     Reinforcement Learning and Planning   \n",
       "10                             Algorithms   \n",
       "11                          Deep Learning   \n",
       "12                                 Theory   \n",
       "13                           Applications   \n",
       "14                          Deep Learning   \n",
       "15                           Applications   \n",
       "16                             Algorithms   \n",
       "17                             Algorithms   \n",
       "18                             Algorithms   \n",
       "19                           Applications   \n",
       "20                             Algorithms   \n",
       "21                                 Theory   \n",
       "22                          Deep Learning   \n",
       "23                           Applications   \n",
       "24                           Applications   \n",
       "25                           Applications   \n",
       "26                          Deep Learning   \n",
       "27                           Applications   \n",
       "28                           Applications   \n",
       "29                           Applications   \n",
       "...                                   ...   \n",
       "982                 Probabilistic Methods   \n",
       "983                            Algorithms   \n",
       "984                 Probabilistic Methods   \n",
       "985                          Optimization   \n",
       "986                 Probabilistic Methods   \n",
       "987                                Theory   \n",
       "988                          Applications   \n",
       "989                         Deep Learning   \n",
       "990                          Optimization   \n",
       "991                            Algorithms   \n",
       "992                          Applications   \n",
       "993                         Deep Learning   \n",
       "994                         Deep Learning   \n",
       "995                            Algorithms   \n",
       "996                          Applications   \n",
       "997                 Probabilistic Methods   \n",
       "998                 Probabilistic Methods   \n",
       "999                                Theory   \n",
       "1000                          Optimizatio   \n",
       "1001                         Applications   \n",
       "1002                Probabilistic Methods   \n",
       "1003                         Applications   \n",
       "1004                           Algorithms   \n",
       "1005                Probabilistic Methods   \n",
       "1006                               Theory   \n",
       "1007                           Algorithms   \n",
       "1008                        Deep Learning   \n",
       "1009   Reinforcement Learning and Plannin   \n",
       "1010                         Applications   \n",
       "1011                         Applications   \n",
       "\n",
       "                                                    bow   pid  \\\n",
       "0     [effici, algorithm, non, convex, isoton, regre...    29   \n",
       "1     [structur, awar, convolut, neural, network, co...    33   \n",
       "2     [kalman, normal, indispens, compon, batch, nor...    34   \n",
       "3     [hogwild, gibb, panaccur, asynchron, gibb, sam...    37   \n",
       "4     [text, adapt, gener, adversari, network, manip...    40   \n",
       "5     [introva, introspect, variat, autoencod, photo...    59   \n",
       "6     [doubli, robust, bayesian, infer, non, station...    68   \n",
       "7     [adapt, deep, embed, synthesi, method, shot, i...    75   \n",
       "8     [gener, invers, optim, onlin, learn, invers, o...    77   \n",
       "9     [polici, polici, gradient, theorem, use, empha...    85   \n",
       "10    [supervis, autoencod, improv, gener, perform, ...    88   \n",
       "11    [visual, object, network, imag, gener, disenta...    92   \n",
       "12    [understand, weight, normal, deep, neural, net...    95   \n",
       "13    [learn, pipelin, limit, data, domain, knowledg...    99   \n",
       "14    [learn, long, rang, spatial, depend, horizont,...   102   \n",
       "15    [joint, sub, band, learn, cliqu, structur, wav...   110   \n",
       "16    [fast, similar, search, via, optim, spars, lif...   142   \n",
       "17    [learn, deep, disentangl, embed, statist, loss...   145   \n",
       "18    [geometr, coupl, mont, carlo, sampl, mont, car...   153   \n",
       "19    [cooper, holist, 3d, scene, understand, singl,...   175   \n",
       "20    [effici, prune, algorithm, robust, isoton, reg...   177   \n",
       "21    [pac, learn, presenc, adversari, exist, evas, ...   178   \n",
       "22    [spars, dnn, improv, adversari, robust, deep, ...   182   \n",
       "23    [snap, ml, hierarch, framework, machin, learn,...   185   \n",
       "24    [see, think, disentangl, semant, scene, comple...   186   \n",
       "25    [chain, reason, visual, question, answer, reas...   187   \n",
       "26    [sigsoftmax, reanalysi, softmax, bottleneck, s...   188   \n",
       "27    [deep, non, blind, deconvolut, via, gener, low...   191   \n",
       "28    [probabilist, pose, graph, optim, via, bingham...   192   \n",
       "29    [metaanchor, learn, detect, object, custom, an...   207   \n",
       "...                                                 ...   ...   \n",
       "982   [thermostat, assist, continu, temper, hamilton...  6787   \n",
       "983   [robust, subspac, approxim, stream, studi, rob...  6793   \n",
       "984   [mean, field, stochast, blockmodel, optim, lan...  6802   \n",
       "985   [analysi, krylov, subspac, solut, regular, non...  6832   \n",
       "986   [autoconj, recogn, exploit, conjugaci, without...  6836   \n",
       "987   [dropblock, regular, method, convolut, network...  6839   \n",
       "988   [forward, model, partial, observ, strategi, ga...  6843   \n",
       "989   [friend, like, need, adversari, vulner, deep, ...  6847   \n",
       "990   [decentr, random, faster, algorithm, wasserste...  6859   \n",
       "991   [joint, autoregress, hierarch, prior, learn, i...  6863   \n",
       "992   [learn, tempor, point, process, via, reinforc,...  6874   \n",
       "993   [bia, gener, deep, gener, model, empir, studi,...  6882   \n",
       "994   [fast, effect, robust, certif, present, new, m...  6892   \n",
       "995   [support, recoveri, orthogon, match, pursuit, ...  6901   \n",
       "996   [differenti, privat, chang, point, detect, cha...  6905   \n",
       "997   [multi, valu, rule, set, interpret, classif, f...  6913   \n",
       "998   [domain, adapt, use, causal, infer, predict, i...  6921   \n",
       "999   [smooth, analysi, discret, tensor, decomposit,...  6923   \n",
       "1000  [mixlasso, gener, mix, regress, via, convex, a...  6961   \n",
       "1001  [semidefinit, relax, certifi, robust, adversar...  6968   \n",
       "1002  [remov, hidden, confound, experiment, ground, ...  6972   \n",
       "1003  [topkapi, parallel, fast, sketch, find, top, f...  6978   \n",
       "1004  [contrast, learn, pairwis, measur, learn, pair...  7985   \n",
       "1005  [point, process, latent, variabl, model, freel...  7992   \n",
       "1006  [comput, statist, effici, learn, bay, net, use...  7994   \n",
       "1007  [spars, pca, spars, linear, regress, spars, pr...  7997   \n",
       "1008  [sequenti, data, classif, resourc, constrain, ...  8002   \n",
       "1009  [transfer, deep, reactiv, polici, mdp, plan, d...  8009   \n",
       "1010  [price, fair, pca, one, extra, dimens, thi, pa...  8034   \n",
       "1011  [groupreduc, block, wise, low, rank, approxim,...  8035   \n",
       "\n",
       "                                                   tpms   tsne_all  tsne_tpms  \\\n",
       "0     [0.724210006, 0.547847061, 0.62121431, 0.69992... -65.037216  43.380173   \n",
       "1     [0.722796601, 0.7524726279999999, 0.681080612,... -27.842775 -41.931042   \n",
       "2     [0.605652029, 0.624528822, 0.5549479039999999,... -45.000961 -22.988417   \n",
       "3     [0.6039084920000001, 0.571028136, 0.547187392,... -86.396667  24.022959   \n",
       "4     [0.6074082789999999, 0.604121554, 0.5843663610...  10.959604 -44.323528   \n",
       "5     [0.554898813, 0.566786583, 0.514959909, 0.5606... -52.689449 -14.038417   \n",
       "6     [0.811906661, 0.7286812490000001, 0.745909935,...  21.148312  -1.963071   \n",
       "7     [0.7246898359999999, 0.74860931, 0.72164041200...  57.467770 -28.714304   \n",
       "8     [0.8553071390000001, 0.729569048, 0.771284843,...  62.712032  38.852795   \n",
       "9     [0.5770863589999999, 0.523376441, 0.518179388,...  85.118027   6.052812   \n",
       "10    [0.7831208590000001, 0.8086628229999999, 0.745...  52.941345 -26.562601   \n",
       "11    [0.622592223, 0.620137725, 0.574635252, 0.6193... -48.542374 -46.703506   \n",
       "12    [0.644970711, 0.6021990779999999, 0.611452154,...  -4.153590  13.390891   \n",
       "13    [0.825202962, 0.8357769540000001, 0.8245410609...  17.879139 -35.804531   \n",
       "14    [0.753889782, 0.8060686090000001, 0.7139329390... -37.060337 -39.884235   \n",
       "15    [0.665462302, 0.631348907, 0.61443569, 0.65938...   5.871789 -42.454613   \n",
       "16    [0.8577442009999999, 0.7920245159999999, 0.809...  51.363522 -17.461079   \n",
       "17    [0.801685634, 0.791540459, 0.772199449, 0.8187...  54.186298 -28.578308   \n",
       "18    [0.796080575, 0.669703717, 0.714382987, 0.7818...  43.549530  24.121429   \n",
       "19    [0.635211113, 0.587038424, 0.582188994, 0.6233...   9.757609 -47.380989   \n",
       "20    [0.8350809440000001, 0.641266087, 0.761110935,...  40.470722  43.279369   \n",
       "21    [0.5843463000000001, 0.563068797, 0.533589984,...  -4.154649 -19.239223   \n",
       "22    [0.666966905, 0.637015755, 0.638722607, 0.7032... -48.874542 -19.332710   \n",
       "23    [0.657971973, 0.853205806, 0.618791222, 0.6497...  19.205162 -23.840919   \n",
       "24    [0.657856715, 0.632397676, 0.6396587229999999,...   6.809194 -47.239983   \n",
       "25    [0.632062365, 0.6729400529999999, 0.603445259,...  12.654006 -36.788307   \n",
       "26    [0.692489644, 0.790134204, 0.660755629, 0.7194... -27.241320 -24.413645   \n",
       "27    [0.562258779, 0.5202836, 0.506214686, 0.550357...   5.565048 -42.852203   \n",
       "28    [0.9113688670000001, 0.7563436379999999, 0.820...   4.842010  29.373499   \n",
       "29    [0.620705712, 0.593533387, 0.572714624, 0.6164...   9.184333 -45.363842   \n",
       "...                                                 ...        ...        ...   \n",
       "982   [0.646289553, 0.620857109, 0.586481252, 0.6541... -83.440186  -3.773678   \n",
       "983   [0.540987701, 0.441798132, 0.49352610399999997...  36.628849  33.431755   \n",
       "984   [0.735002521, 0.627056098, 0.647996389, 0.7320... -85.291252  23.962334   \n",
       "985   [0.644204279, 0.46829059700000003, 0.536020003... -60.415810  45.334076   \n",
       "986   [0.644937403, 0.646330124, 0.606580474, 0.6317... -88.951286  -2.032948   \n",
       "987   [0.602325926, 0.709435875, 0.611376699, 0.6140... -13.005722 -40.898853   \n",
       "988   [0.64940197, 0.696797065, 0.612499372, 0.66309...  13.244852 -31.995758   \n",
       "989   [0.596239485, 0.552854089, 0.56523045, 0.61261... -28.122467 -20.176826   \n",
       "990   [0.649590907, 0.572511066, 0.579816594, 0.6330... -67.124580  29.979273   \n",
       "991   [0.5645583710000001, 0.599846334, 0.522823875,...  54.194683 -14.596280   \n",
       "992   [0.6848055690000001, 0.606161123, 0.618028853,...  22.287842   6.262251   \n",
       "993   [0.825245676, 0.77820804, 0.764052464, 0.83451... -52.453613 -39.021587   \n",
       "994   [0.656920721, 0.7048807429999999, 0.624150393,... -48.894798 -19.396210   \n",
       "995   [0.6322439089999999, 0.5179587760000001, 0.563...  41.317558  32.567497   \n",
       "996   [0.6977355690000001, 0.557927934, 0.63827413, ...  31.028465  36.121666   \n",
       "997   [0.823699588, 0.7256162290000001, 0.770973646,... -87.882576  17.551443   \n",
       "998   [0.534160482, 0.482813768, 0.514349219, 0.5274... -92.187416  15.178188   \n",
       "999   [0.693092713, 0.629186489, 0.656472765, 0.7012... -10.954827  21.518019   \n",
       "1000  [0.791815187, 0.657667486, 0.70105964, 0.77798...  -3.057512  30.973089   \n",
       "1001  [0.612903855, 0.584632164, 0.580678234, 0.6383...  29.588923 -18.780851   \n",
       "1002  [0.586181571, 0.490689461, 0.549189971, 0.5911... -92.203499  15.671731   \n",
       "1003  [0.672761353, 0.6915534390000001, 0.673524338,...  26.572653  19.820202   \n",
       "1004  [0.801794205, 0.6445370810000001, 0.70768539, ...  42.427158  25.685112   \n",
       "1005  [0.78844959, 0.730344946, 0.7138572390000001, ... -80.002975  -5.024580   \n",
       "1006  [0.442452024, 0.376913364, 0.45425219, 0.45383...  -0.688502  15.611752   \n",
       "1007  [0.755127242, 0.609168548, 0.665014251, 0.7336...  42.023003  32.024750   \n",
       "1008  [0.849686171, 0.9341852970000001, 0.7916773859... -39.611614 -27.079840   \n",
       "1009  [0.7646644690000001, 0.7638223829999999, 0.729...  78.536331   3.035766   \n",
       "1010  [0.7302362170000001, 0.631884585, 0.691013077,...  25.288885  27.855110   \n",
       "1011  [0.7068314809999999, 0.8144392220000001, 0.691...  16.285067 -24.585033   \n",
       "\n",
       "       Session  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4     D2_S1_T2  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7     D1_S2_T2  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  \n",
       "12         NaN  \n",
       "13         NaN  \n",
       "14         NaN  \n",
       "15         NaN  \n",
       "16         NaN  \n",
       "17         NaN  \n",
       "18    D2_S2_T1  \n",
       "19         NaN  \n",
       "20         NaN  \n",
       "21         NaN  \n",
       "22         NaN  \n",
       "23         NaN  \n",
       "24         NaN  \n",
       "25         NaN  \n",
       "26         NaN  \n",
       "27         NaN  \n",
       "28         NaN  \n",
       "29         NaN  \n",
       "...        ...  \n",
       "982        NaN  \n",
       "983   D3_S2_T1  \n",
       "984        NaN  \n",
       "985   D2_S2_T3  \n",
       "986        NaN  \n",
       "987        NaN  \n",
       "988        NaN  \n",
       "989        NaN  \n",
       "990   D3_S2_T3  \n",
       "991        NaN  \n",
       "992   D1_S2_T1  \n",
       "993   D1_S2_T2  \n",
       "994        NaN  \n",
       "995   D3_S2_T1  \n",
       "996        NaN  \n",
       "997        NaN  \n",
       "998        NaN  \n",
       "999        NaN  \n",
       "1000       NaN  \n",
       "1001       NaN  \n",
       "1002  D3_S1_T2  \n",
       "1003       NaN  \n",
       "1004       NaN  \n",
       "1005  D1_S2_T1  \n",
       "1006       NaN  \n",
       "1007       NaN  \n",
       "1008       NaN  \n",
       "1009       NaN  \n",
       "1010       NaN  \n",
       "1011       NaN  \n",
       "\n",
       "[1012 rows x 14 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add Session from file\n",
    "adf = pd.read_csv('S&O2.csv')\n",
    "spot = adf[['Paper ID','Session']]\n",
    "\n",
    "tmp = df.merge(spot, on='Paper ID', how='left', suffixes=('','_'))\n",
    "tmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = newdf.drop(columns=['Session'])\n",
    "tmp = newdf.merge(spot_df, left_on='Paper ID', right_on='Paper ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper ID</th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Emails</th>\n",
       "      <th>Subject Areas</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Primary Subject Area</th>\n",
       "      <th>Top-level Primary Subject Area</th>\n",
       "      <th>bow</th>\n",
       "      <th>pid</th>\n",
       "      <th>tpms</th>\n",
       "      <th>tsne_all</th>\n",
       "      <th>tsne_tpms</th>\n",
       "      <th>Session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Efficient Algorithms for Non-convex Isotonic R...</td>\n",
       "      <td>We consider the minimization of submodular fun...</td>\n",
       "      <td>francis.bach@inria.fr</td>\n",
       "      <td>Optimization/Submodular Optimization*; Optimiz...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Optimization/Submodular Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[effici, algorithm, non, convex, isoton, regre...</td>\n",
       "      <td>29</td>\n",
       "      <td>[0.724210006, 0.547847061, 0.62121431, 0.69992...</td>\n",
       "      <td>29.950420</td>\n",
       "      <td>41.906616</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Structure-Aware Convolutional Neural Networks</td>\n",
       "      <td>Convolutional neural networks (CNNs) are inher...</td>\n",
       "      <td>jianlong.chang@nlpr.ia.ac.cn;jie.gu@nlpr.ia.ac...</td>\n",
       "      <td>Deep Learning*; Deep Learning/CNN Architecture...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[structur, awar, convolut, neural, network, co...</td>\n",
       "      <td>33</td>\n",
       "      <td>[0.722796601, 0.7524726279999999, 0.681080612,...</td>\n",
       "      <td>69.435448</td>\n",
       "      <td>-41.231922</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>Kalman Normalization</td>\n",
       "      <td>As an indispensable component, Batch Normaliza...</td>\n",
       "      <td>wanggrun@mail2.sysu.edu.cn;jiefengpeng@gmail.c...</td>\n",
       "      <td>Deep Learning/CNN Architectures*; Applications...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/CNN Architectures</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[kalman, normal, indispens, compon, batch, nor...</td>\n",
       "      <td>34</td>\n",
       "      <td>[0.605652029, 0.624528822, 0.5549479039999999,...</td>\n",
       "      <td>75.101242</td>\n",
       "      <td>-22.875866</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>HOGWILD!-Gibbs can be PanAccurate</td>\n",
       "      <td>Asynchronous Gibbs sampling has been recently ...</td>\n",
       "      <td>costis@csail.mit.edu;ndikkala@mit.edu;jayanti@...</td>\n",
       "      <td>Probabilistic Methods/Distributed Inference*; ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Distributed Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[hogwild, gibb, panaccur, asynchron, gibb, sam...</td>\n",
       "      <td>37</td>\n",
       "      <td>[0.6039084920000001, 0.571028136, 0.547187392,...</td>\n",
       "      <td>-42.259544</td>\n",
       "      <td>22.692909</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>Text-Adaptive Generative Adversarial Networks:...</td>\n",
       "      <td>This paper addresses the problem of manipulati...</td>\n",
       "      <td>shnnam@yonsei.ac.kr;kim_yunji@yonsei.ac.kr;seo...</td>\n",
       "      <td>Applications/Computational Photography*; Appli...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Applications/Computational Photography</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[text, adapt, gener, adversari, network, manip...</td>\n",
       "      <td>40</td>\n",
       "      <td>[0.6074082789999999, 0.604121554, 0.5843663610...</td>\n",
       "      <td>-8.646683</td>\n",
       "      <td>-43.590607</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59</td>\n",
       "      <td>IntroVAE: Introspective Variational Autoencode...</td>\n",
       "      <td>We present a novel introspective variational a...</td>\n",
       "      <td>huaibo.huang@cripac.ia.ac.cn;zhihang.li@nlpr.i...</td>\n",
       "      <td>Deep Learning/Generative Models*; Deep Learnin...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Generative Models</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[introva, introspect, variat, autoencod, photo...</td>\n",
       "      <td>59</td>\n",
       "      <td>[0.554898813, 0.566786583, 0.514959909, 0.5606...</td>\n",
       "      <td>81.031715</td>\n",
       "      <td>-14.190269</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>Doubly Robust Bayesian Inference for Non-Stati...</td>\n",
       "      <td>We present the very first robust Bayesian Onli...</td>\n",
       "      <td>j.knoblauch@warwick.ac.uk;j.e.jewson@warwick.a...</td>\n",
       "      <td>Applications/Time Series Analysis*; Algorithms...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Time Series Analysis</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[doubli, robust, bayesian, infer, non, station...</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.811906661, 0.7286812490000001, 0.745909935,...</td>\n",
       "      <td>-18.716530</td>\n",
       "      <td>-3.146081</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>Adapted Deep Embeddings: A Synthesis of Method...</td>\n",
       "      <td>The focus in machine learning has branched bey...</td>\n",
       "      <td>tysc7237@colorado.edu;karl.ridgeway@colorado.e...</td>\n",
       "      <td>Algorithms/Multitask and Transfer Learning*; A...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Multitask and Transfer Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[adapt, deep, embed, synthesi, method, shot, i...</td>\n",
       "      <td>75</td>\n",
       "      <td>[0.7246898359999999, 0.74860931, 0.72164041200...</td>\n",
       "      <td>-55.623451</td>\n",
       "      <td>-29.995140</td>\n",
       "      <td>D3_S1_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>Generalized Inverse Optimization through Onlin...</td>\n",
       "      <td>Inverse optimization is a powerful paradigm fo...</td>\n",
       "      <td>chaosheng@pitt.edu;yiran.chen@duke.edu;bzeng@p...</td>\n",
       "      <td>Algorithms/Online Learning*; Applications/Quan...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Online Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[gener, invers, optim, onlin, learn, invers, o...</td>\n",
       "      <td>77</td>\n",
       "      <td>[0.8553071390000001, 0.729569048, 0.771284843,...</td>\n",
       "      <td>-79.361519</td>\n",
       "      <td>25.245207</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>85</td>\n",
       "      <td>An Off-policy Policy Gradient Theorem Using Em...</td>\n",
       "      <td>Policy gradient methods are widely used for co...</td>\n",
       "      <td>imani@ualberta.ca;graves@ualberta.ca;whitem@ua...</td>\n",
       "      <td>Reinforcement Learning and Planning/Reinforcem...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Reinforcement Learning and Planning/Reinforcem...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>[polici, polici, gradient, theorem, use, empha...</td>\n",
       "      <td>85</td>\n",
       "      <td>[0.5770863589999999, 0.523376441, 0.518179388,...</td>\n",
       "      <td>44.501297</td>\n",
       "      <td>7.835011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>88</td>\n",
       "      <td>Supervised autoencoders: Improving generalizat...</td>\n",
       "      <td>Generalization performance is a central goal i...</td>\n",
       "      <td>leile@iu.edu;andnpatt@iu.edu;whitem@ualberta.ca</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learnin</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[supervis, autoencod, improv, gener, perform, ...</td>\n",
       "      <td>88</td>\n",
       "      <td>[0.7831208590000001, 0.8086628229999999, 0.745...</td>\n",
       "      <td>-58.400303</td>\n",
       "      <td>-27.623331</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>92</td>\n",
       "      <td>Visual Object Networks: Image Generation with ...</td>\n",
       "      <td>Recent progress in deep generative models has ...</td>\n",
       "      <td>junyanz@mit.edu;ztzhang@mit.edu;ckzhang@mit.ed...</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[visual, object, network, imag, gener, disenta...</td>\n",
       "      <td>92</td>\n",
       "      <td>[0.622592223, 0.620137725, 0.574635252, 0.6193...</td>\n",
       "      <td>85.215065</td>\n",
       "      <td>-45.918297</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>95</td>\n",
       "      <td>Understanding Weight Normalized Deep Neural Ne...</td>\n",
       "      <td>This paper presents a general framework for no...</td>\n",
       "      <td>xu573@purdue.edu;wangxiao@purdue.edu</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theor</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[understand, weight, normal, deep, neural, net...</td>\n",
       "      <td>95</td>\n",
       "      <td>[0.644970711, 0.6021990779999999, 0.611452154,...</td>\n",
       "      <td>9.355120</td>\n",
       "      <td>0.585828</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>99</td>\n",
       "      <td>Learning Pipelines with Limited Data and Domai...</td>\n",
       "      <td>As machine learning becomes more widely used i...</td>\n",
       "      <td>mrinmayaster@gmail.com;avinava.dubey@gmail.com...</td>\n",
       "      <td>Applications*; Applications/Computer Vision</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[learn, pipelin, limit, data, domain, knowledg...</td>\n",
       "      <td>99</td>\n",
       "      <td>[0.825202962, 0.8357769540000001, 0.8245410609...</td>\n",
       "      <td>-15.508667</td>\n",
       "      <td>-35.415489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>102</td>\n",
       "      <td>Learning long-range spatial dependencies with ...</td>\n",
       "      <td>Progress in deep learning has spawned great su...</td>\n",
       "      <td>drew_linsley@brown.edu;junkyung_kim@brown.edu;...</td>\n",
       "      <td>Deep Learning/Biologically Plausible Deep Netw...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Biologically Plausible Deep Netw...</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[learn, long, rang, spatial, depend, horizont,...</td>\n",
       "      <td>102</td>\n",
       "      <td>[0.753889782, 0.8060686090000001, 0.7139329390...</td>\n",
       "      <td>66.520264</td>\n",
       "      <td>-39.277554</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>110</td>\n",
       "      <td>Joint Sub-bands Learning with Clique Structure...</td>\n",
       "      <td>Convolutional neural networks (CNNs) have rece...</td>\n",
       "      <td>zszhong@pku.edu.cn;tianchengshen@pku.edu.cn;ib...</td>\n",
       "      <td>Applications/Computer Vision*; Deep Learning/C...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[joint, sub, band, learn, cliqu, structur, wav...</td>\n",
       "      <td>110</td>\n",
       "      <td>[0.665462302, 0.631348907, 0.61443569, 0.65938...</td>\n",
       "      <td>-3.620618</td>\n",
       "      <td>-41.783928</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>142</td>\n",
       "      <td>Fast Similarity Search via Optimal Sparse Lifting</td>\n",
       "      <td>Similarity search is a fundamental problem in ...</td>\n",
       "      <td>wyli@cuhk.edu.cn;216019005@link.cuhk.edu.cn;yi...</td>\n",
       "      <td>Algorithms/Sparse Coding and Dimensionality Ex...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Sparse Coding and Dimensionality Ex...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[fast, similar, search, via, optim, spars, lif...</td>\n",
       "      <td>142</td>\n",
       "      <td>[0.8577442009999999, 0.7920245159999999, 0.809...</td>\n",
       "      <td>-59.549507</td>\n",
       "      <td>-19.159504</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>145</td>\n",
       "      <td>Learning Deep Disentangled Embeddings With the...</td>\n",
       "      <td>Deep-embedding methods aim to discover represe...</td>\n",
       "      <td>karl.ridgeway@colorado.edu;mozer@colorado.edu</td>\n",
       "      <td>Algorithms/Representation Learning*; Algorithm...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[learn, deep, disentangl, embed, statist, loss...</td>\n",
       "      <td>145</td>\n",
       "      <td>[0.801685634, 0.791540459, 0.772199449, 0.8187...</td>\n",
       "      <td>-52.455151</td>\n",
       "      <td>-29.709421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>153</td>\n",
       "      <td>Geometrically Coupled Monte Carlo Sampling</td>\n",
       "      <td>Monte Carlo sampling in high-dimensional, low-...</td>\n",
       "      <td>mr504@cam.ac.uk;kchoro@google.com;chalusf3@gma...</td>\n",
       "      <td>Algorithms/Stochastic Methods*; Reinforcement ...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Stochastic Methods</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[geometr, coupl, mont, carlo, sampl, mont, car...</td>\n",
       "      <td>153</td>\n",
       "      <td>[0.796080575, 0.669703717, 0.714382987, 0.7818...</td>\n",
       "      <td>-72.128998</td>\n",
       "      <td>22.797417</td>\n",
       "      <td>D2_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>175</td>\n",
       "      <td>Cooperative Holistic 3D Scene Understanding fr...</td>\n",
       "      <td>Holistic 3D indoor scene understanding involve...</td>\n",
       "      <td>huangsiyuan@ucla.edu;syqi@cs.ucla.edu;yinxuex@...</td>\n",
       "      <td>Applications/Visual Scene Analysis and Interpr...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Visual Scene Analysis and Interpr...</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[cooper, holist, 3d, scene, understand, singl,...</td>\n",
       "      <td>175</td>\n",
       "      <td>[0.635211113, 0.587038424, 0.582188994, 0.6233...</td>\n",
       "      <td>-7.480874</td>\n",
       "      <td>-46.575882</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>177</td>\n",
       "      <td>An Efficient Pruning Algorithm for Robust Isot...</td>\n",
       "      <td>We study a generalization of the classic isoto...</td>\n",
       "      <td>clim9@wisc.edu</td>\n",
       "      <td>Algorithms/Regression</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Regressio</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[effici, prune, algorithm, robust, isoton, reg...</td>\n",
       "      <td>177</td>\n",
       "      <td>[0.8350809440000001, 0.641266087, 0.761110935,...</td>\n",
       "      <td>-74.375404</td>\n",
       "      <td>41.805172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>178</td>\n",
       "      <td>PAC-learning in the presence of adversaries</td>\n",
       "      <td>The existence of evasion attacks during the te...</td>\n",
       "      <td>dcullina@princeton.edu;abhagoji@princeton.edu;...</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theor</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[pac, learn, presenc, adversari, exist, evas, ...</td>\n",
       "      <td>178</td>\n",
       "      <td>[0.5843463000000001, 0.563068797, 0.533589984,...</td>\n",
       "      <td>9.359765</td>\n",
       "      <td>-20.007828</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>182</td>\n",
       "      <td>Sparse DNNs with Improved Adversarial Robustness</td>\n",
       "      <td>Deep neural networks (DNNs) are computationall...</td>\n",
       "      <td>yiwen.guo@intel.com;pkuzc@pku.edu.cn;zcs@mail....</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Algorithm...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[spars, dnn, improv, adversari, robust, deep, ...</td>\n",
       "      <td>182</td>\n",
       "      <td>[0.666966905, 0.637015755, 0.638722607, 0.7032...</td>\n",
       "      <td>84.842842</td>\n",
       "      <td>-20.159740</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>185</td>\n",
       "      <td>Snap ML: A Hierarchical Framework for Machine ...</td>\n",
       "      <td>We describe a new software framework for fast ...</td>\n",
       "      <td>cdu@zurich.ibm.com;tpa@zurich.ibm.com;rig@zuri...</td>\n",
       "      <td>Applications/Hardware and Systems*; Data, Comp...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Hardware and Systems</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[snap, ml, hierarch, framework, machin, learn,...</td>\n",
       "      <td>185</td>\n",
       "      <td>[0.657971973, 0.853205806, 0.618791222, 0.6497...</td>\n",
       "      <td>-16.822359</td>\n",
       "      <td>-20.884203</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>186</td>\n",
       "      <td>See and Think: Disentangling Semantic Scene Co...</td>\n",
       "      <td>Semantic scene completion predicts volumetric ...</td>\n",
       "      <td>liushice@ict.ac.cn;huyu@ict.ac.cn;zengyiming@i...</td>\n",
       "      <td>Applications/Computer Vision*; Deep Learning/C...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[see, think, disentangl, semant, scene, comple...</td>\n",
       "      <td>186</td>\n",
       "      <td>[0.657856715, 0.632397676, 0.6396587229999999,...</td>\n",
       "      <td>-4.536843</td>\n",
       "      <td>-46.435524</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>187</td>\n",
       "      <td>Chain of Reasoning for Visual Question Answering</td>\n",
       "      <td>Reasoning plays an essential role in Visual Qu...</td>\n",
       "      <td>wuchenfei@bupt.edu.cn;liujinlai@bupt.edu.cn;xj...</td>\n",
       "      <td>Applications/Visual Question Answering*; Neuro...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Visual Question Answering</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[chain, reason, visual, question, answer, reas...</td>\n",
       "      <td>187</td>\n",
       "      <td>[0.632062365, 0.6729400529999999, 0.603445259,...</td>\n",
       "      <td>-10.336796</td>\n",
       "      <td>-36.345360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>188</td>\n",
       "      <td>Sigsoftmax: Reanalysis of the Softmax Bottleneck</td>\n",
       "      <td>Softmax is an output activation function for m...</td>\n",
       "      <td>kanai.sekitoshi@lab.ntt.co.jp;fujiwara.yasuhir...</td>\n",
       "      <td>Deep Learning*; Deep Learning/Recurrent Networ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[sigsoftmax, reanalysi, softmax, bottleneck, s...</td>\n",
       "      <td>188</td>\n",
       "      <td>[0.692489644, 0.790134204, 0.660755629, 0.7194...</td>\n",
       "      <td>69.954987</td>\n",
       "      <td>-24.284136</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>191</td>\n",
       "      <td>Deep Non-Blind Deconvolution via Generalized L...</td>\n",
       "      <td>In this paper, we present a deep convolutional...</td>\n",
       "      <td>rwq.renwenqi@gmail.com;zhjw1988@gmail.com;fore...</td>\n",
       "      <td>Applications/Computer Vision*; Applications/De...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[deep, non, blind, deconvolut, via, gener, low...</td>\n",
       "      <td>191</td>\n",
       "      <td>[0.562258779, 0.5202836, 0.506214686, 0.550357...</td>\n",
       "      <td>-3.312739</td>\n",
       "      <td>-42.153278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>192</td>\n",
       "      <td>Probabilistic Pose Graph Optimization via Bing...</td>\n",
       "      <td>We introduce Tempered Geodesic MCMC (TG-MCMC) ...</td>\n",
       "      <td>tolga.birdal@tum.de;umut.simsekli@telecom-pari...</td>\n",
       "      <td>Applications/Computer Vision*; Applications/Ro...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[probabilist, pose, graph, optim, via, bingham...</td>\n",
       "      <td>192</td>\n",
       "      <td>[0.9113688670000001, 0.7563436379999999, 0.820...</td>\n",
       "      <td>-2.593879</td>\n",
       "      <td>27.874113</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>207</td>\n",
       "      <td>MetaAnchor: Learning to Detect Objects with Cu...</td>\n",
       "      <td>We propose a novel and flexible anchor mechani...</td>\n",
       "      <td>yangt15@fudan.edu.cn;zhangxiangyu@megvii.com;l...</td>\n",
       "      <td>Applications/Object Detection</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Object Detectio</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[metaanchor, learn, detect, object, custom, an...</td>\n",
       "      <td>207</td>\n",
       "      <td>[0.620705712, 0.593533387, 0.572714624, 0.6164...</td>\n",
       "      <td>-6.911834</td>\n",
       "      <td>-44.603474</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>6787</td>\n",
       "      <td>Thermostat-assisted continuously-tempered Hami...</td>\n",
       "      <td>In this paper, we propose a novel sampling met...</td>\n",
       "      <td>r.luo@cs.ucl.ac.uk;jianhong.wang.17@ucl.ac.uk;...</td>\n",
       "      <td>Probabilistic Methods/MCMC</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/MCM</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[thermostat, assist, continu, temper, hamilton...</td>\n",
       "      <td>6787</td>\n",
       "      <td>[0.646289553, 0.620857109, 0.586481252, 0.6541...</td>\n",
       "      <td>-43.545441</td>\n",
       "      <td>-4.772652</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>6793</td>\n",
       "      <td>Robust Subspace Approximation in a Stream</td>\n",
       "      <td>We study robust subspace estimation in the str...</td>\n",
       "      <td>roiel@cs.cmu.edu;asevekar@andrew.cmu.edu;dwood...</td>\n",
       "      <td>Algorithms*; Algorithms/Regression</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[robust, subspac, approxim, stream, studi, rob...</td>\n",
       "      <td>6793</td>\n",
       "      <td>[0.540987701, 0.441798132, 0.49352610399999997...</td>\n",
       "      <td>-75.541176</td>\n",
       "      <td>31.828382</td>\n",
       "      <td>D3_S1_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>6802</td>\n",
       "      <td>Mean Field for the Stochastic Blockmodel: Opti...</td>\n",
       "      <td>Variational approximation has been widely used...</td>\n",
       "      <td>soumendu041@gmail.com;purna.sarkar@austin.utex...</td>\n",
       "      <td>Probabilistic Methods/Variational Inference*; ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Variational Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[mean, field, stochast, blockmodel, optim, lan...</td>\n",
       "      <td>6802</td>\n",
       "      <td>[0.735002521, 0.627056098, 0.647996389, 0.7320...</td>\n",
       "      <td>-45.091202</td>\n",
       "      <td>22.743847</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>6832</td>\n",
       "      <td>Analysis of Krylov Subspace Solutions of  Regu...</td>\n",
       "      <td>We provide convergence rates for Krylov subspa...</td>\n",
       "      <td>ycarmon@gmail.com;jduchi@stanford.edu</td>\n",
       "      <td>Optimization/Non-Convex Optimization*; Algorit...</td>\n",
       "      <td>Oral</td>\n",
       "      <td>Optimization/Non-Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[analysi, krylov, subspac, solut, regular, non...</td>\n",
       "      <td>6832</td>\n",
       "      <td>[0.644204279, 0.46829059700000003, 0.536020003...</td>\n",
       "      <td>26.129072</td>\n",
       "      <td>43.834412</td>\n",
       "      <td>D2_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>6836</td>\n",
       "      <td>Autoconj: Recognizing and Exploiting Conjugacy...</td>\n",
       "      <td>Deriving conditional and marginal distribution...</td>\n",
       "      <td>mdhoffma@cs.princeton.edu;mattjj@google.com;tr...</td>\n",
       "      <td>Probabilistic Methods/Graphical Models*; Data,...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Graphical Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[autoconj, recogn, exploit, conjugaci, without...</td>\n",
       "      <td>6836</td>\n",
       "      <td>[0.644937403, 0.646330124, 0.606580474, 0.6317...</td>\n",
       "      <td>-36.022869</td>\n",
       "      <td>-2.977412</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>6839</td>\n",
       "      <td>DropBlock: A regularization method for convolu...</td>\n",
       "      <td>Deep neural networks often work well when they...</td>\n",
       "      <td>golnazg@google.com;tsungyi@google.com;qvl@goog...</td>\n",
       "      <td>Theory/Regularization*; Deep Learning/CNN Arch...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Regularization</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[dropblock, regular, method, convolut, network...</td>\n",
       "      <td>6839</td>\n",
       "      <td>[0.602325926, 0.709435875, 0.611376699, 0.6140...</td>\n",
       "      <td>10.156830</td>\n",
       "      <td>-40.257950</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>6843</td>\n",
       "      <td>Forward Modeling for Partial Observation Strat...</td>\n",
       "      <td>We formulate the problem of \\emph{defogging} a...</td>\n",
       "      <td>gab@fb.com;zlin@fb.com;jgehring@fb.com;dangant...</td>\n",
       "      <td>Applications/Game Playing</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Game Playin</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[forward, model, partial, observ, strategi, ga...</td>\n",
       "      <td>6843</td>\n",
       "      <td>[0.64940197, 0.696797065, 0.612499372, 0.66309...</td>\n",
       "      <td>-10.947182</td>\n",
       "      <td>-31.871689</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>6847</td>\n",
       "      <td>With Friends Like These, Who Needs Adversaries?</td>\n",
       "      <td>The vulnerability of deep networks to adversar...</td>\n",
       "      <td>sjetley@robots.ox.ac.uk;nicklord@robots.ox.ac....</td>\n",
       "      <td>Deep Learning*; Algorithms/Classification; Alg...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[friend, like, need, adversari, vulner, deep, ...</td>\n",
       "      <td>6847</td>\n",
       "      <td>[0.596239485, 0.552854089, 0.56523045, 0.61261...</td>\n",
       "      <td>69.137093</td>\n",
       "      <td>-26.654100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>6859</td>\n",
       "      <td>Decentralize and Randomize: Faster Algorithm f...</td>\n",
       "      <td>We study the problem of decentralized distribu...</td>\n",
       "      <td>pavel.dvurechensky@gmail.com;darina.dvinskikh@...</td>\n",
       "      <td>Optimization/Convex Optimization*; Algorithms/...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization/Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[decentr, random, faster, algorithm, wasserste...</td>\n",
       "      <td>6859</td>\n",
       "      <td>[0.649590907, 0.572511066, 0.579816594, 0.6330...</td>\n",
       "      <td>32.173798</td>\n",
       "      <td>28.452133</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>6863</td>\n",
       "      <td>Joint Autoregressive and Hierarchical Priors f...</td>\n",
       "      <td>Recent models for learned image compression ar...</td>\n",
       "      <td>dminnen@google.com;jballe@google.com;gtoderici...</td>\n",
       "      <td>Algorithms/Representation Learning*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[joint, autoregress, hierarch, prior, learn, i...</td>\n",
       "      <td>6863</td>\n",
       "      <td>[0.5645583710000001, 0.599846334, 0.522823875,...</td>\n",
       "      <td>-52.424301</td>\n",
       "      <td>-30.890600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>6874</td>\n",
       "      <td>Learning Temporal Point Processes via Reinforc...</td>\n",
       "      <td>Many real world problems from sustainability, ...</td>\n",
       "      <td>sli370@gatech.edu;benjaminforever@sjtu.edu.cn;...</td>\n",
       "      <td>Applications/Time Series Analysis</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Applications/Time Series Analysi</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[learn, tempor, point, process, via, reinforc,...</td>\n",
       "      <td>6874</td>\n",
       "      <td>[0.6848055690000001, 0.606161123, 0.618028853,...</td>\n",
       "      <td>-19.862894</td>\n",
       "      <td>8.033325</td>\n",
       "      <td>D2_S1_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>6882</td>\n",
       "      <td>Bias and Generalization in Deep Generative Mod...</td>\n",
       "      <td>In high dimensional settings, density estimati...</td>\n",
       "      <td>sjzhao@stanford.edu;hyren@cs.stanford.edu;xfyu...</td>\n",
       "      <td>Deep Learning/Generative Models*; Deep Learnin...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning/Generative Models</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[bia, gener, deep, gener, model, empir, studi,...</td>\n",
       "      <td>6882</td>\n",
       "      <td>[0.825245676, 0.77820804, 0.764052464, 0.83451...</td>\n",
       "      <td>80.826553</td>\n",
       "      <td>-38.422794</td>\n",
       "      <td>D2_S2_T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>6892</td>\n",
       "      <td>Fast and Effective Robustness Certification</td>\n",
       "      <td>We present a new method and system for certify...</td>\n",
       "      <td>gsingh@inf.ethz.ch;timon.gehr@inf.ethz.ch;matt...</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[fast, effect, robust, certif, present, new, m...</td>\n",
       "      <td>6892</td>\n",
       "      <td>[0.656920721, 0.7048807429999999, 0.624150393,...</td>\n",
       "      <td>84.853836</td>\n",
       "      <td>-20.459106</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>6901</td>\n",
       "      <td>Support Recovery for Orthogonal Matching Pursu...</td>\n",
       "      <td>This paper studies the problem of sparse regre...</td>\n",
       "      <td>raghavsomani1995@gmail.com;chiragpvg@gmail.com...</td>\n",
       "      <td>Algorithms/Sparsity and Compressed Sensing*; A...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Sparsity and Compressed Sensing</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[support, recoveri, orthogon, match, pursuit, ...</td>\n",
       "      <td>6901</td>\n",
       "      <td>[0.6322439089999999, 0.5179587760000001, 0.563...</td>\n",
       "      <td>-71.281883</td>\n",
       "      <td>30.983622</td>\n",
       "      <td>D2_S2_T3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>6905</td>\n",
       "      <td>Differentially Private Change-Point Detection</td>\n",
       "      <td>The change-point detection problem seeks to id...</td>\n",
       "      <td>krehbiel@richmond.edu;rachelc@gatech.edu;wanro...</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security*...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[differenti, privat, chang, point, detect, cha...</td>\n",
       "      <td>6905</td>\n",
       "      <td>[0.6977355690000001, 0.557927934, 0.63827413, ...</td>\n",
       "      <td>-28.408152</td>\n",
       "      <td>34.926235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>6913</td>\n",
       "      <td>Multi-value Rule Sets for Interpretable Classi...</td>\n",
       "      <td>We present Multi-value Rule Sets (MRS) for int...</td>\n",
       "      <td>tong-wang@uiowa.edu</td>\n",
       "      <td>Probabilistic Methods/Hierarchical Models*; Ap...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Hierarchical Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[multi, valu, rule, set, interpret, classif, f...</td>\n",
       "      <td>6913</td>\n",
       "      <td>[0.823699588, 0.7256162290000001, 0.770973646,...</td>\n",
       "      <td>-37.061535</td>\n",
       "      <td>16.019241</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6921</td>\n",
       "      <td>Domain Adaptation by Using Causal Inference to...</td>\n",
       "      <td>An important goal common to domain adaptation ...</td>\n",
       "      <td>sara.magliacane@gmail.com;thijsvanommen@gmail....</td>\n",
       "      <td>Probabilistic Methods/Causal Inference*; Deep ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Causal Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[domain, adapt, use, causal, infer, predict, i...</td>\n",
       "      <td>6921</td>\n",
       "      <td>[0.534160482, 0.482813768, 0.514349219, 0.5274...</td>\n",
       "      <td>-33.443409</td>\n",
       "      <td>13.715412</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>6923</td>\n",
       "      <td>Smoothed Analysis of Discrete Tensor Decomposi...</td>\n",
       "      <td>We analyze linear independence of rank one ten...</td>\n",
       "      <td>anari.nima@gmail.com;costis@csail.mit.edu;maas...</td>\n",
       "      <td>Theory*; Algorithms/Components Analysis (e.g.,...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[smooth, analysi, discret, tensor, decomposit,...</td>\n",
       "      <td>6923</td>\n",
       "      <td>[0.693092713, 0.629186489, 0.656472765, 0.7012...</td>\n",
       "      <td>4.982391</td>\n",
       "      <td>19.488535</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>6961</td>\n",
       "      <td>MixLasso: Generalized Mixed Regression via Con...</td>\n",
       "      <td>We consider a generalization of mixed regressi...</td>\n",
       "      <td>eyan@cs.cmu.edu;b01902065@ntu.edu.tw;kaizhong8...</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Optimizatio</td>\n",
       "      <td>Optimizatio</td>\n",
       "      <td>[mixlasso, gener, mix, regress, via, convex, a...</td>\n",
       "      <td>6961</td>\n",
       "      <td>[0.791815187, 0.657667486, 0.70105964, 0.77798...</td>\n",
       "      <td>11.150247</td>\n",
       "      <td>29.388924</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>6968</td>\n",
       "      <td>Semidefinite relaxations for certifying robust...</td>\n",
       "      <td>Research on adversarial examples are evolved i...</td>\n",
       "      <td>aditir1994@gmail.com;jacob.steinhardt@gmail.co...</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Securit</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[semidefinit, relax, certifi, robust, adversar...</td>\n",
       "      <td>6968</td>\n",
       "      <td>[0.612903855, 0.584632164, 0.580678234, 0.6383...</td>\n",
       "      <td>-26.983023</td>\n",
       "      <td>-19.791059</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>6972</td>\n",
       "      <td>Removing Hidden Confounding by Experimental Gr...</td>\n",
       "      <td>Observational data is being increasingly used ...</td>\n",
       "      <td>kallus@cornell.edu;apm470@nyu.edu;urishalit@te...</td>\n",
       "      <td>Probabilistic Methods/Causal Inference*; Algor...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Probabilistic Methods/Causal Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[remov, hidden, confound, experiment, ground, ...</td>\n",
       "      <td>6972</td>\n",
       "      <td>[0.586181571, 0.490689461, 0.549189971, 0.5911...</td>\n",
       "      <td>-33.386219</td>\n",
       "      <td>14.227854</td>\n",
       "      <td>D3_S1_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>6978</td>\n",
       "      <td>Topkapi: Parallel and Fast Sketches for Findin...</td>\n",
       "      <td>Identifying the top-K frequent items is one of...</td>\n",
       "      <td>ankush@gatech.edu;cary.jiang@rice.edu;anshumal...</td>\n",
       "      <td>Applications/Web Applications and Internet Dat...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Web Applications and Internet Data</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[topkapi, parallel, fast, sketch, find, top, f...</td>\n",
       "      <td>6978</td>\n",
       "      <td>[0.672761353, 0.6915534390000001, 0.673524338,...</td>\n",
       "      <td>-24.045568</td>\n",
       "      <td>1.927942</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>7985</td>\n",
       "      <td>Contrastive Learning from Pairwise Measurements</td>\n",
       "      <td>Learning from pairwise measurements naturally ...</td>\n",
       "      <td>yichen2016@u.northwestern.edu;zy6@princeton.ed...</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[contrast, learn, pairwis, measur, learn, pair...</td>\n",
       "      <td>7985</td>\n",
       "      <td>[0.801794205, 0.6445370810000001, 0.70768539, ...</td>\n",
       "      <td>-70.215393</td>\n",
       "      <td>24.161211</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>7992</td>\n",
       "      <td>Point process latent variable models of freely...</td>\n",
       "      <td>A fundamental goal of systems neuroscience is ...</td>\n",
       "      <td>as4529@columbia.edu;scott.linderman@columbia.e...</td>\n",
       "      <td>Probabilistic Methods/Latent Variable Models*;...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Probabilistic Methods/Latent Variable Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[point, process, latent, variabl, model, freel...</td>\n",
       "      <td>7992</td>\n",
       "      <td>[0.78844959, 0.730344946, 0.7138572390000001, ...</td>\n",
       "      <td>-47.077015</td>\n",
       "      <td>-6.283218</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>7994</td>\n",
       "      <td>Computationally and Statistically Efficient Le...</td>\n",
       "      <td>Causal discovery from empirical data is a fund...</td>\n",
       "      <td>kbellome@purdue.edu;jhonorio@purdue.edu</td>\n",
       "      <td>Theory/Learning Theory*; Probabilistic Methods...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[comput, statist, effici, learn, bay, net, use...</td>\n",
       "      <td>7994</td>\n",
       "      <td>[0.442452024, 0.376913364, 0.45425219, 0.45383...</td>\n",
       "      <td>13.572625</td>\n",
       "      <td>14.079021</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>7997</td>\n",
       "      <td>Sparse PCA from Sparse Linear Regression</td>\n",
       "      <td>Sparse Principal Component Analysis (SPCA) and...</td>\n",
       "      <td>guy@mit.edu;sp765@mit.edu;mpersu@mit.edu</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[spars, pca, spars, linear, regress, spars, pr...</td>\n",
       "      <td>7997</td>\n",
       "      <td>[0.755127242, 0.609168548, 0.665014251, 0.7336...</td>\n",
       "      <td>-70.626175</td>\n",
       "      <td>30.425714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>8002</td>\n",
       "      <td>Sequential Data Classification for Resource-co...</td>\n",
       "      <td>We study the problem of fast and efficient cla...</td>\n",
       "      <td>t-dodenn@microsoft.com;chiragramdas@gmail.com;...</td>\n",
       "      <td>Deep Learning/Efficient Inference Methods*; De...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Efficient Inference Methods</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[sequenti, data, classif, resourc, constrain, ...</td>\n",
       "      <td>8002</td>\n",
       "      <td>[0.849686171, 0.9341852970000001, 0.7916773859...</td>\n",
       "      <td>77.401146</td>\n",
       "      <td>-28.128359</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>8009</td>\n",
       "      <td>Transfer of Deep Reactive Policies for MDP Pla...</td>\n",
       "      <td>Domain-independent probabilistic planners inpu...</td>\n",
       "      <td>quantum.computing96@gmail.com;sankalp2621998@g...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Reinforcement Learning and Plannin</td>\n",
       "      <td>Reinforcement Learning and Plannin</td>\n",
       "      <td>[transfer, deep, reactiv, polici, mdp, plan, d...</td>\n",
       "      <td>8009</td>\n",
       "      <td>[0.7646644690000001, 0.7638223829999999, 0.729...</td>\n",
       "      <td>41.460049</td>\n",
       "      <td>4.912152</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>8034</td>\n",
       "      <td>The Price of Fair PCA: One Extra dimension</td>\n",
       "      <td>In this paper, we investigate the possibility ...</td>\n",
       "      <td>s.samadi@gmail.com;tao@gatech.edu;jamiemor@cis...</td>\n",
       "      <td>Applications/Fairness, Accountability, and Tra...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Fairness, Accountability, and Tra...</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[price, fair, pca, one, extra, dimens, thi, pa...</td>\n",
       "      <td>8034</td>\n",
       "      <td>[0.7302362170000001, 0.631884585, 0.691013077,...</td>\n",
       "      <td>-22.797361</td>\n",
       "      <td>26.325262</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>8035</td>\n",
       "      <td>GroupReduce: Block-Wise Low-Rank Approximation...</td>\n",
       "      <td>Model compression is essential for serving lar...</td>\n",
       "      <td>phpchen@ucdavis.edu;sisidaisy@google.com;liyan...</td>\n",
       "      <td>Applications/Natural Language Processing</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Natural Language Processin</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[groupreduc, block, wise, low, rank, approxim,...</td>\n",
       "      <td>8035</td>\n",
       "      <td>[0.7068314809999999, 0.8144392220000001, 0.691...</td>\n",
       "      <td>-13.926091</td>\n",
       "      <td>-24.498652</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Paper ID                                        Paper Title  \\\n",
       "0           29  Efficient Algorithms for Non-convex Isotonic R...   \n",
       "1           33      Structure-Aware Convolutional Neural Networks   \n",
       "2           34                               Kalman Normalization   \n",
       "3           37                  HOGWILD!-Gibbs can be PanAccurate   \n",
       "4           40  Text-Adaptive Generative Adversarial Networks:...   \n",
       "5           59  IntroVAE: Introspective Variational Autoencode...   \n",
       "6           68  Doubly Robust Bayesian Inference for Non-Stati...   \n",
       "7           75  Adapted Deep Embeddings: A Synthesis of Method...   \n",
       "8           77  Generalized Inverse Optimization through Onlin...   \n",
       "9           85  An Off-policy Policy Gradient Theorem Using Em...   \n",
       "10          88  Supervised autoencoders: Improving generalizat...   \n",
       "11          92  Visual Object Networks: Image Generation with ...   \n",
       "12          95  Understanding Weight Normalized Deep Neural Ne...   \n",
       "13          99  Learning Pipelines with Limited Data and Domai...   \n",
       "14         102  Learning long-range spatial dependencies with ...   \n",
       "15         110  Joint Sub-bands Learning with Clique Structure...   \n",
       "16         142  Fast Similarity Search via Optimal Sparse Lifting   \n",
       "17         145  Learning Deep Disentangled Embeddings With the...   \n",
       "18         153         Geometrically Coupled Monte Carlo Sampling   \n",
       "19         175  Cooperative Holistic 3D Scene Understanding fr...   \n",
       "20         177  An Efficient Pruning Algorithm for Robust Isot...   \n",
       "21         178        PAC-learning in the presence of adversaries   \n",
       "22         182   Sparse DNNs with Improved Adversarial Robustness   \n",
       "23         185  Snap ML: A Hierarchical Framework for Machine ...   \n",
       "24         186  See and Think: Disentangling Semantic Scene Co...   \n",
       "25         187   Chain of Reasoning for Visual Question Answering   \n",
       "26         188   Sigsoftmax: Reanalysis of the Softmax Bottleneck   \n",
       "27         191  Deep Non-Blind Deconvolution via Generalized L...   \n",
       "28         192  Probabilistic Pose Graph Optimization via Bing...   \n",
       "29         207  MetaAnchor: Learning to Detect Objects with Cu...   \n",
       "...        ...                                                ...   \n",
       "982       6787  Thermostat-assisted continuously-tempered Hami...   \n",
       "983       6793          Robust Subspace Approximation in a Stream   \n",
       "984       6802  Mean Field for the Stochastic Blockmodel: Opti...   \n",
       "985       6832  Analysis of Krylov Subspace Solutions of  Regu...   \n",
       "986       6836  Autoconj: Recognizing and Exploiting Conjugacy...   \n",
       "987       6839  DropBlock: A regularization method for convolu...   \n",
       "988       6843  Forward Modeling for Partial Observation Strat...   \n",
       "989       6847    With Friends Like These, Who Needs Adversaries?   \n",
       "990       6859  Decentralize and Randomize: Faster Algorithm f...   \n",
       "991       6863  Joint Autoregressive and Hierarchical Priors f...   \n",
       "992       6874  Learning Temporal Point Processes via Reinforc...   \n",
       "993       6882  Bias and Generalization in Deep Generative Mod...   \n",
       "994       6892        Fast and Effective Robustness Certification   \n",
       "995       6901  Support Recovery for Orthogonal Matching Pursu...   \n",
       "996       6905      Differentially Private Change-Point Detection   \n",
       "997       6913  Multi-value Rule Sets for Interpretable Classi...   \n",
       "998       6921  Domain Adaptation by Using Causal Inference to...   \n",
       "999       6923  Smoothed Analysis of Discrete Tensor Decomposi...   \n",
       "1000      6961  MixLasso: Generalized Mixed Regression via Con...   \n",
       "1001      6968  Semidefinite relaxations for certifying robust...   \n",
       "1002      6972  Removing Hidden Confounding by Experimental Gr...   \n",
       "1003      6978  Topkapi: Parallel and Fast Sketches for Findin...   \n",
       "1004      7985    Contrastive Learning from Pairwise Measurements   \n",
       "1005      7992  Point process latent variable models of freely...   \n",
       "1006      7994  Computationally and Statistically Efficient Le...   \n",
       "1007      7997           Sparse PCA from Sparse Linear Regression   \n",
       "1008      8002  Sequential Data Classification for Resource-co...   \n",
       "1009      8009  Transfer of Deep Reactive Policies for MDP Pla...   \n",
       "1010      8034         The Price of Fair PCA: One Extra dimension   \n",
       "1011      8035  GroupReduce: Block-Wise Low-Rank Approximation...   \n",
       "\n",
       "                                               Abstract  \\\n",
       "0     We consider the minimization of submodular fun...   \n",
       "1     Convolutional neural networks (CNNs) are inher...   \n",
       "2     As an indispensable component, Batch Normaliza...   \n",
       "3     Asynchronous Gibbs sampling has been recently ...   \n",
       "4     This paper addresses the problem of manipulati...   \n",
       "5     We present a novel introspective variational a...   \n",
       "6     We present the very first robust Bayesian Onli...   \n",
       "7     The focus in machine learning has branched bey...   \n",
       "8     Inverse optimization is a powerful paradigm fo...   \n",
       "9     Policy gradient methods are widely used for co...   \n",
       "10    Generalization performance is a central goal i...   \n",
       "11    Recent progress in deep generative models has ...   \n",
       "12    This paper presents a general framework for no...   \n",
       "13    As machine learning becomes more widely used i...   \n",
       "14    Progress in deep learning has spawned great su...   \n",
       "15    Convolutional neural networks (CNNs) have rece...   \n",
       "16    Similarity search is a fundamental problem in ...   \n",
       "17    Deep-embedding methods aim to discover represe...   \n",
       "18    Monte Carlo sampling in high-dimensional, low-...   \n",
       "19    Holistic 3D indoor scene understanding involve...   \n",
       "20    We study a generalization of the classic isoto...   \n",
       "21    The existence of evasion attacks during the te...   \n",
       "22    Deep neural networks (DNNs) are computationall...   \n",
       "23    We describe a new software framework for fast ...   \n",
       "24    Semantic scene completion predicts volumetric ...   \n",
       "25    Reasoning plays an essential role in Visual Qu...   \n",
       "26    Softmax is an output activation function for m...   \n",
       "27    In this paper, we present a deep convolutional...   \n",
       "28    We introduce Tempered Geodesic MCMC (TG-MCMC) ...   \n",
       "29    We propose a novel and flexible anchor mechani...   \n",
       "...                                                 ...   \n",
       "982   In this paper, we propose a novel sampling met...   \n",
       "983   We study robust subspace estimation in the str...   \n",
       "984   Variational approximation has been widely used...   \n",
       "985   We provide convergence rates for Krylov subspa...   \n",
       "986   Deriving conditional and marginal distribution...   \n",
       "987   Deep neural networks often work well when they...   \n",
       "988   We formulate the problem of \\emph{defogging} a...   \n",
       "989   The vulnerability of deep networks to adversar...   \n",
       "990   We study the problem of decentralized distribu...   \n",
       "991   Recent models for learned image compression ar...   \n",
       "992   Many real world problems from sustainability, ...   \n",
       "993   In high dimensional settings, density estimati...   \n",
       "994   We present a new method and system for certify...   \n",
       "995   This paper studies the problem of sparse regre...   \n",
       "996   The change-point detection problem seeks to id...   \n",
       "997   We present Multi-value Rule Sets (MRS) for int...   \n",
       "998   An important goal common to domain adaptation ...   \n",
       "999   We analyze linear independence of rank one ten...   \n",
       "1000  We consider a generalization of mixed regressi...   \n",
       "1001  Research on adversarial examples are evolved i...   \n",
       "1002  Observational data is being increasingly used ...   \n",
       "1003  Identifying the top-K frequent items is one of...   \n",
       "1004  Learning from pairwise measurements naturally ...   \n",
       "1005  A fundamental goal of systems neuroscience is ...   \n",
       "1006  Causal discovery from empirical data is a fund...   \n",
       "1007  Sparse Principal Component Analysis (SPCA) and...   \n",
       "1008  We study the problem of fast and efficient cla...   \n",
       "1009  Domain-independent probabilistic planners inpu...   \n",
       "1010  In this paper, we investigate the possibility ...   \n",
       "1011  Model compression is essential for serving lar...   \n",
       "\n",
       "                                          Author Emails  \\\n",
       "0                                 francis.bach@inria.fr   \n",
       "1     jianlong.chang@nlpr.ia.ac.cn;jie.gu@nlpr.ia.ac...   \n",
       "2     wanggrun@mail2.sysu.edu.cn;jiefengpeng@gmail.c...   \n",
       "3     costis@csail.mit.edu;ndikkala@mit.edu;jayanti@...   \n",
       "4     shnnam@yonsei.ac.kr;kim_yunji@yonsei.ac.kr;seo...   \n",
       "5     huaibo.huang@cripac.ia.ac.cn;zhihang.li@nlpr.i...   \n",
       "6     j.knoblauch@warwick.ac.uk;j.e.jewson@warwick.a...   \n",
       "7     tysc7237@colorado.edu;karl.ridgeway@colorado.e...   \n",
       "8     chaosheng@pitt.edu;yiran.chen@duke.edu;bzeng@p...   \n",
       "9     imani@ualberta.ca;graves@ualberta.ca;whitem@ua...   \n",
       "10      leile@iu.edu;andnpatt@iu.edu;whitem@ualberta.ca   \n",
       "11    junyanz@mit.edu;ztzhang@mit.edu;ckzhang@mit.ed...   \n",
       "12                 xu573@purdue.edu;wangxiao@purdue.edu   \n",
       "13    mrinmayaster@gmail.com;avinava.dubey@gmail.com...   \n",
       "14    drew_linsley@brown.edu;junkyung_kim@brown.edu;...   \n",
       "15    zszhong@pku.edu.cn;tianchengshen@pku.edu.cn;ib...   \n",
       "16    wyli@cuhk.edu.cn;216019005@link.cuhk.edu.cn;yi...   \n",
       "17        karl.ridgeway@colorado.edu;mozer@colorado.edu   \n",
       "18    mr504@cam.ac.uk;kchoro@google.com;chalusf3@gma...   \n",
       "19    huangsiyuan@ucla.edu;syqi@cs.ucla.edu;yinxuex@...   \n",
       "20                                       clim9@wisc.edu   \n",
       "21    dcullina@princeton.edu;abhagoji@princeton.edu;...   \n",
       "22    yiwen.guo@intel.com;pkuzc@pku.edu.cn;zcs@mail....   \n",
       "23    cdu@zurich.ibm.com;tpa@zurich.ibm.com;rig@zuri...   \n",
       "24    liushice@ict.ac.cn;huyu@ict.ac.cn;zengyiming@i...   \n",
       "25    wuchenfei@bupt.edu.cn;liujinlai@bupt.edu.cn;xj...   \n",
       "26    kanai.sekitoshi@lab.ntt.co.jp;fujiwara.yasuhir...   \n",
       "27    rwq.renwenqi@gmail.com;zhjw1988@gmail.com;fore...   \n",
       "28    tolga.birdal@tum.de;umut.simsekli@telecom-pari...   \n",
       "29    yangt15@fudan.edu.cn;zhangxiangyu@megvii.com;l...   \n",
       "...                                                 ...   \n",
       "982   r.luo@cs.ucl.ac.uk;jianhong.wang.17@ucl.ac.uk;...   \n",
       "983   roiel@cs.cmu.edu;asevekar@andrew.cmu.edu;dwood...   \n",
       "984   soumendu041@gmail.com;purna.sarkar@austin.utex...   \n",
       "985               ycarmon@gmail.com;jduchi@stanford.edu   \n",
       "986   mdhoffma@cs.princeton.edu;mattjj@google.com;tr...   \n",
       "987   golnazg@google.com;tsungyi@google.com;qvl@goog...   \n",
       "988   gab@fb.com;zlin@fb.com;jgehring@fb.com;dangant...   \n",
       "989   sjetley@robots.ox.ac.uk;nicklord@robots.ox.ac....   \n",
       "990   pavel.dvurechensky@gmail.com;darina.dvinskikh@...   \n",
       "991   dminnen@google.com;jballe@google.com;gtoderici...   \n",
       "992   sli370@gatech.edu;benjaminforever@sjtu.edu.cn;...   \n",
       "993   sjzhao@stanford.edu;hyren@cs.stanford.edu;xfyu...   \n",
       "994   gsingh@inf.ethz.ch;timon.gehr@inf.ethz.ch;matt...   \n",
       "995   raghavsomani1995@gmail.com;chiragpvg@gmail.com...   \n",
       "996   krehbiel@richmond.edu;rachelc@gatech.edu;wanro...   \n",
       "997                                 tong-wang@uiowa.edu   \n",
       "998   sara.magliacane@gmail.com;thijsvanommen@gmail....   \n",
       "999   anari.nima@gmail.com;costis@csail.mit.edu;maas...   \n",
       "1000  eyan@cs.cmu.edu;b01902065@ntu.edu.tw;kaizhong8...   \n",
       "1001  aditir1994@gmail.com;jacob.steinhardt@gmail.co...   \n",
       "1002  kallus@cornell.edu;apm470@nyu.edu;urishalit@te...   \n",
       "1003  ankush@gatech.edu;cary.jiang@rice.edu;anshumal...   \n",
       "1004  yichen2016@u.northwestern.edu;zy6@princeton.ed...   \n",
       "1005  as4529@columbia.edu;scott.linderman@columbia.e...   \n",
       "1006            kbellome@purdue.edu;jhonorio@purdue.edu   \n",
       "1007           guy@mit.edu;sp765@mit.edu;mpersu@mit.edu   \n",
       "1008  t-dodenn@microsoft.com;chiragramdas@gmail.com;...   \n",
       "1009  quantum.computing96@gmail.com;sankalp2621998@g...   \n",
       "1010  s.samadi@gmail.com;tao@gatech.edu;jamiemor@cis...   \n",
       "1011  phpchen@ucdavis.edu;sisidaisy@google.com;liyan...   \n",
       "\n",
       "                                          Subject Areas   Decision  \\\n",
       "0     Optimization/Submodular Optimization*; Optimiz...     Poster   \n",
       "1     Deep Learning*; Deep Learning/CNN Architecture...     Poster   \n",
       "2     Deep Learning/CNN Architectures*; Applications...     Poster   \n",
       "3     Probabilistic Methods/Distributed Inference*; ...     Poster   \n",
       "4     Applications/Computational Photography*; Appli...  Spotlight   \n",
       "5     Deep Learning/Generative Models*; Deep Learnin...     Poster   \n",
       "6     Applications/Time Series Analysis*; Algorithms...     Poster   \n",
       "7     Algorithms/Multitask and Transfer Learning*; A...  Spotlight   \n",
       "8     Algorithms/Online Learning*; Applications/Quan...     Poster   \n",
       "9     Reinforcement Learning and Planning/Reinforcem...     Poster   \n",
       "10                   Algorithms/Representation Learning     Poster   \n",
       "11    Deep Learning/Adversarial Networks*; Applicati...     Poster   \n",
       "12                               Theory/Learning Theory     Poster   \n",
       "13          Applications*; Applications/Computer Vision     Poster   \n",
       "14    Deep Learning/Biologically Plausible Deep Netw...     Poster   \n",
       "15    Applications/Computer Vision*; Deep Learning/C...     Poster   \n",
       "16    Algorithms/Sparse Coding and Dimensionality Ex...     Poster   \n",
       "17    Algorithms/Representation Learning*; Algorithm...     Poster   \n",
       "18    Algorithms/Stochastic Methods*; Reinforcement ...  Spotlight   \n",
       "19    Applications/Visual Scene Analysis and Interpr...     Poster   \n",
       "20                                Algorithms/Regression     Poster   \n",
       "21                               Theory/Learning Theory     Poster   \n",
       "22    Deep Learning/Adversarial Networks*; Algorithm...     Poster   \n",
       "23    Applications/Hardware and Systems*; Data, Comp...     Poster   \n",
       "24    Applications/Computer Vision*; Deep Learning/C...     Poster   \n",
       "25    Applications/Visual Question Answering*; Neuro...     Poster   \n",
       "26    Deep Learning*; Deep Learning/Recurrent Networ...     Poster   \n",
       "27    Applications/Computer Vision*; Applications/De...     Poster   \n",
       "28    Applications/Computer Vision*; Applications/Ro...     Poster   \n",
       "29                        Applications/Object Detection     Poster   \n",
       "...                                                 ...        ...   \n",
       "982                          Probabilistic Methods/MCMC     Poster   \n",
       "983                  Algorithms*; Algorithms/Regression  Spotlight   \n",
       "984   Probabilistic Methods/Variational Inference*; ...     Poster   \n",
       "985   Optimization/Non-Convex Optimization*; Algorit...       Oral   \n",
       "986   Probabilistic Methods/Graphical Models*; Data,...     Poster   \n",
       "987   Theory/Regularization*; Deep Learning/CNN Arch...     Poster   \n",
       "988                           Applications/Game Playing     Poster   \n",
       "989   Deep Learning*; Algorithms/Classification; Alg...     Poster   \n",
       "990   Optimization/Convex Optimization*; Algorithms/...  Spotlight   \n",
       "991   Algorithms/Representation Learning*; Applicati...     Poster   \n",
       "992                   Applications/Time Series Analysis  Spotlight   \n",
       "993   Deep Learning/Generative Models*; Deep Learnin...  Spotlight   \n",
       "994   Deep Learning/Adversarial Networks*; Applicati...     Poster   \n",
       "995   Algorithms/Sparsity and Compressed Sensing*; A...  Spotlight   \n",
       "996   Applications/Privacy, Anonymity, and Security*...     Poster   \n",
       "997   Probabilistic Methods/Hierarchical Models*; Ap...     Poster   \n",
       "998   Probabilistic Methods/Causal Inference*; Deep ...     Poster   \n",
       "999   Theory*; Algorithms/Components Analysis (e.g.,...     Poster   \n",
       "1000                                       Optimization     Poster   \n",
       "1001      Applications/Privacy, Anonymity, and Security     Poster   \n",
       "1002  Probabilistic Methods/Causal Inference*; Algor...  Spotlight   \n",
       "1003  Applications/Web Applications and Internet Dat...     Poster   \n",
       "1004  Algorithms/Components Analysis (e.g., CCA, ICA...     Poster   \n",
       "1005  Probabilistic Methods/Latent Variable Models*;...  Spotlight   \n",
       "1006  Theory/Learning Theory*; Probabilistic Methods...     Poster   \n",
       "1007  Algorithms/Components Analysis (e.g., CCA, ICA...     Poster   \n",
       "1008  Deep Learning/Efficient Inference Methods*; De...     Poster   \n",
       "1009                Reinforcement Learning and Planning     Poster   \n",
       "1010  Applications/Fairness, Accountability, and Tra...     Poster   \n",
       "1011           Applications/Natural Language Processing     Poster   \n",
       "\n",
       "                                   Primary Subject Area  \\\n",
       "0                  Optimization/Submodular Optimization   \n",
       "1                                         Deep Learning   \n",
       "2                       Deep Learning/CNN Architectures   \n",
       "3           Probabilistic Methods/Distributed Inference   \n",
       "4                Applications/Computational Photography   \n",
       "5                       Deep Learning/Generative Models   \n",
       "6                     Applications/Time Series Analysis   \n",
       "7            Algorithms/Multitask and Transfer Learning   \n",
       "8                            Algorithms/Online Learning   \n",
       "9     Reinforcement Learning and Planning/Reinforcem...   \n",
       "10                    Algorithms/Representation Learnin   \n",
       "11                   Deep Learning/Adversarial Networks   \n",
       "12                                Theory/Learning Theor   \n",
       "13                                         Applications   \n",
       "14    Deep Learning/Biologically Plausible Deep Netw...   \n",
       "15                         Applications/Computer Vision   \n",
       "16    Algorithms/Sparse Coding and Dimensionality Ex...   \n",
       "17                   Algorithms/Representation Learning   \n",
       "18                        Algorithms/Stochastic Methods   \n",
       "19    Applications/Visual Scene Analysis and Interpr...   \n",
       "20                                 Algorithms/Regressio   \n",
       "21                                Theory/Learning Theor   \n",
       "22                   Deep Learning/Adversarial Networks   \n",
       "23                    Applications/Hardware and Systems   \n",
       "24                         Applications/Computer Vision   \n",
       "25               Applications/Visual Question Answering   \n",
       "26                                        Deep Learning   \n",
       "27                         Applications/Computer Vision   \n",
       "28                         Applications/Computer Vision   \n",
       "29                         Applications/Object Detectio   \n",
       "...                                                 ...   \n",
       "982                           Probabilistic Methods/MCM   \n",
       "983                                          Algorithms   \n",
       "984         Probabilistic Methods/Variational Inference   \n",
       "985                Optimization/Non-Convex Optimization   \n",
       "986              Probabilistic Methods/Graphical Models   \n",
       "987                               Theory/Regularization   \n",
       "988                            Applications/Game Playin   \n",
       "989                                       Deep Learning   \n",
       "990                    Optimization/Convex Optimization   \n",
       "991                  Algorithms/Representation Learning   \n",
       "992                    Applications/Time Series Analysi   \n",
       "993                     Deep Learning/Generative Models   \n",
       "994                  Deep Learning/Adversarial Networks   \n",
       "995          Algorithms/Sparsity and Compressed Sensing   \n",
       "996       Applications/Privacy, Anonymity, and Security   \n",
       "997           Probabilistic Methods/Hierarchical Models   \n",
       "998              Probabilistic Methods/Causal Inference   \n",
       "999                                              Theory   \n",
       "1000                                        Optimizatio   \n",
       "1001       Applications/Privacy, Anonymity, and Securit   \n",
       "1002             Probabilistic Methods/Causal Inference   \n",
       "1003    Applications/Web Applications and Internet Data   \n",
       "1004  Algorithms/Components Analysis (e.g., CCA, ICA...   \n",
       "1005       Probabilistic Methods/Latent Variable Models   \n",
       "1006                             Theory/Learning Theory   \n",
       "1007  Algorithms/Components Analysis (e.g., CCA, ICA...   \n",
       "1008          Deep Learning/Efficient Inference Methods   \n",
       "1009                 Reinforcement Learning and Plannin   \n",
       "1010  Applications/Fairness, Accountability, and Tra...   \n",
       "1011            Applications/Natural Language Processin   \n",
       "\n",
       "           Top-level Primary Subject Area  \\\n",
       "0                            Optimization   \n",
       "1                           Deep Learning   \n",
       "2                           Deep Learning   \n",
       "3                   Probabilistic Methods   \n",
       "4                            Applications   \n",
       "5                           Deep Learning   \n",
       "6                            Applications   \n",
       "7                              Algorithms   \n",
       "8                              Algorithms   \n",
       "9     Reinforcement Learning and Planning   \n",
       "10                             Algorithms   \n",
       "11                          Deep Learning   \n",
       "12                                 Theory   \n",
       "13                           Applications   \n",
       "14                          Deep Learning   \n",
       "15                           Applications   \n",
       "16                             Algorithms   \n",
       "17                             Algorithms   \n",
       "18                             Algorithms   \n",
       "19                           Applications   \n",
       "20                             Algorithms   \n",
       "21                                 Theory   \n",
       "22                          Deep Learning   \n",
       "23                           Applications   \n",
       "24                           Applications   \n",
       "25                           Applications   \n",
       "26                          Deep Learning   \n",
       "27                           Applications   \n",
       "28                           Applications   \n",
       "29                           Applications   \n",
       "...                                   ...   \n",
       "982                 Probabilistic Methods   \n",
       "983                            Algorithms   \n",
       "984                 Probabilistic Methods   \n",
       "985                          Optimization   \n",
       "986                 Probabilistic Methods   \n",
       "987                                Theory   \n",
       "988                          Applications   \n",
       "989                         Deep Learning   \n",
       "990                          Optimization   \n",
       "991                            Algorithms   \n",
       "992                          Applications   \n",
       "993                         Deep Learning   \n",
       "994                         Deep Learning   \n",
       "995                            Algorithms   \n",
       "996                          Applications   \n",
       "997                 Probabilistic Methods   \n",
       "998                 Probabilistic Methods   \n",
       "999                                Theory   \n",
       "1000                          Optimizatio   \n",
       "1001                         Applications   \n",
       "1002                Probabilistic Methods   \n",
       "1003                         Applications   \n",
       "1004                           Algorithms   \n",
       "1005                Probabilistic Methods   \n",
       "1006                               Theory   \n",
       "1007                           Algorithms   \n",
       "1008                        Deep Learning   \n",
       "1009   Reinforcement Learning and Plannin   \n",
       "1010                         Applications   \n",
       "1011                         Applications   \n",
       "\n",
       "                                                    bow   pid  \\\n",
       "0     [effici, algorithm, non, convex, isoton, regre...    29   \n",
       "1     [structur, awar, convolut, neural, network, co...    33   \n",
       "2     [kalman, normal, indispens, compon, batch, nor...    34   \n",
       "3     [hogwild, gibb, panaccur, asynchron, gibb, sam...    37   \n",
       "4     [text, adapt, gener, adversari, network, manip...    40   \n",
       "5     [introva, introspect, variat, autoencod, photo...    59   \n",
       "6     [doubli, robust, bayesian, infer, non, station...    68   \n",
       "7     [adapt, deep, embed, synthesi, method, shot, i...    75   \n",
       "8     [gener, invers, optim, onlin, learn, invers, o...    77   \n",
       "9     [polici, polici, gradient, theorem, use, empha...    85   \n",
       "10    [supervis, autoencod, improv, gener, perform, ...    88   \n",
       "11    [visual, object, network, imag, gener, disenta...    92   \n",
       "12    [understand, weight, normal, deep, neural, net...    95   \n",
       "13    [learn, pipelin, limit, data, domain, knowledg...    99   \n",
       "14    [learn, long, rang, spatial, depend, horizont,...   102   \n",
       "15    [joint, sub, band, learn, cliqu, structur, wav...   110   \n",
       "16    [fast, similar, search, via, optim, spars, lif...   142   \n",
       "17    [learn, deep, disentangl, embed, statist, loss...   145   \n",
       "18    [geometr, coupl, mont, carlo, sampl, mont, car...   153   \n",
       "19    [cooper, holist, 3d, scene, understand, singl,...   175   \n",
       "20    [effici, prune, algorithm, robust, isoton, reg...   177   \n",
       "21    [pac, learn, presenc, adversari, exist, evas, ...   178   \n",
       "22    [spars, dnn, improv, adversari, robust, deep, ...   182   \n",
       "23    [snap, ml, hierarch, framework, machin, learn,...   185   \n",
       "24    [see, think, disentangl, semant, scene, comple...   186   \n",
       "25    [chain, reason, visual, question, answer, reas...   187   \n",
       "26    [sigsoftmax, reanalysi, softmax, bottleneck, s...   188   \n",
       "27    [deep, non, blind, deconvolut, via, gener, low...   191   \n",
       "28    [probabilist, pose, graph, optim, via, bingham...   192   \n",
       "29    [metaanchor, learn, detect, object, custom, an...   207   \n",
       "...                                                 ...   ...   \n",
       "982   [thermostat, assist, continu, temper, hamilton...  6787   \n",
       "983   [robust, subspac, approxim, stream, studi, rob...  6793   \n",
       "984   [mean, field, stochast, blockmodel, optim, lan...  6802   \n",
       "985   [analysi, krylov, subspac, solut, regular, non...  6832   \n",
       "986   [autoconj, recogn, exploit, conjugaci, without...  6836   \n",
       "987   [dropblock, regular, method, convolut, network...  6839   \n",
       "988   [forward, model, partial, observ, strategi, ga...  6843   \n",
       "989   [friend, like, need, adversari, vulner, deep, ...  6847   \n",
       "990   [decentr, random, faster, algorithm, wasserste...  6859   \n",
       "991   [joint, autoregress, hierarch, prior, learn, i...  6863   \n",
       "992   [learn, tempor, point, process, via, reinforc,...  6874   \n",
       "993   [bia, gener, deep, gener, model, empir, studi,...  6882   \n",
       "994   [fast, effect, robust, certif, present, new, m...  6892   \n",
       "995   [support, recoveri, orthogon, match, pursuit, ...  6901   \n",
       "996   [differenti, privat, chang, point, detect, cha...  6905   \n",
       "997   [multi, valu, rule, set, interpret, classif, f...  6913   \n",
       "998   [domain, adapt, use, causal, infer, predict, i...  6921   \n",
       "999   [smooth, analysi, discret, tensor, decomposit,...  6923   \n",
       "1000  [mixlasso, gener, mix, regress, via, convex, a...  6961   \n",
       "1001  [semidefinit, relax, certifi, robust, adversar...  6968   \n",
       "1002  [remov, hidden, confound, experiment, ground, ...  6972   \n",
       "1003  [topkapi, parallel, fast, sketch, find, top, f...  6978   \n",
       "1004  [contrast, learn, pairwis, measur, learn, pair...  7985   \n",
       "1005  [point, process, latent, variabl, model, freel...  7992   \n",
       "1006  [comput, statist, effici, learn, bay, net, use...  7994   \n",
       "1007  [spars, pca, spars, linear, regress, spars, pr...  7997   \n",
       "1008  [sequenti, data, classif, resourc, constrain, ...  8002   \n",
       "1009  [transfer, deep, reactiv, polici, mdp, plan, d...  8009   \n",
       "1010  [price, fair, pca, one, extra, dimens, thi, pa...  8034   \n",
       "1011  [groupreduc, block, wise, low, rank, approxim,...  8035   \n",
       "\n",
       "                                                   tpms   tsne_all  tsne_tpms  \\\n",
       "0     [0.724210006, 0.547847061, 0.62121431, 0.69992...  29.950420  41.906616   \n",
       "1     [0.722796601, 0.7524726279999999, 0.681080612,...  69.435448 -41.231922   \n",
       "2     [0.605652029, 0.624528822, 0.5549479039999999,...  75.101242 -22.875866   \n",
       "3     [0.6039084920000001, 0.571028136, 0.547187392,... -42.259544  22.692909   \n",
       "4     [0.6074082789999999, 0.604121554, 0.5843663610...  -8.646683 -43.590607   \n",
       "5     [0.554898813, 0.566786583, 0.514959909, 0.5606...  81.031715 -14.190269   \n",
       "6     [0.811906661, 0.7286812490000001, 0.745909935,... -18.716530  -3.146081   \n",
       "7     [0.7246898359999999, 0.74860931, 0.72164041200... -55.623451 -29.995140   \n",
       "8     [0.8553071390000001, 0.729569048, 0.771284843,... -79.361519  25.245207   \n",
       "9     [0.5770863589999999, 0.523376441, 0.518179388,...  44.501297   7.835011   \n",
       "10    [0.7831208590000001, 0.8086628229999999, 0.745... -58.400303 -27.623331   \n",
       "11    [0.622592223, 0.620137725, 0.574635252, 0.6193...  85.215065 -45.918297   \n",
       "12    [0.644970711, 0.6021990779999999, 0.611452154,...   9.355120   0.585828   \n",
       "13    [0.825202962, 0.8357769540000001, 0.8245410609... -15.508667 -35.415489   \n",
       "14    [0.753889782, 0.8060686090000001, 0.7139329390...  66.520264 -39.277554   \n",
       "15    [0.665462302, 0.631348907, 0.61443569, 0.65938...  -3.620618 -41.783928   \n",
       "16    [0.8577442009999999, 0.7920245159999999, 0.809... -59.549507 -19.159504   \n",
       "17    [0.801685634, 0.791540459, 0.772199449, 0.8187... -52.455151 -29.709421   \n",
       "18    [0.796080575, 0.669703717, 0.714382987, 0.7818... -72.128998  22.797417   \n",
       "19    [0.635211113, 0.587038424, 0.582188994, 0.6233...  -7.480874 -46.575882   \n",
       "20    [0.8350809440000001, 0.641266087, 0.761110935,... -74.375404  41.805172   \n",
       "21    [0.5843463000000001, 0.563068797, 0.533589984,...   9.359765 -20.007828   \n",
       "22    [0.666966905, 0.637015755, 0.638722607, 0.7032...  84.842842 -20.159740   \n",
       "23    [0.657971973, 0.853205806, 0.618791222, 0.6497... -16.822359 -20.884203   \n",
       "24    [0.657856715, 0.632397676, 0.6396587229999999,...  -4.536843 -46.435524   \n",
       "25    [0.632062365, 0.6729400529999999, 0.603445259,... -10.336796 -36.345360   \n",
       "26    [0.692489644, 0.790134204, 0.660755629, 0.7194...  69.954987 -24.284136   \n",
       "27    [0.562258779, 0.5202836, 0.506214686, 0.550357...  -3.312739 -42.153278   \n",
       "28    [0.9113688670000001, 0.7563436379999999, 0.820...  -2.593879  27.874113   \n",
       "29    [0.620705712, 0.593533387, 0.572714624, 0.6164...  -6.911834 -44.603474   \n",
       "...                                                 ...        ...        ...   \n",
       "982   [0.646289553, 0.620857109, 0.586481252, 0.6541... -43.545441  -4.772652   \n",
       "983   [0.540987701, 0.441798132, 0.49352610399999997... -75.541176  31.828382   \n",
       "984   [0.735002521, 0.627056098, 0.647996389, 0.7320... -45.091202  22.743847   \n",
       "985   [0.644204279, 0.46829059700000003, 0.536020003...  26.129072  43.834412   \n",
       "986   [0.644937403, 0.646330124, 0.606580474, 0.6317... -36.022869  -2.977412   \n",
       "987   [0.602325926, 0.709435875, 0.611376699, 0.6140...  10.156830 -40.257950   \n",
       "988   [0.64940197, 0.696797065, 0.612499372, 0.66309... -10.947182 -31.871689   \n",
       "989   [0.596239485, 0.552854089, 0.56523045, 0.61261...  69.137093 -26.654100   \n",
       "990   [0.649590907, 0.572511066, 0.579816594, 0.6330...  32.173798  28.452133   \n",
       "991   [0.5645583710000001, 0.599846334, 0.522823875,... -52.424301 -30.890600   \n",
       "992   [0.6848055690000001, 0.606161123, 0.618028853,... -19.862894   8.033325   \n",
       "993   [0.825245676, 0.77820804, 0.764052464, 0.83451...  80.826553 -38.422794   \n",
       "994   [0.656920721, 0.7048807429999999, 0.624150393,...  84.853836 -20.459106   \n",
       "995   [0.6322439089999999, 0.5179587760000001, 0.563... -71.281883  30.983622   \n",
       "996   [0.6977355690000001, 0.557927934, 0.63827413, ... -28.408152  34.926235   \n",
       "997   [0.823699588, 0.7256162290000001, 0.770973646,... -37.061535  16.019241   \n",
       "998   [0.534160482, 0.482813768, 0.514349219, 0.5274... -33.443409  13.715412   \n",
       "999   [0.693092713, 0.629186489, 0.656472765, 0.7012...   4.982391  19.488535   \n",
       "1000  [0.791815187, 0.657667486, 0.70105964, 0.77798...  11.150247  29.388924   \n",
       "1001  [0.612903855, 0.584632164, 0.580678234, 0.6383... -26.983023 -19.791059   \n",
       "1002  [0.586181571, 0.490689461, 0.549189971, 0.5911... -33.386219  14.227854   \n",
       "1003  [0.672761353, 0.6915534390000001, 0.673524338,... -24.045568   1.927942   \n",
       "1004  [0.801794205, 0.6445370810000001, 0.70768539, ... -70.215393  24.161211   \n",
       "1005  [0.78844959, 0.730344946, 0.7138572390000001, ... -47.077015  -6.283218   \n",
       "1006  [0.442452024, 0.376913364, 0.45425219, 0.45383...  13.572625  14.079021   \n",
       "1007  [0.755127242, 0.609168548, 0.665014251, 0.7336... -70.626175  30.425714   \n",
       "1008  [0.849686171, 0.9341852970000001, 0.7916773859...  77.401146 -28.128359   \n",
       "1009  [0.7646644690000001, 0.7638223829999999, 0.729...  41.460049   4.912152   \n",
       "1010  [0.7302362170000001, 0.631884585, 0.691013077,... -22.797361  26.325262   \n",
       "1011  [0.7068314809999999, 0.8144392220000001, 0.691... -13.926091 -24.498652   \n",
       "\n",
       "       Session  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4     D3_S2_T2  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7     D3_S1_T1  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10         NaN  \n",
       "11         NaN  \n",
       "12         NaN  \n",
       "13         NaN  \n",
       "14         NaN  \n",
       "15         NaN  \n",
       "16         NaN  \n",
       "17         NaN  \n",
       "18    D2_S2_T1  \n",
       "19         NaN  \n",
       "20         NaN  \n",
       "21         NaN  \n",
       "22         NaN  \n",
       "23         NaN  \n",
       "24         NaN  \n",
       "25         NaN  \n",
       "26         NaN  \n",
       "27         NaN  \n",
       "28         NaN  \n",
       "29         NaN  \n",
       "...        ...  \n",
       "982        NaN  \n",
       "983   D3_S1_T3  \n",
       "984        NaN  \n",
       "985   D2_S2_T3  \n",
       "986        NaN  \n",
       "987        NaN  \n",
       "988        NaN  \n",
       "989        NaN  \n",
       "990   D3_S2_T3  \n",
       "991        NaN  \n",
       "992   D2_S1_T2  \n",
       "993   D2_S2_T2  \n",
       "994        NaN  \n",
       "995   D2_S2_T3  \n",
       "996        NaN  \n",
       "997        NaN  \n",
       "998        NaN  \n",
       "999        NaN  \n",
       "1000       NaN  \n",
       "1001       NaN  \n",
       "1002  D3_S1_T1  \n",
       "1003       NaN  \n",
       "1004       NaN  \n",
       "1005  D1_S2_T1  \n",
       "1006       NaN  \n",
       "1007       NaN  \n",
       "1008       NaN  \n",
       "1009       NaN  \n",
       "1010       NaN  \n",
       "1011       NaN  \n",
       "\n",
       "[1012 rows x 14 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.to_csv('session_arrangement_with_oral_and_spot_final_hanna.csv', index=False, columns=['Paper ID', 'Paper Title', 'Abstract', 'Subject Areas', \n",
    "                                                                      'Primary Subject Area', 'Top-level Primary Subject Area',\n",
    "                                                                      'tsne_all', 'tsne_tpms', 'Decision', 'Session'], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving day 4 orals and spotlight to 1.\n",
    "poster_df = tmp.copy()\n",
    "poster_df['PosterSession'] = poster_df['Session'].apply(lambda x: 0 if isinstance(x, float) else int(x.split('_')[0][1])*2 + int(x.split('_')[1][1])-2)\n",
    "# poster_df['PosterSession'] = poster_df['PosterSession'].apply(lambda x: 1 if x == 4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper ID</th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Emails</th>\n",
       "      <th>Subject Areas</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Primary Subject Area</th>\n",
       "      <th>Top-level Primary Subject Area</th>\n",
       "      <th>bow</th>\n",
       "      <th>pid</th>\n",
       "      <th>tpms</th>\n",
       "      <th>tsne_all</th>\n",
       "      <th>tsne_tpms</th>\n",
       "      <th>Session</th>\n",
       "      <th>PosterSession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>267</td>\n",
       "      <td>(Probably) Concave Graph Matching</td>\n",
       "      <td>In this paper we address the graph matching pr...</td>\n",
       "      <td>haggai.maron@weizmann.ac.il;yaron.lipman@weizm...</td>\n",
       "      <td>Optimization/Convex Optimization*; Optimizatio...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization/Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[probabl, concav, graph, match, thi, paper, ad...</td>\n",
       "      <td>267</td>\n",
       "      <td>[0.858271366, 0.682665183, 0.7683895479999999,...</td>\n",
       "      <td>-67.131195</td>\n",
       "      <td>29.937187</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>576</td>\n",
       "      <td>Efficient nonmyopic batch active search</td>\n",
       "      <td>Active search is a learning paradigm for activ...</td>\n",
       "      <td>jiang.s@wustl.edu;luizgustavo@wustl.edu;mbabbo...</td>\n",
       "      <td>Algorithms/Active Learning</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Active Learnin</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[effici, nonmyop, batch, activ, search, activ,...</td>\n",
       "      <td>576</td>\n",
       "      <td>[0.5437475, 0.48220424799999995, 0.508575226, ...</td>\n",
       "      <td>60.245289</td>\n",
       "      <td>9.279699</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>597</td>\n",
       "      <td>Interactive Structure Learning with Structural...</td>\n",
       "      <td>In this work, we introduce interactive structu...</td>\n",
       "      <td>ctosh@cs.ucsd.edu;dasgupta@cs.ucsd.edu</td>\n",
       "      <td>Algorithms/Active Learning*; Algorithms/Semi-S...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Active Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[interact, structur, learn, structur, queri, c...</td>\n",
       "      <td>597</td>\n",
       "      <td>[0.529437719, 0.45932953600000004, 0.490521479...</td>\n",
       "      <td>59.319515</td>\n",
       "      <td>37.968044</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1026</td>\n",
       "      <td>Discovery of Latent 3D Keypoints via End-to-en...</td>\n",
       "      <td>This paper presents KeypointNet, an end-to-end...</td>\n",
       "      <td>supasorn@gmail.com;snavely@google.com;tompson@...</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Oral</td>\n",
       "      <td>Applications/Computer Visio</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[discoveri, latent, 3d, keypoint, via, end, en...</td>\n",
       "      <td>1026</td>\n",
       "      <td>[0.581163477, 0.5984493120000001, 0.542658568,...</td>\n",
       "      <td>9.342001</td>\n",
       "      <td>-47.488724</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1099</td>\n",
       "      <td>Norm matters: efficient and accurate normaliza...</td>\n",
       "      <td>Over the past few years, Batch-Normalization h...</td>\n",
       "      <td>elad.hoffer@gmail.com;ron.banner@intel.com;ita...</td>\n",
       "      <td>Deep Learning*; Deep Learning/CNN Architecture...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[norm, matter, effici, accur, normal, scheme, ...</td>\n",
       "      <td>1099</td>\n",
       "      <td>[0.546826715, 0.578286664, 0.504709097, 0.5672...</td>\n",
       "      <td>-26.945894</td>\n",
       "      <td>-22.626886</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1143</td>\n",
       "      <td>Learning to Reconstruct Shapes from Unseen Cat...</td>\n",
       "      <td>From a single view, humans are able to halluci...</td>\n",
       "      <td>xiuming@mit.edu;ztzhang@mit.edu;ckzhang@mit.ed...</td>\n",
       "      <td>Applications/Object Recognition*; Applications...</td>\n",
       "      <td>Oral</td>\n",
       "      <td>Applications/Object Recognition</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[learn, reconstruct, shape, unseen, categori, ...</td>\n",
       "      <td>1143</td>\n",
       "      <td>[0.572495249, 0.567489183, 0.534011075, 0.5716...</td>\n",
       "      <td>10.185015</td>\n",
       "      <td>-47.350956</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1147</td>\n",
       "      <td>Smoothed analysis of the low-rank approach for...</td>\n",
       "      <td>We consider semidefinite programs (SDPs) of si...</td>\n",
       "      <td>tpumir@princeton.edu;sjelassi@princeton.edu;nb...</td>\n",
       "      <td>Optimization*; Optimization/Convex Optimizatio...</td>\n",
       "      <td>Oral</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[smooth, analysi, low, rank, approach, smooth,...</td>\n",
       "      <td>1147</td>\n",
       "      <td>[0.460976129, 0.33447025, 0.36871131700000004,...</td>\n",
       "      <td>-70.034546</td>\n",
       "      <td>43.803680</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1446</td>\n",
       "      <td>Optimal Algorithms for Non-Smooth Distributed ...</td>\n",
       "      <td>In this work, we consider the distributed opti...</td>\n",
       "      <td>kevin.scaman@gmail.com;francis.bach@inria.fr;s...</td>\n",
       "      <td>Optimization/Convex Optimization*; Application...</td>\n",
       "      <td>Oral</td>\n",
       "      <td>Optimization/Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[optim, algorithm, non, smooth, distribut, opt...</td>\n",
       "      <td>1446</td>\n",
       "      <td>[0.637403434, 0.535576182, 0.5500409629999999,...</td>\n",
       "      <td>-67.139160</td>\n",
       "      <td>45.827702</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1878</td>\n",
       "      <td>DeepProbLog:  Neural Probabilistic Logic Progr...</td>\n",
       "      <td>We introduce DeepProbLog, a probabilistic logi...</td>\n",
       "      <td>robin.manhaeve@cs.kuleuven.be;sebastijan.duman...</td>\n",
       "      <td>Algorithms/Relational Learning*; Deep Learning...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Relational Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[deepproblog, neural, probabilist, logic, prog...</td>\n",
       "      <td>1878</td>\n",
       "      <td>[0.6685511, 0.718956288, 0.641330434, 0.673511...</td>\n",
       "      <td>53.303432</td>\n",
       "      <td>-30.856102</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1881</td>\n",
       "      <td>Convergence of Cubic Regularization for Noncon...</td>\n",
       "      <td>Cubic-regularized Newton's method (CR) is a po...</td>\n",
       "      <td>zhou.1172@osu.edu;wang.10982@osu.edu;liang.889...</td>\n",
       "      <td>Optimization*; Optimization/Non-Convex Optimiz...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[converg, cubic, regular, nonconvex, optim, kl...</td>\n",
       "      <td>1881</td>\n",
       "      <td>[0.7832019729999999, 0.517215119, 0.519890496,...</td>\n",
       "      <td>-69.925735</td>\n",
       "      <td>46.154724</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1920</td>\n",
       "      <td>Direct Runge-Kutta Discretization Achieves Acc...</td>\n",
       "      <td>We study gradient-based optimization methods o...</td>\n",
       "      <td>jzhzhang@mit.edu;aryanm@mit.edu;suvrit@mit.edu...</td>\n",
       "      <td>Optimization/Convex Optimization*; Algorithms/...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization/Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[direct, rung, kutta, discret, achiev, acceler...</td>\n",
       "      <td>1920</td>\n",
       "      <td>[0.6863303190000001, 0.49512777799999996, 0.54...</td>\n",
       "      <td>-67.139565</td>\n",
       "      <td>44.497669</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>2171</td>\n",
       "      <td>Limited Memory Kelley's Method Converges for C...</td>\n",
       "      <td>The original simplicial method ({\\sc OSM}), a ...</td>\n",
       "      <td>sz557@cornell.edu;swatig@gatech.edu;udell@corn...</td>\n",
       "      <td>Optimization/Convex Optimization*; Optimizatio...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization/Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[limit, memori, kelley, method, converg, compo...</td>\n",
       "      <td>2171</td>\n",
       "      <td>[0.588896619, 0.477438454, 0.5104155429999999,...</td>\n",
       "      <td>-67.109413</td>\n",
       "      <td>43.639351</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2298</td>\n",
       "      <td>Data-Efficient Model-based Reinforcement Learn...</td>\n",
       "      <td>Model-based reinforcement learning (RL) algori...</td>\n",
       "      <td>kchua@berkeley.edu;roberto.calandra@berkeley.e...</td>\n",
       "      <td>Reinforcement Learning and Planning/Model-Base...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Reinforcement Learning and Planning/Model-Based R</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>[data, effici, model, base, reinforc, learn, d...</td>\n",
       "      <td>2298</td>\n",
       "      <td>[0.693454531, 0.674571321, 0.635436176, 0.6904...</td>\n",
       "      <td>83.043457</td>\n",
       "      <td>2.235853</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>2440</td>\n",
       "      <td>LAG: Lazily Aggregated Gradient for Communicat...</td>\n",
       "      <td>This paper presents a new class of gradient me...</td>\n",
       "      <td>chen3827@umn.edu;georgios@umn.edu;nudtsuntao@1...</td>\n",
       "      <td>Optimization*; Optimization/Convex Optimization</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[lag, lazili, aggreg, gradient, commun, effici...</td>\n",
       "      <td>2440</td>\n",
       "      <td>[0.628226054, 0.583180337, 0.527631899, 0.5999...</td>\n",
       "      <td>-69.777893</td>\n",
       "      <td>49.156544</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2491</td>\n",
       "      <td>Contour location via entropy reduction leverag...</td>\n",
       "      <td>We introduce an algorithm to locate contours o...</td>\n",
       "      <td>noll@mit.edu;rlam@mit.edu;kwillcox@mit.edu</td>\n",
       "      <td>Algorithms/Classification*; Algorithms/Active ...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Classification</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[contour, locat, via, entropi, reduct, leverag...</td>\n",
       "      <td>2491</td>\n",
       "      <td>[0.7669138120000001, 0.643375559, 0.697614418,...</td>\n",
       "      <td>48.901409</td>\n",
       "      <td>-1.069540</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2501</td>\n",
       "      <td>Multiple-Step Greedy Policies in Approximate a...</td>\n",
       "      <td>Multiple-step lookahead policies have demonstr...</td>\n",
       "      <td>jonathan.efroni@gmail.com;gald@tx.technion.ac....</td>\n",
       "      <td>Reinforcement Learning and Planning/Reinforcem...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Reinforcement Learning and Planning/Reinforcem...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>[multipl, step, greedi, polici, approxim, onli...</td>\n",
       "      <td>2501</td>\n",
       "      <td>[0.594272799, 0.518109147, 0.561630995, 0.5968...</td>\n",
       "      <td>80.190575</td>\n",
       "      <td>8.092484</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>2562</td>\n",
       "      <td>Hyperbolic Neural Networks</td>\n",
       "      <td>Hyperbolic spaces have recently gained momentu...</td>\n",
       "      <td>octavian.ganea@inf.ethz.ch;gary.becigneul@inf....</td>\n",
       "      <td>Deep Learning*; Applications/Natural Language ...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[hyperbol, neural, network, hyperbol, space, r...</td>\n",
       "      <td>2562</td>\n",
       "      <td>[0.7522543740000001, 0.736023832, 0.697689227,...</td>\n",
       "      <td>-26.121195</td>\n",
       "      <td>-17.066725</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2582</td>\n",
       "      <td>Fully Understanding The Hashing Trick</td>\n",
       "      <td>Feature hashing, also known as {\\em the hashin...</td>\n",
       "      <td>lior.kamma@cs.au.dk;cfreksen@cs.au.dk;larsen@c...</td>\n",
       "      <td>Algorithms/Similarity and Distance Learning*; ...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Similarity and Distance Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[fulli, understand, hash, trick, featur, hash,...</td>\n",
       "      <td>2582</td>\n",
       "      <td>[0.521237043, 0.44199288600000003, 0.471181035...</td>\n",
       "      <td>46.861782</td>\n",
       "      <td>33.453499</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2641</td>\n",
       "      <td>Low-rank Interaction with Sparse Additive Effe...</td>\n",
       "      <td>Many applications of machine learning involve ...</td>\n",
       "      <td>genevieve.robin@polytechnique.edu;htwai@asu.ed...</td>\n",
       "      <td>Algorithms/Missing Data*; Optimization/Convex ...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Missing Data</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[low, rank, interact, spars, addit, effect, mo...</td>\n",
       "      <td>2641</td>\n",
       "      <td>[0.81091035, 0.666503034, 0.688653182, 0.75665...</td>\n",
       "      <td>46.222477</td>\n",
       "      <td>31.233282</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2665</td>\n",
       "      <td>A Simple Proximal Stochastic Gradient Method f...</td>\n",
       "      <td>We analyze stochastic gradient algorithms for ...</td>\n",
       "      <td>zz-li14@mails.tsinghua.edu.cn;lijian83@mail.ts...</td>\n",
       "      <td>Optimization*; Algorithms/Stochastic Methods; ...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[simpl, proxim, stochast, gradient, method, no...</td>\n",
       "      <td>2665</td>\n",
       "      <td>[0.5443507870000001, 0.389543226, 0.379131083,...</td>\n",
       "      <td>-69.883400</td>\n",
       "      <td>46.994019</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2861</td>\n",
       "      <td>Binary Classification from Positive-Confidence...</td>\n",
       "      <td>Reducing labeling costs in supervised learning...</td>\n",
       "      <td>ishida@ms.k.u-tokyo.ac.jp;gang.niu@riken.jp;su...</td>\n",
       "      <td>Algorithms/Semi-Supervised Learning</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Semi-Supervised Learnin</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[binari, classif, posit, confid, data, reduc, ...</td>\n",
       "      <td>2861</td>\n",
       "      <td>[0.645438133, 0.590653698, 0.608418902, 0.6539...</td>\n",
       "      <td>48.151466</td>\n",
       "      <td>-12.391636</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2893</td>\n",
       "      <td>Constructing Fast Network through Deconstructi...</td>\n",
       "      <td>Convolutional neural networks have achieved gr...</td>\n",
       "      <td>jyh2986@kaist.ac.kr;junmo.kim@kaist.ac.kr</td>\n",
       "      <td>Deep Learning/CNN Architectures*; Algorithms/C...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning/CNN Architectures</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[construct, fast, network, deconstruct, convol...</td>\n",
       "      <td>2893</td>\n",
       "      <td>[0.5751594329999999, 0.662647356, 0.536300601,...</td>\n",
       "      <td>-45.007767</td>\n",
       "      <td>-41.029495</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>2974</td>\n",
       "      <td>Learning to Infer Graphics Programs from Hand-...</td>\n",
       "      <td>We introduce a model that learns to convert si...</td>\n",
       "      <td>ellisk@mit.edu;daniel_ritchie@brown.edu;asolar...</td>\n",
       "      <td>Deep Learning/Program Induction</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning/Program Inductio</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[learn, infer, graphic, program, hand, drawn, ...</td>\n",
       "      <td>2974</td>\n",
       "      <td>[0.559116815, 0.572513619, 0.530804837, 0.5530...</td>\n",
       "      <td>-32.042522</td>\n",
       "      <td>-30.779812</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>3035</td>\n",
       "      <td>ResNet with one-neuron hidden layers is a Univ...</td>\n",
       "      <td>We demonstrate that a very deep ResNet with st...</td>\n",
       "      <td>hongzhou.lin@inria.fr;stefje@csail.mit.edu</td>\n",
       "      <td>Deep Learning*; Theory/Learning Theory</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[resnet, one, neuron, hidden, layer, univers, ...</td>\n",
       "      <td>3035</td>\n",
       "      <td>[0.661626699, 0.66508273, 0.620017194, 0.73787...</td>\n",
       "      <td>-26.482437</td>\n",
       "      <td>-21.562668</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>3551</td>\n",
       "      <td>A Simple Unified Framework for Detecting Out-o...</td>\n",
       "      <td>Detecting test samples drawn sufficiently far ...</td>\n",
       "      <td>kiminlee@kaist.ac.kr;kibok@umich.edu;honglak@e...</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learnin</td>\n",
       "      <td>Deep Learnin</td>\n",
       "      <td>[simpl, unifi, framework, detect, distribut, s...</td>\n",
       "      <td>3551</td>\n",
       "      <td>[0.6365459960000001, 0.63109569, 0.604992714, ...</td>\n",
       "      <td>-23.449856</td>\n",
       "      <td>-27.983456</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>3682</td>\n",
       "      <td>Stochastic Chebyshev Gradient Descent for Spec...</td>\n",
       "      <td>A large class of machine learning techniques r...</td>\n",
       "      <td>hawki17@kaist.ac.kr;haimav@post.tau.ac.il;jinw...</td>\n",
       "      <td>Optimization*; Algorithms/Stochastic Methods</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[stochast, chebyshev, gradient, descent, spect...</td>\n",
       "      <td>3682</td>\n",
       "      <td>[0.73760857, 0.615259542, 0.645803433, 0.70288...</td>\n",
       "      <td>-69.869652</td>\n",
       "      <td>44.747562</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>3833</td>\n",
       "      <td>Learning Loop Invariants for Program Verification</td>\n",
       "      <td>A fundamental problem in program verification ...</td>\n",
       "      <td>xsi@seas.upenn.edu;hanjundai@gatech.edu;rmukun...</td>\n",
       "      <td>Deep Learning/Program Induction*; Deep Learnin...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning/Program Induction</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[learn, loop, invari, program, verif, fundamen...</td>\n",
       "      <td>3833</td>\n",
       "      <td>[0.6634387389999999, 0.709670893, 0.639796905,...</td>\n",
       "      <td>-32.456005</td>\n",
       "      <td>-30.657389</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>4859</td>\n",
       "      <td>Learning Libraries of Subroutines for Neurally...</td>\n",
       "      <td>Successful approaches to program induction req...</td>\n",
       "      <td>ellisk@mit.edu;lucasem@mit.edu;mathias.sable-m...</td>\n",
       "      <td>Deep Learning/Program Induction</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning/Program Inductio</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[learn, librari, subroutin, neurally–guid, bay...</td>\n",
       "      <td>4859</td>\n",
       "      <td>[0.584069737, 0.6295379489999999, 0.5559945, 0...</td>\n",
       "      <td>-32.058723</td>\n",
       "      <td>-30.780697</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>4901</td>\n",
       "      <td>Robust Hypothesis Testing Using Wasserstein Un...</td>\n",
       "      <td>We develop a novel computationally efficient a...</td>\n",
       "      <td>rgao32@gatech.edu;lxie49@gatech.edu;yao.xie@is...</td>\n",
       "      <td>Optimization*; Theory/Frequentist Statistics; ...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[robust, hypothesi, test, use, wasserstein, un...</td>\n",
       "      <td>4901</td>\n",
       "      <td>[0.8681026629999999, 0.6750643359999999, 0.786...</td>\n",
       "      <td>-70.040543</td>\n",
       "      <td>26.340662</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>5026</td>\n",
       "      <td>Sample-Efficient Reinforcement Learning with S...</td>\n",
       "      <td>There is growing interest in combining model-f...</td>\n",
       "      <td>jacobbuckman@gmail.com;mail@danijar.com;gjt@go...</td>\n",
       "      <td>Reinforcement Learning and Planning/Model-Base...</td>\n",
       "      <td>Oral</td>\n",
       "      <td>Reinforcement Learning and Planning/Model-Base...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>[sampl, effici, reinforc, learn, stochast, ens...</td>\n",
       "      <td>5026</td>\n",
       "      <td>[0.590708845, 0.592122578, 0.559167734, 0.5872...</td>\n",
       "      <td>84.390198</td>\n",
       "      <td>2.709555</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>5045</td>\n",
       "      <td>Bilevel learning of the Group Lasso structure</td>\n",
       "      <td>Regression with group-sparsity penalty plays a...</td>\n",
       "      <td>jordan.frecon@iit.it;saverio.salzo@iit.it;mass...</td>\n",
       "      <td>Algorithms/Model Selection and Structure Learn...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Model Selection and Structure Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[bilevel, learn, group, lasso, structur, regre...</td>\n",
       "      <td>5045</td>\n",
       "      <td>[0.783325127, 0.626205489, 0.6653859129999999,...</td>\n",
       "      <td>47.347546</td>\n",
       "      <td>30.596678</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>5129</td>\n",
       "      <td>Wasserstein Distributionally Robust Kalman Fil...</td>\n",
       "      <td>We study a distributionally robust mean square...</td>\n",
       "      <td>soroosh.shafiee@epfl.ch;viet-anh.nguyen@epfl.c...</td>\n",
       "      <td>Optimization/Convex Optimization*; Reinforceme...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization/Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[wasserstein, distribut, robust, kalman, filte...</td>\n",
       "      <td>5129</td>\n",
       "      <td>[0.8379091000000001, 0.66053631, 0.722060905, ...</td>\n",
       "      <td>-67.129349</td>\n",
       "      <td>26.124783</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>5135</td>\n",
       "      <td>Graph Oracle Models, Lower Bounds, and Gaps fo...</td>\n",
       "      <td>We suggest a general oracle-based framework th...</td>\n",
       "      <td>blake@ttic.edu;jialei@uchicago.edu;ads22@bu.ed...</td>\n",
       "      <td>Optimization/Convex Optimization*; Algorithms/...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization/Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[graph, oracl, model, lower, bound, gap, paral...</td>\n",
       "      <td>5135</td>\n",
       "      <td>[0.6741490529999999, 0.635817593, 0.61815163, ...</td>\n",
       "      <td>-67.137169</td>\n",
       "      <td>45.887924</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>5289</td>\n",
       "      <td>Generalized Cross Entropy Loss for Training De...</td>\n",
       "      <td>Deep neural networks (DNNs) have achieved trem...</td>\n",
       "      <td>zz452@cornell.edu;msabuncu@cornell.edu</td>\n",
       "      <td>Algorithms/Classification*; Deep Learning/Opti...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Classification</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[gener, cross, entropi, loss, train, deep, neu...</td>\n",
       "      <td>5289</td>\n",
       "      <td>[0.793750381, 0.8099054, 0.758090835, 0.815338...</td>\n",
       "      <td>49.048794</td>\n",
       "      <td>-27.138659</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>5345</td>\n",
       "      <td>Improving Neural Program Synthesis with Inferr...</td>\n",
       "      <td>The task of program synthesis, or automaticall...</td>\n",
       "      <td>ricshin@berkeley.edu;illia@near.ai;dawnsong@gm...</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learnin</td>\n",
       "      <td>Deep Learnin</td>\n",
       "      <td>[improv, neural, program, synthesi, infer, exe...</td>\n",
       "      <td>5345</td>\n",
       "      <td>[0.467971409, 0.617539232, 0.458885926, 0.4637...</td>\n",
       "      <td>-23.434278</td>\n",
       "      <td>-31.065639</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>5356</td>\n",
       "      <td>Policy-Conditioned Uncertainty Sets for Robust...</td>\n",
       "      <td>What policy should be employed in a Markov dec...</td>\n",
       "      <td>andrea.tirinzoni@polimi.it;mpetrik@cs.unh.edu;...</td>\n",
       "      <td>Reinforcement Learning and Planning/Decision a...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Reinforcement Learning and Planning/Decision a...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>[polici, condit, uncertainti, set, robust, mar...</td>\n",
       "      <td>5356</td>\n",
       "      <td>[0.610306855, 0.5182120960000001, 0.552038275,...</td>\n",
       "      <td>86.962540</td>\n",
       "      <td>7.188701</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>5839</td>\n",
       "      <td>Learning convex bounds for linear quadratic co...</td>\n",
       "      <td>Learning to make decisions from observed data ...</td>\n",
       "      <td>jack.umenberger@it.uu.se;thomas.schon@it.uu.se</td>\n",
       "      <td>Reinforcement Learning and Planning/Decision a...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Reinforcement Learning and Planning/Decision a...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>[learn, convex, bound, linear, quadrat, contro...</td>\n",
       "      <td>5839</td>\n",
       "      <td>[0.710832627, 0.62145682, 0.6379692610000001, ...</td>\n",
       "      <td>83.833725</td>\n",
       "      <td>7.571307</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>5841</td>\n",
       "      <td>To What Extent Do Different Neural Networks Le...</td>\n",
       "      <td>Studying the learned representations is import...</td>\n",
       "      <td>wanglw@cis.pku.edu.cn;lunjia@stanford.edu;guji...</td>\n",
       "      <td>Deep Learning*; Theory</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[extent, differ, neural, network, learn, repre...</td>\n",
       "      <td>5841</td>\n",
       "      <td>[0.701640321, 0.7164536090000001, 0.675077135,...</td>\n",
       "      <td>-27.302887</td>\n",
       "      <td>-21.865208</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>6460</td>\n",
       "      <td>Non-delusional Q-learning and Value-iteration</td>\n",
       "      <td>We identify a fundamental source of error in Q...</td>\n",
       "      <td>tyler.lu@gmail.com;schuurmans@google.com;cbout...</td>\n",
       "      <td>Reinforcement Learning and Planning*; Reinforc...</td>\n",
       "      <td>Oral</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>[non, delusion, learn, valu, iter, identifi, f...</td>\n",
       "      <td>6460</td>\n",
       "      <td>[0.675618191, 0.587158384, 0.631925449, 0.6821...</td>\n",
       "      <td>76.513412</td>\n",
       "      <td>7.280374</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>6793</td>\n",
       "      <td>Robust Subspace Approximation in a Stream</td>\n",
       "      <td>We study robust subspace estimation in the str...</td>\n",
       "      <td>roiel@cs.cmu.edu;asevekar@andrew.cmu.edu;dwood...</td>\n",
       "      <td>Algorithms*; Algorithms/Regression</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[robust, subspac, approxim, stream, studi, rob...</td>\n",
       "      <td>6793</td>\n",
       "      <td>[0.540987701, 0.441798132, 0.49352610399999997...</td>\n",
       "      <td>36.628849</td>\n",
       "      <td>33.431755</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>6859</td>\n",
       "      <td>Decentralize and Randomize: Faster Algorithm f...</td>\n",
       "      <td>We study the problem of decentralized distribu...</td>\n",
       "      <td>pavel.dvurechensky@gmail.com;darina.dvinskikh@...</td>\n",
       "      <td>Optimization/Convex Optimization*; Algorithms/...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization/Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[decentr, random, faster, algorithm, wasserste...</td>\n",
       "      <td>6859</td>\n",
       "      <td>[0.649590907, 0.572511066, 0.579816594, 0.6330...</td>\n",
       "      <td>-67.124580</td>\n",
       "      <td>29.979273</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>6901</td>\n",
       "      <td>Support Recovery for Orthogonal Matching Pursu...</td>\n",
       "      <td>This paper studies the problem of sparse regre...</td>\n",
       "      <td>raghavsomani1995@gmail.com;chiragpvg@gmail.com...</td>\n",
       "      <td>Algorithms/Sparsity and Compressed Sensing*; A...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Sparsity and Compressed Sensing</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[support, recoveri, orthogon, match, pursuit, ...</td>\n",
       "      <td>6901</td>\n",
       "      <td>[0.6322439089999999, 0.5179587760000001, 0.563...</td>\n",
       "      <td>41.317558</td>\n",
       "      <td>32.567497</td>\n",
       "      <td>D3_S2_T1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Paper ID                                        Paper Title  \\\n",
       "37        267                  (Probably) Concave Graph Matching   \n",
       "101       576            Efficient nonmyopic batch active search   \n",
       "103       597  Interactive Structure Learning with Structural...   \n",
       "190      1026  Discovery of Latent 3D Keypoints via End-to-en...   \n",
       "199      1099  Norm matters: efficient and accurate normaliza...   \n",
       "208      1143  Learning to Reconstruct Shapes from Unseen Cat...   \n",
       "210      1147  Smoothed analysis of the low-rank approach for...   \n",
       "253      1446  Optimal Algorithms for Non-Smooth Distributed ...   \n",
       "346      1878  DeepProbLog:  Neural Probabilistic Logic Progr...   \n",
       "347      1881  Convergence of Cubic Regularization for Noncon...   \n",
       "360      1920  Direct Runge-Kutta Discretization Achieves Acc...   \n",
       "408      2171  Limited Memory Kelley's Method Converges for C...   \n",
       "439      2298  Data-Efficient Model-based Reinforcement Learn...   \n",
       "466      2440  LAG: Lazily Aggregated Gradient for Communicat...   \n",
       "482      2491  Contour location via entropy reduction leverag...   \n",
       "484      2501  Multiple-Step Greedy Policies in Approximate a...   \n",
       "494      2562                         Hyperbolic Neural Networks   \n",
       "498      2582              Fully Understanding The Hashing Trick   \n",
       "509      2641  Low-rank Interaction with Sparse Additive Effe...   \n",
       "515      2665  A Simple Proximal Stochastic Gradient Method f...   \n",
       "547      2861  Binary Classification from Positive-Confidence...   \n",
       "550      2893  Constructing Fast Network through Deconstructi...   \n",
       "560      2974  Learning to Infer Graphics Programs from Hand-...   \n",
       "570      3035  ResNet with one-neuron hidden layers is a Univ...   \n",
       "662      3551  A Simple Unified Framework for Detecting Out-o...   \n",
       "683      3682  Stochastic Chebyshev Gradient Descent for Spec...   \n",
       "716      3833  Learning Loop Invariants for Program Verification   \n",
       "721      4859  Learning Libraries of Subroutines for Neurally...   \n",
       "730      4901  Robust Hypothesis Testing Using Wasserstein Un...   \n",
       "759      5026  Sample-Efficient Reinforcement Learning with S...   \n",
       "766      5045      Bilevel learning of the Group Lasso structure   \n",
       "782      5129  Wasserstein Distributionally Robust Kalman Fil...   \n",
       "784      5135  Graph Oracle Models, Lower Bounds, and Gaps fo...   \n",
       "810      5289  Generalized Cross Entropy Loss for Training De...   \n",
       "823      5345  Improving Neural Program Synthesis with Inferr...   \n",
       "825      5356  Policy-Conditioned Uncertainty Sets for Robust...   \n",
       "881      5839  Learning convex bounds for linear quadratic co...   \n",
       "883      5841  To What Extent Do Different Neural Networks Le...   \n",
       "916      6460      Non-delusional Q-learning and Value-iteration   \n",
       "983      6793          Robust Subspace Approximation in a Stream   \n",
       "990      6859  Decentralize and Randomize: Faster Algorithm f...   \n",
       "995      6901  Support Recovery for Orthogonal Matching Pursu...   \n",
       "\n",
       "                                              Abstract  \\\n",
       "37   In this paper we address the graph matching pr...   \n",
       "101  Active search is a learning paradigm for activ...   \n",
       "103  In this work, we introduce interactive structu...   \n",
       "190  This paper presents KeypointNet, an end-to-end...   \n",
       "199  Over the past few years, Batch-Normalization h...   \n",
       "208  From a single view, humans are able to halluci...   \n",
       "210  We consider semidefinite programs (SDPs) of si...   \n",
       "253  In this work, we consider the distributed opti...   \n",
       "346  We introduce DeepProbLog, a probabilistic logi...   \n",
       "347  Cubic-regularized Newton's method (CR) is a po...   \n",
       "360  We study gradient-based optimization methods o...   \n",
       "408  The original simplicial method ({\\sc OSM}), a ...   \n",
       "439  Model-based reinforcement learning (RL) algori...   \n",
       "466  This paper presents a new class of gradient me...   \n",
       "482  We introduce an algorithm to locate contours o...   \n",
       "484  Multiple-step lookahead policies have demonstr...   \n",
       "494  Hyperbolic spaces have recently gained momentu...   \n",
       "498  Feature hashing, also known as {\\em the hashin...   \n",
       "509  Many applications of machine learning involve ...   \n",
       "515  We analyze stochastic gradient algorithms for ...   \n",
       "547  Reducing labeling costs in supervised learning...   \n",
       "550  Convolutional neural networks have achieved gr...   \n",
       "560  We introduce a model that learns to convert si...   \n",
       "570  We demonstrate that a very deep ResNet with st...   \n",
       "662  Detecting test samples drawn sufficiently far ...   \n",
       "683  A large class of machine learning techniques r...   \n",
       "716  A fundamental problem in program verification ...   \n",
       "721  Successful approaches to program induction req...   \n",
       "730  We develop a novel computationally efficient a...   \n",
       "759  There is growing interest in combining model-f...   \n",
       "766  Regression with group-sparsity penalty plays a...   \n",
       "782  We study a distributionally robust mean square...   \n",
       "784  We suggest a general oracle-based framework th...   \n",
       "810  Deep neural networks (DNNs) have achieved trem...   \n",
       "823  The task of program synthesis, or automaticall...   \n",
       "825  What policy should be employed in a Markov dec...   \n",
       "881  Learning to make decisions from observed data ...   \n",
       "883  Studying the learned representations is import...   \n",
       "916  We identify a fundamental source of error in Q...   \n",
       "983  We study robust subspace estimation in the str...   \n",
       "990  We study the problem of decentralized distribu...   \n",
       "995  This paper studies the problem of sparse regre...   \n",
       "\n",
       "                                         Author Emails  \\\n",
       "37   haggai.maron@weizmann.ac.il;yaron.lipman@weizm...   \n",
       "101  jiang.s@wustl.edu;luizgustavo@wustl.edu;mbabbo...   \n",
       "103             ctosh@cs.ucsd.edu;dasgupta@cs.ucsd.edu   \n",
       "190  supasorn@gmail.com;snavely@google.com;tompson@...   \n",
       "199  elad.hoffer@gmail.com;ron.banner@intel.com;ita...   \n",
       "208  xiuming@mit.edu;ztzhang@mit.edu;ckzhang@mit.ed...   \n",
       "210  tpumir@princeton.edu;sjelassi@princeton.edu;nb...   \n",
       "253  kevin.scaman@gmail.com;francis.bach@inria.fr;s...   \n",
       "346  robin.manhaeve@cs.kuleuven.be;sebastijan.duman...   \n",
       "347  zhou.1172@osu.edu;wang.10982@osu.edu;liang.889...   \n",
       "360  jzhzhang@mit.edu;aryanm@mit.edu;suvrit@mit.edu...   \n",
       "408  sz557@cornell.edu;swatig@gatech.edu;udell@corn...   \n",
       "439  kchua@berkeley.edu;roberto.calandra@berkeley.e...   \n",
       "466  chen3827@umn.edu;georgios@umn.edu;nudtsuntao@1...   \n",
       "482         noll@mit.edu;rlam@mit.edu;kwillcox@mit.edu   \n",
       "484  jonathan.efroni@gmail.com;gald@tx.technion.ac....   \n",
       "494  octavian.ganea@inf.ethz.ch;gary.becigneul@inf....   \n",
       "498  lior.kamma@cs.au.dk;cfreksen@cs.au.dk;larsen@c...   \n",
       "509  genevieve.robin@polytechnique.edu;htwai@asu.ed...   \n",
       "515  zz-li14@mails.tsinghua.edu.cn;lijian83@mail.ts...   \n",
       "547  ishida@ms.k.u-tokyo.ac.jp;gang.niu@riken.jp;su...   \n",
       "550          jyh2986@kaist.ac.kr;junmo.kim@kaist.ac.kr   \n",
       "560  ellisk@mit.edu;daniel_ritchie@brown.edu;asolar...   \n",
       "570         hongzhou.lin@inria.fr;stefje@csail.mit.edu   \n",
       "662  kiminlee@kaist.ac.kr;kibok@umich.edu;honglak@e...   \n",
       "683  hawki17@kaist.ac.kr;haimav@post.tau.ac.il;jinw...   \n",
       "716  xsi@seas.upenn.edu;hanjundai@gatech.edu;rmukun...   \n",
       "721  ellisk@mit.edu;lucasem@mit.edu;mathias.sable-m...   \n",
       "730  rgao32@gatech.edu;lxie49@gatech.edu;yao.xie@is...   \n",
       "759  jacobbuckman@gmail.com;mail@danijar.com;gjt@go...   \n",
       "766  jordan.frecon@iit.it;saverio.salzo@iit.it;mass...   \n",
       "782  soroosh.shafiee@epfl.ch;viet-anh.nguyen@epfl.c...   \n",
       "784  blake@ttic.edu;jialei@uchicago.edu;ads22@bu.ed...   \n",
       "810             zz452@cornell.edu;msabuncu@cornell.edu   \n",
       "823  ricshin@berkeley.edu;illia@near.ai;dawnsong@gm...   \n",
       "825  andrea.tirinzoni@polimi.it;mpetrik@cs.unh.edu;...   \n",
       "881     jack.umenberger@it.uu.se;thomas.schon@it.uu.se   \n",
       "883  wanglw@cis.pku.edu.cn;lunjia@stanford.edu;guji...   \n",
       "916  tyler.lu@gmail.com;schuurmans@google.com;cbout...   \n",
       "983  roiel@cs.cmu.edu;asevekar@andrew.cmu.edu;dwood...   \n",
       "990  pavel.dvurechensky@gmail.com;darina.dvinskikh@...   \n",
       "995  raghavsomani1995@gmail.com;chiragpvg@gmail.com...   \n",
       "\n",
       "                                         Subject Areas   Decision  \\\n",
       "37   Optimization/Convex Optimization*; Optimizatio...  Spotlight   \n",
       "101                         Algorithms/Active Learning  Spotlight   \n",
       "103  Algorithms/Active Learning*; Algorithms/Semi-S...  Spotlight   \n",
       "190                       Applications/Computer Vision       Oral   \n",
       "199  Deep Learning*; Deep Learning/CNN Architecture...  Spotlight   \n",
       "208  Applications/Object Recognition*; Applications...       Oral   \n",
       "210  Optimization*; Optimization/Convex Optimizatio...       Oral   \n",
       "253  Optimization/Convex Optimization*; Application...       Oral   \n",
       "346  Algorithms/Relational Learning*; Deep Learning...  Spotlight   \n",
       "347  Optimization*; Optimization/Non-Convex Optimiz...  Spotlight   \n",
       "360  Optimization/Convex Optimization*; Algorithms/...  Spotlight   \n",
       "408  Optimization/Convex Optimization*; Optimizatio...  Spotlight   \n",
       "439  Reinforcement Learning and Planning/Model-Base...  Spotlight   \n",
       "466    Optimization*; Optimization/Convex Optimization  Spotlight   \n",
       "482  Algorithms/Classification*; Algorithms/Active ...  Spotlight   \n",
       "484  Reinforcement Learning and Planning/Reinforcem...  Spotlight   \n",
       "494  Deep Learning*; Applications/Natural Language ...  Spotlight   \n",
       "498  Algorithms/Similarity and Distance Learning*; ...  Spotlight   \n",
       "509  Algorithms/Missing Data*; Optimization/Convex ...  Spotlight   \n",
       "515  Optimization*; Algorithms/Stochastic Methods; ...  Spotlight   \n",
       "547                Algorithms/Semi-Supervised Learning  Spotlight   \n",
       "550  Deep Learning/CNN Architectures*; Algorithms/C...  Spotlight   \n",
       "560                    Deep Learning/Program Induction  Spotlight   \n",
       "570             Deep Learning*; Theory/Learning Theory  Spotlight   \n",
       "662                                      Deep Learning  Spotlight   \n",
       "683       Optimization*; Algorithms/Stochastic Methods  Spotlight   \n",
       "716  Deep Learning/Program Induction*; Deep Learnin...  Spotlight   \n",
       "721                    Deep Learning/Program Induction  Spotlight   \n",
       "730  Optimization*; Theory/Frequentist Statistics; ...  Spotlight   \n",
       "759  Reinforcement Learning and Planning/Model-Base...       Oral   \n",
       "766  Algorithms/Model Selection and Structure Learn...  Spotlight   \n",
       "782  Optimization/Convex Optimization*; Reinforceme...  Spotlight   \n",
       "784  Optimization/Convex Optimization*; Algorithms/...  Spotlight   \n",
       "810  Algorithms/Classification*; Deep Learning/Opti...  Spotlight   \n",
       "823                                      Deep Learning  Spotlight   \n",
       "825  Reinforcement Learning and Planning/Decision a...  Spotlight   \n",
       "881  Reinforcement Learning and Planning/Decision a...  Spotlight   \n",
       "883                             Deep Learning*; Theory  Spotlight   \n",
       "916  Reinforcement Learning and Planning*; Reinforc...       Oral   \n",
       "983                 Algorithms*; Algorithms/Regression  Spotlight   \n",
       "990  Optimization/Convex Optimization*; Algorithms/...  Spotlight   \n",
       "995  Algorithms/Sparsity and Compressed Sensing*; A...  Spotlight   \n",
       "\n",
       "                                  Primary Subject Area  \\\n",
       "37                    Optimization/Convex Optimization   \n",
       "101                          Algorithms/Active Learnin   \n",
       "103                         Algorithms/Active Learning   \n",
       "190                        Applications/Computer Visio   \n",
       "199                                      Deep Learning   \n",
       "208                    Applications/Object Recognition   \n",
       "210                                       Optimization   \n",
       "253                   Optimization/Convex Optimization   \n",
       "346                     Algorithms/Relational Learning   \n",
       "347                                       Optimization   \n",
       "360                   Optimization/Convex Optimization   \n",
       "408                   Optimization/Convex Optimization   \n",
       "439  Reinforcement Learning and Planning/Model-Based R   \n",
       "466                                       Optimization   \n",
       "482                          Algorithms/Classification   \n",
       "484  Reinforcement Learning and Planning/Reinforcem...   \n",
       "494                                      Deep Learning   \n",
       "498        Algorithms/Similarity and Distance Learning   \n",
       "509                            Algorithms/Missing Data   \n",
       "515                                       Optimization   \n",
       "547                 Algorithms/Semi-Supervised Learnin   \n",
       "550                    Deep Learning/CNN Architectures   \n",
       "560                     Deep Learning/Program Inductio   \n",
       "570                                      Deep Learning   \n",
       "662                                       Deep Learnin   \n",
       "683                                       Optimization   \n",
       "716                    Deep Learning/Program Induction   \n",
       "721                     Deep Learning/Program Inductio   \n",
       "730                                       Optimization   \n",
       "759  Reinforcement Learning and Planning/Model-Base...   \n",
       "766  Algorithms/Model Selection and Structure Learning   \n",
       "782                   Optimization/Convex Optimization   \n",
       "784                   Optimization/Convex Optimization   \n",
       "810                          Algorithms/Classification   \n",
       "823                                       Deep Learnin   \n",
       "825  Reinforcement Learning and Planning/Decision a...   \n",
       "881  Reinforcement Learning and Planning/Decision a...   \n",
       "883                                      Deep Learning   \n",
       "916                Reinforcement Learning and Planning   \n",
       "983                                         Algorithms   \n",
       "990                   Optimization/Convex Optimization   \n",
       "995         Algorithms/Sparsity and Compressed Sensing   \n",
       "\n",
       "          Top-level Primary Subject Area  \\\n",
       "37                          Optimization   \n",
       "101                           Algorithms   \n",
       "103                           Algorithms   \n",
       "190                         Applications   \n",
       "199                        Deep Learning   \n",
       "208                         Applications   \n",
       "210                         Optimization   \n",
       "253                         Optimization   \n",
       "346                           Algorithms   \n",
       "347                         Optimization   \n",
       "360                         Optimization   \n",
       "408                         Optimization   \n",
       "439  Reinforcement Learning and Planning   \n",
       "466                         Optimization   \n",
       "482                           Algorithms   \n",
       "484  Reinforcement Learning and Planning   \n",
       "494                        Deep Learning   \n",
       "498                           Algorithms   \n",
       "509                           Algorithms   \n",
       "515                         Optimization   \n",
       "547                           Algorithms   \n",
       "550                        Deep Learning   \n",
       "560                        Deep Learning   \n",
       "570                        Deep Learning   \n",
       "662                         Deep Learnin   \n",
       "683                         Optimization   \n",
       "716                        Deep Learning   \n",
       "721                        Deep Learning   \n",
       "730                         Optimization   \n",
       "759  Reinforcement Learning and Planning   \n",
       "766                           Algorithms   \n",
       "782                         Optimization   \n",
       "784                         Optimization   \n",
       "810                           Algorithms   \n",
       "823                         Deep Learnin   \n",
       "825  Reinforcement Learning and Planning   \n",
       "881  Reinforcement Learning and Planning   \n",
       "883                        Deep Learning   \n",
       "916  Reinforcement Learning and Planning   \n",
       "983                           Algorithms   \n",
       "990                         Optimization   \n",
       "995                           Algorithms   \n",
       "\n",
       "                                                   bow   pid  \\\n",
       "37   [probabl, concav, graph, match, thi, paper, ad...   267   \n",
       "101  [effici, nonmyop, batch, activ, search, activ,...   576   \n",
       "103  [interact, structur, learn, structur, queri, c...   597   \n",
       "190  [discoveri, latent, 3d, keypoint, via, end, en...  1026   \n",
       "199  [norm, matter, effici, accur, normal, scheme, ...  1099   \n",
       "208  [learn, reconstruct, shape, unseen, categori, ...  1143   \n",
       "210  [smooth, analysi, low, rank, approach, smooth,...  1147   \n",
       "253  [optim, algorithm, non, smooth, distribut, opt...  1446   \n",
       "346  [deepproblog, neural, probabilist, logic, prog...  1878   \n",
       "347  [converg, cubic, regular, nonconvex, optim, kl...  1881   \n",
       "360  [direct, rung, kutta, discret, achiev, acceler...  1920   \n",
       "408  [limit, memori, kelley, method, converg, compo...  2171   \n",
       "439  [data, effici, model, base, reinforc, learn, d...  2298   \n",
       "466  [lag, lazili, aggreg, gradient, commun, effici...  2440   \n",
       "482  [contour, locat, via, entropi, reduct, leverag...  2491   \n",
       "484  [multipl, step, greedi, polici, approxim, onli...  2501   \n",
       "494  [hyperbol, neural, network, hyperbol, space, r...  2562   \n",
       "498  [fulli, understand, hash, trick, featur, hash,...  2582   \n",
       "509  [low, rank, interact, spars, addit, effect, mo...  2641   \n",
       "515  [simpl, proxim, stochast, gradient, method, no...  2665   \n",
       "547  [binari, classif, posit, confid, data, reduc, ...  2861   \n",
       "550  [construct, fast, network, deconstruct, convol...  2893   \n",
       "560  [learn, infer, graphic, program, hand, drawn, ...  2974   \n",
       "570  [resnet, one, neuron, hidden, layer, univers, ...  3035   \n",
       "662  [simpl, unifi, framework, detect, distribut, s...  3551   \n",
       "683  [stochast, chebyshev, gradient, descent, spect...  3682   \n",
       "716  [learn, loop, invari, program, verif, fundamen...  3833   \n",
       "721  [learn, librari, subroutin, neurally–guid, bay...  4859   \n",
       "730  [robust, hypothesi, test, use, wasserstein, un...  4901   \n",
       "759  [sampl, effici, reinforc, learn, stochast, ens...  5026   \n",
       "766  [bilevel, learn, group, lasso, structur, regre...  5045   \n",
       "782  [wasserstein, distribut, robust, kalman, filte...  5129   \n",
       "784  [graph, oracl, model, lower, bound, gap, paral...  5135   \n",
       "810  [gener, cross, entropi, loss, train, deep, neu...  5289   \n",
       "823  [improv, neural, program, synthesi, infer, exe...  5345   \n",
       "825  [polici, condit, uncertainti, set, robust, mar...  5356   \n",
       "881  [learn, convex, bound, linear, quadrat, contro...  5839   \n",
       "883  [extent, differ, neural, network, learn, repre...  5841   \n",
       "916  [non, delusion, learn, valu, iter, identifi, f...  6460   \n",
       "983  [robust, subspac, approxim, stream, studi, rob...  6793   \n",
       "990  [decentr, random, faster, algorithm, wasserste...  6859   \n",
       "995  [support, recoveri, orthogon, match, pursuit, ...  6901   \n",
       "\n",
       "                                                  tpms   tsne_all  tsne_tpms  \\\n",
       "37   [0.858271366, 0.682665183, 0.7683895479999999,... -67.131195  29.937187   \n",
       "101  [0.5437475, 0.48220424799999995, 0.508575226, ...  60.245289   9.279699   \n",
       "103  [0.529437719, 0.45932953600000004, 0.490521479...  59.319515  37.968044   \n",
       "190  [0.581163477, 0.5984493120000001, 0.542658568,...   9.342001 -47.488724   \n",
       "199  [0.546826715, 0.578286664, 0.504709097, 0.5672... -26.945894 -22.626886   \n",
       "208  [0.572495249, 0.567489183, 0.534011075, 0.5716...  10.185015 -47.350956   \n",
       "210  [0.460976129, 0.33447025, 0.36871131700000004,... -70.034546  43.803680   \n",
       "253  [0.637403434, 0.535576182, 0.5500409629999999,... -67.139160  45.827702   \n",
       "346  [0.6685511, 0.718956288, 0.641330434, 0.673511...  53.303432 -30.856102   \n",
       "347  [0.7832019729999999, 0.517215119, 0.519890496,... -69.925735  46.154724   \n",
       "360  [0.6863303190000001, 0.49512777799999996, 0.54... -67.139565  44.497669   \n",
       "408  [0.588896619, 0.477438454, 0.5104155429999999,... -67.109413  43.639351   \n",
       "439  [0.693454531, 0.674571321, 0.635436176, 0.6904...  83.043457   2.235853   \n",
       "466  [0.628226054, 0.583180337, 0.527631899, 0.5999... -69.777893  49.156544   \n",
       "482  [0.7669138120000001, 0.643375559, 0.697614418,...  48.901409  -1.069540   \n",
       "484  [0.594272799, 0.518109147, 0.561630995, 0.5968...  80.190575   8.092484   \n",
       "494  [0.7522543740000001, 0.736023832, 0.697689227,... -26.121195 -17.066725   \n",
       "498  [0.521237043, 0.44199288600000003, 0.471181035...  46.861782  33.453499   \n",
       "509  [0.81091035, 0.666503034, 0.688653182, 0.75665...  46.222477  31.233282   \n",
       "515  [0.5443507870000001, 0.389543226, 0.379131083,... -69.883400  46.994019   \n",
       "547  [0.645438133, 0.590653698, 0.608418902, 0.6539...  48.151466 -12.391636   \n",
       "550  [0.5751594329999999, 0.662647356, 0.536300601,... -45.007767 -41.029495   \n",
       "560  [0.559116815, 0.572513619, 0.530804837, 0.5530... -32.042522 -30.779812   \n",
       "570  [0.661626699, 0.66508273, 0.620017194, 0.73787... -26.482437 -21.562668   \n",
       "662  [0.6365459960000001, 0.63109569, 0.604992714, ... -23.449856 -27.983456   \n",
       "683  [0.73760857, 0.615259542, 0.645803433, 0.70288... -69.869652  44.747562   \n",
       "716  [0.6634387389999999, 0.709670893, 0.639796905,... -32.456005 -30.657389   \n",
       "721  [0.584069737, 0.6295379489999999, 0.5559945, 0... -32.058723 -30.780697   \n",
       "730  [0.8681026629999999, 0.6750643359999999, 0.786... -70.040543  26.340662   \n",
       "759  [0.590708845, 0.592122578, 0.559167734, 0.5872...  84.390198   2.709555   \n",
       "766  [0.783325127, 0.626205489, 0.6653859129999999,...  47.347546  30.596678   \n",
       "782  [0.8379091000000001, 0.66053631, 0.722060905, ... -67.129349  26.124783   \n",
       "784  [0.6741490529999999, 0.635817593, 0.61815163, ... -67.137169  45.887924   \n",
       "810  [0.793750381, 0.8099054, 0.758090835, 0.815338...  49.048794 -27.138659   \n",
       "823  [0.467971409, 0.617539232, 0.458885926, 0.4637... -23.434278 -31.065639   \n",
       "825  [0.610306855, 0.5182120960000001, 0.552038275,...  86.962540   7.188701   \n",
       "881  [0.710832627, 0.62145682, 0.6379692610000001, ...  83.833725   7.571307   \n",
       "883  [0.701640321, 0.7164536090000001, 0.675077135,... -27.302887 -21.865208   \n",
       "916  [0.675618191, 0.587158384, 0.631925449, 0.6821...  76.513412   7.280374   \n",
       "983  [0.540987701, 0.441798132, 0.49352610399999997...  36.628849  33.431755   \n",
       "990  [0.649590907, 0.572511066, 0.579816594, 0.6330... -67.124580  29.979273   \n",
       "995  [0.6322439089999999, 0.5179587760000001, 0.563...  41.317558  32.567497   \n",
       "\n",
       "      Session  PosterSession  \n",
       "37   D3_S2_T3              6  \n",
       "101  D3_S2_T1              6  \n",
       "103  D3_S2_T1              6  \n",
       "190  D3_S2_T2              6  \n",
       "199  D3_S2_T2              6  \n",
       "208  D3_S2_T2              6  \n",
       "210  D3_S2_T3              6  \n",
       "253  D3_S2_T3              6  \n",
       "346  D3_S2_T2              6  \n",
       "347  D3_S2_T3              6  \n",
       "360  D3_S2_T3              6  \n",
       "408  D3_S2_T3              6  \n",
       "439  D3_S2_T1              6  \n",
       "466  D3_S2_T3              6  \n",
       "482  D3_S2_T1              6  \n",
       "484  D3_S2_T1              6  \n",
       "494  D3_S2_T2              6  \n",
       "498  D3_S2_T1              6  \n",
       "509  D3_S2_T3              6  \n",
       "515  D3_S2_T3              6  \n",
       "547  D3_S2_T1              6  \n",
       "550  D3_S2_T2              6  \n",
       "560  D3_S2_T2              6  \n",
       "570  D3_S2_T2              6  \n",
       "662  D3_S2_T2              6  \n",
       "683  D3_S2_T3              6  \n",
       "716  D3_S2_T2              6  \n",
       "721  D3_S2_T2              6  \n",
       "730  D3_S2_T3              6  \n",
       "759  D3_S2_T1              6  \n",
       "766  D3_S2_T1              6  \n",
       "782  D3_S2_T3              6  \n",
       "784  D3_S2_T3              6  \n",
       "810  D3_S2_T2              6  \n",
       "823  D3_S2_T2              6  \n",
       "825  D3_S2_T1              6  \n",
       "881  D3_S2_T1              6  \n",
       "883  D3_S2_T2              6  \n",
       "916  D3_S2_T1              6  \n",
       "983  D3_S2_T1              6  \n",
       "990  D3_S2_T3              6  \n",
       "995  D3_S2_T1              6  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_df[poster_df['PosterSession'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "poster_df['day_v3'] = tmp['Session'].apply(lambda x: 0 if isinstance(x, float) else int(x.split('_')[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "day4_talks = poster_df[poster_df['day_v3'] == 4].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poster session assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poster conflicts is defined as the number of common authors between two papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "poster_conflicts = {}\n",
    "for i, irow in tqdm_notebook(poster_df.iterrows()):\n",
    "    iemails = set(e.strip() for e in irow['Author Emails'].split(';'))\n",
    "    for j, jrow in poster_df.iterrows():\n",
    "        if j <= i:\n",
    "            continue\n",
    "        jemails = set(e.strip() for e in jrow['Author Emails'].split(';'))\n",
    "        c = len(iemails.intersection(jemails))\n",
    "        if c > 0:\n",
    "            poster_conflicts[i,j] = poster_conflicts[j,i] = c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "poster_conflicts_first_author = {}\n",
    "for i, irow in tqdm_notebook(poster_df.iterrows()):\n",
    "    iemail = irow['Author Emails'].split(';')[0].strip()\n",
    "    for j, jrow in poster_df.iterrows():\n",
    "        if j <= i:\n",
    "            continue\n",
    "        jemail = jrow['Author Emails'].split(';')[0].strip()\n",
    "        if iemail == jemail:\n",
    "            poster_conflicts_first_author[i,j] = poster_conflicts_first_author[j,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1674"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of papers with at least one conflict paper\n",
    "len(poster_conflicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3L, 852L): 1,\n",
       " (34L, 35L): 1,\n",
       " (35L, 34L): 1,\n",
       " (52L, 53L): 1,\n",
       " (53L, 52L): 1,\n",
       " (54L, 947L): 1,\n",
       " (56L, 80L): 1,\n",
       " (59L, 815L): 1,\n",
       " (78L, 361L): 1,\n",
       " (80L, 56L): 1,\n",
       " (82L, 868L): 1,\n",
       " (97L, 206L): 1,\n",
       " (99L, 121L): 1,\n",
       " (106L, 114L): 1,\n",
       " (106L, 247L): 1,\n",
       " (106L, 343L): 1,\n",
       " (113L, 183L): 1,\n",
       " (114L, 106L): 1,\n",
       " (114L, 247L): 1,\n",
       " (114L, 343L): 1,\n",
       " (121L, 99L): 1,\n",
       " (183L, 113L): 1,\n",
       " (200L, 476L): 1,\n",
       " (206L, 97L): 1,\n",
       " (207L, 332L): 1,\n",
       " (241L, 607L): 1,\n",
       " (242L, 807L): 1,\n",
       " (247L, 106L): 1,\n",
       " (247L, 114L): 1,\n",
       " (247L, 343L): 1,\n",
       " (257L, 377L): 1,\n",
       " (287L, 401L): 1,\n",
       " (291L, 1006L): 1,\n",
       " (332L, 207L): 1,\n",
       " (343L, 106L): 1,\n",
       " (343L, 114L): 1,\n",
       " (343L, 247L): 1,\n",
       " (361L, 78L): 1,\n",
       " (377L, 257L): 1,\n",
       " (382L, 622L): 1,\n",
       " (401L, 287L): 1,\n",
       " (426L, 552L): 1,\n",
       " (428L, 523L): 1,\n",
       " (432L, 448L): 1,\n",
       " (437L, 453L): 1,\n",
       " (448L, 432L): 1,\n",
       " (449L, 452L): 1,\n",
       " (452L, 449L): 1,\n",
       " (453L, 437L): 1,\n",
       " (461L, 842L): 1,\n",
       " (465L, 888L): 1,\n",
       " (476L, 200L): 1,\n",
       " (486L, 797L): 1,\n",
       " (495L, 817L): 1,\n",
       " (519L, 525L): 1,\n",
       " (523L, 428L): 1,\n",
       " (525L, 519L): 1,\n",
       " (540L, 787L): 1,\n",
       " (552L, 426L): 1,\n",
       " (560L, 721L): 1,\n",
       " (571L, 825L): 1,\n",
       " (578L, 808L): 1,\n",
       " (603L, 784L): 1,\n",
       " (607L, 241L): 1,\n",
       " (622L, 382L): 1,\n",
       " (635L, 871L): 1,\n",
       " (639L, 821L): 1,\n",
       " (639L, 855L): 1,\n",
       " (639L, 1002L): 1,\n",
       " (721L, 560L): 1,\n",
       " (784L, 603L): 1,\n",
       " (787L, 540L): 1,\n",
       " (797L, 486L): 1,\n",
       " (807L, 242L): 1,\n",
       " (808L, 578L): 1,\n",
       " (815L, 59L): 1,\n",
       " (817L, 495L): 1,\n",
       " (821L, 639L): 1,\n",
       " (821L, 855L): 1,\n",
       " (821L, 1002L): 1,\n",
       " (825L, 571L): 1,\n",
       " (842L, 461L): 1,\n",
       " (852L, 3L): 1,\n",
       " (855L, 639L): 1,\n",
       " (855L, 821L): 1,\n",
       " (855L, 1002L): 1,\n",
       " (868L, 82L): 1,\n",
       " (871L, 635L): 1,\n",
       " (888L, 465L): 1,\n",
       " (947L, 54L): 1,\n",
       " (1002L, 639L): 1,\n",
       " (1002L, 821L): 1,\n",
       " (1002L, 855L): 1,\n",
       " (1006L, 291L): 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_conflicts_first_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Algorithms                                           207\n",
       "Deep Learning                                        194\n",
       "Applications                                         193\n",
       "Probabilistic Methods                                106\n",
       "Theory                                                97\n",
       "Reinforcement Learning and Planning                   85\n",
       "Optimization                                          80\n",
       "Neuroscience and Cognitive Science                    33\n",
       "Deep Learnin                                           7\n",
       "Data, Competitions, Implementations, and Software      6\n",
       "Application                                            2\n",
       "Optimizatio                                            1\n",
       "Reinforcement Learning and Plannin                     1\n",
       "Name: Top-level Primary Subject Area, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_df['Top-level Primary Subject Area'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poster similarity is defined as the sum of tpms, tpsa, psa, and bow minus the number of common authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_sim = TPMS + TPSA + PSA + BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1012L, 1012L)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_day = list(poster_df.PosterSession.values)\n",
    "poster_fixed = set(poster_df[poster_df.Decision != 'Poster'].index.values)\n",
    "poster_free = list(poster_df[poster_df.Decision == 'Poster'].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 38,\n",
       " 39,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 69,\n",
       " 70,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 78,\n",
       " 79,\n",
       " 81,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 102,\n",
       " 105,\n",
       " 106,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 129,\n",
       " 131,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 177,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 197,\n",
       " 198,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 206,\n",
       " 207,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 227,\n",
       " 228,\n",
       " 230,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 239,\n",
       " 240,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 264,\n",
       " 265,\n",
       " 267,\n",
       " 269,\n",
       " 270,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 290,\n",
       " 291,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 316,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 348,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 361,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 373,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 429,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 462,\n",
       " 464,\n",
       " 465,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 483,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 496,\n",
       " 497,\n",
       " 500,\n",
       " 501,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 516,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 532,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 548,\n",
       " 549,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 571,\n",
       " 572,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 634,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 644,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 651,\n",
       " 652,\n",
       " 654,\n",
       " 655,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 679,\n",
       " 681,\n",
       " 682,\n",
       " 685,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 715,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 722,\n",
       " 723,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 752,\n",
       " 754,\n",
       " 755,\n",
       " 757,\n",
       " 758,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 806,\n",
       " 807,\n",
       " 809,\n",
       " 812,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 824,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 846,\n",
       " 847,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 874,\n",
       " 875,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 882,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 899,\n",
       " 900,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 921,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 934,\n",
       " 936,\n",
       " 937,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 958,\n",
       " 959,\n",
       " 961,\n",
       " 962,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 984,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 991,\n",
       " 994,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999,\n",
       " 1000,\n",
       " 1001,\n",
       " 1003,\n",
       " 1004,\n",
       " 1006,\n",
       " 1007,\n",
       " 1008,\n",
       " 1009,\n",
       " 1010,\n",
       " 1011]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpsa_vc = poster_df['Top-level Primary Subject Area'].value_counts()\n",
    "tpsa_idx = dict(zip(tpsa_vc.index, range(len(tpsa_vc))))\n",
    "poster_df['tpsa'] = poster_df['Top-level Primary Subject Area'].apply(lambda x: tpsa_idx[x])\n",
    "poster_tpsa = poster_df['tpsa'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poster size contraint\n",
    "def count_violators(label, constraints):\n",
    "    for day, size in enumerate(constraints):\n",
    "        day += 1\n",
    "        cnt = sum(1 for l in label if l == day)\n",
    "        if cnt != size:\n",
    "            print 'day %d: size (%d) != count (%d)' % (day, size, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_conflicts(label, conflicts):\n",
    "    return [((i,j),v,label[i]) for (i,j),v in conflicts.iteritems() if label[i] == label[j] and j > i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def check_label_topic_dist(label, topic):    \n",
    "    for g, v in sorted(Counter(zip(label,topic)).items()):\n",
    "        print g, v        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(i,j) for i in range(len(poster_day)-1) for j in range(i+1, len(poster_day))]\n",
    "\n",
    "def metric(label, sim, conflicts):\n",
    "    total_sim = sum(sim[i,j] for i,j in pairs if label[i] == label[j])\n",
    "    total_conflict = sum(1 for (i,j),v in conflicts.iteritems() if label[i] == label[j])\n",
    "    return total_sim, total_conflict    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(vals, swap=None):\n",
    "    # do the swap before computation\n",
    "    if swap is not None:\n",
    "        src, dst = swap\n",
    "        vals[src] -= 1\n",
    "        vals[dst] += 1\n",
    "        \n",
    "    m = 1.0*sum(vals)/len(vals)    \n",
    "    res = max(0, max(vals) - m)\n",
    "    \n",
    "    # undo the swap after computation\n",
    "    if swap is not None:\n",
    "        src, dst = swap\n",
    "        vals[src] += 1\n",
    "        vals[dst] -= 1\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "class Searcher(object):\n",
    "    def __init__(self, label, topic, sim, conflicts):\n",
    "        self.L = label\n",
    "        self.N = len(label)\n",
    "        self.nLabel = max(label)+1\n",
    "        \n",
    "        self.T = topic        \n",
    "        self.nTopic = len(set(topic))\n",
    "        self.Bcnt = dict((i, [0]*self.nLabel) for i in xrange(self.nTopic))\n",
    "        for i in range(len(label)):\n",
    "            self.Bcnt[topic[i]][label[i]] += 1\n",
    "            \n",
    "        self.Bval = sum(balance(vals) for t,vals in self.Bcnt.iteritems())        \n",
    "        \n",
    "        self.S = sim\n",
    "        self.Sval = sum(sim[i,j] for i in xrange(len(label)-1) for j in xrange(i+1, len(label)) if label[i] == label[j])        \n",
    "        \n",
    "        self.C = conflicts        \n",
    "        self.Cval = sum(1 for (i,j),v in conflicts.iteritems() if label[i] == label[j])                \n",
    "            \n",
    "    def value(self):        \n",
    "        return self.Sval, self.Cval, self.Bval\n",
    "        \n",
    "    def update(self, i, j, mode):        \n",
    "        N, L, S, C, T, Bcnt = self.N, self.L, self.S, self.C, self.T, self.Bcnt\n",
    "        Li = L[i]\n",
    "        Lj = L[j]\n",
    "        if Li != Lj:\n",
    "            # changes due to swap of label between i and j            \n",
    "            oldSi = sum(S[i,k] for k in xrange(i+1, N) if Li == L[k]) + sum(S[k,i] for k in xrange(i) if Li == L[k])\n",
    "            newSi = sum(S[i,k] for k in xrange(i+1, N) if Lj == L[k]) + sum(S[k,i] for k in xrange(i) if Lj == L[k])\n",
    "            oldSj = sum(S[j,k] for k in xrange(j+1, N) if Lj == L[k]) + sum(S[k,j] for k in xrange(j) if Lj == L[k])\n",
    "            newSj = sum(S[j,k] for k in xrange(j+1, N) if Li == L[k]) + sum(S[k,j] for k in xrange(j) if Li == L[k])                                                \n",
    "            newSval = self.Sval - oldSi + newSi - oldSj + newSj\n",
    "            \n",
    "            oldCi = sum(1 for (a,b),v in C.iteritems() if (a == i and Li == L[b]) or (b == i and Li == L[a]))\n",
    "            newCi = sum(1 for (a,b),v in C.iteritems() if (a == i and Lj == L[b]) or (b == i and Lj == L[a]))\n",
    "            oldCj = sum(1 for (a,b),v in C.iteritems() if (a == j and Lj == L[b]) or (b == i and Lj == L[a]))\n",
    "            newCj = sum(1 for (a,b),v in C.iteritems() if (a == j and Li == L[b]) or (b == i and Li == L[a]))\n",
    "            newCval = self.Cval - oldCi + newCi - oldCj + newCj\n",
    "            \n",
    "            oldBi = balance(Bcnt[T[i]])\n",
    "            newBi = balance(Bcnt[T[i]], (Li, Lj))\n",
    "            oldBj = balance(Bcnt[T[j]])\n",
    "            newBj = balance(Bcnt[T[j]], (Lj, Li))            \n",
    "            newBval = self.Bval - oldBi + newBi - oldBj + newBj\n",
    "\n",
    "            do_update = False\n",
    "            if mode == 'sim':\n",
    "                if newSval > self.Sval and self.Cval >= newCval and self.Bval >= newBval:\n",
    "                    do_update = True\n",
    "            elif mode == 'con':\n",
    "                if newSval >= self.Sval*0.95 and self.Cval > newCval and self.Bval >= newBval:\n",
    "                    do_update = True\n",
    "            elif mode == 'bal':\n",
    "                if newSval >= self.Sval*0.95 and self.Cval >= newCval and self.Bval > newBval:\n",
    "                    do_update = True\n",
    "            elif mode == 'force':\n",
    "                do_update = True\n",
    "                                    \n",
    "            if do_update:\n",
    "                self.Cval = newCval\n",
    "                self.Sval = newSval\n",
    "                self.Bval = newBval\n",
    "                self.Bcnt[T[i]][Li] -= 1\n",
    "                self.Bcnt[T[i]][Lj] += 1\n",
    "                self.Bcnt[T[j]][Lj] -= 1                \n",
    "                self.Bcnt[T[j]][Li] += 1                               \n",
    "                self.L[i], self.L[j] = self.L[j], self.L[i]      \n",
    "\n",
    "        return self.value()\n",
    "        \n",
    "    def optimize_similarities(self, i, j):\n",
    "        return self.update(i,j,'sim')\n",
    "    \n",
    "    def optimize_conflicts(self, i, j):\n",
    "        return self.update(i,j,'con')\n",
    "    \n",
    "    def optimize_balance(self, i, j):\n",
    "        return self.update(i,j,'bal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 246 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(314320.6206786493, 1042)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time metric(poster_day, poster_sim, poster_conflicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random initialization\n",
    "num_posters_per_day = [169, 169, 169, 169, 168,168]\n",
    "np.random.shuffle(poster_free)\n",
    "start = 0\n",
    "for day in [1,2,3,4,5,6]:\n",
    "    n = sum(1 for i in poster_day if i == day)\n",
    "    gap = num_posters_per_day[day-1] - n    \n",
    "    for p in poster_free[start:start+gap]:\n",
    "        poster_day[p] = day\n",
    "    start = start + gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(poster_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[sim] 79411.78, 264, 64'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "searcher = Searcher(poster_day, poster_tpsa, poster_sim, poster_conflicts)\n",
    "update_cnt = 0\n",
    "for epoch in tnrange(1):\n",
    "    np.random.shuffle(poster_free)\n",
    "    for i,j in zip(poster_free[:-1:2], poster_free[1::2]):        \n",
    "        sval, cval, bval = searcher.optimize_balance(i, j)\n",
    "        update_cnt += 1\n",
    "        if update_cnt % 500 == 1:\n",
    "            clear_output()\n",
    "            display('[bal] %.2f, %d, %d' % (sval, cval, bval))        \n",
    "    \n",
    "    np.random.shuffle(poster_free)\n",
    "    for i,j in zip(poster_free[:-1:2], poster_free[1::2]):        \n",
    "        sval, cval, bval = searcher.optimize_conflicts(i, j)\n",
    "        update_cnt += 1\n",
    "        if update_cnt % 500 == 1:\n",
    "            clear_output()\n",
    "            display('[con] %.2f, %d, %d' % (sval, cval, bval))\n",
    "\n",
    "    np.random.shuffle(poster_free)\n",
    "    for i,j in zip(poster_free[:-1:2], poster_free[1::2]):        \n",
    "        sval, cval, bval = searcher.optimize_similarities(i, j)\n",
    "        update_cnt += 1\n",
    "        if update_cnt % 500 == 1:\n",
    "            clear_output()\n",
    "            display('[sim] %.2f, %d, %d' % (sval, cval, bval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_violators(poster_day, num_posters_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0) 33\n",
      "(1, 1) 37\n",
      "(1, 2) 36\n",
      "(1, 3) 14\n",
      "(1, 4) 19\n",
      "(1, 5) 11\n",
      "(1, 6) 6\n",
      "(1, 7) 7\n",
      "(1, 8) 2\n",
      "(1, 9) 2\n",
      "(1, 11) 1\n",
      "(1, 12) 1\n",
      "(2, 0) 38\n",
      "(2, 1) 37\n",
      "(2, 2) 36\n",
      "(2, 3) 11\n",
      "(2, 4) 15\n",
      "(2, 5) 13\n",
      "(2, 6) 11\n",
      "(2, 7) 7\n",
      "(2, 8) 1\n",
      "(3, 0) 27\n",
      "(3, 1) 37\n",
      "(3, 2) 33\n",
      "(3, 3) 22\n",
      "(3, 4) 19\n",
      "(3, 5) 9\n",
      "(3, 6) 15\n",
      "(3, 7) 5\n",
      "(3, 8) 1\n",
      "(3, 10) 1\n",
      "(4, 0) 33\n",
      "(4, 1) 19\n",
      "(4, 2) 36\n",
      "(4, 3) 24\n",
      "(4, 4) 15\n",
      "(4, 5) 21\n",
      "(4, 6) 18\n",
      "(4, 7) 3\n",
      "(5, 0) 38\n",
      "(5, 1) 27\n",
      "(5, 2) 29\n",
      "(5, 3) 24\n",
      "(5, 4) 19\n",
      "(5, 5) 10\n",
      "(5, 6) 12\n",
      "(5, 7) 6\n",
      "(5, 9) 2\n",
      "(5, 10) 1\n",
      "(6, 0) 38\n",
      "(6, 1) 37\n",
      "(6, 2) 23\n",
      "(6, 3) 11\n",
      "(6, 4) 10\n",
      "(6, 5) 21\n",
      "(6, 6) 18\n",
      "(6, 7) 5\n",
      "(6, 8) 3\n",
      "(6, 9) 2\n"
     ]
    }
   ],
   "source": [
    "check_label_topic_dist(poster_day, poster_tpsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(find_conflicts(poster_day, poster_conflicts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 247 1 1\n",
      "42 809 1 3\n"
     ]
    }
   ],
   "source": [
    "for (i,j),_,_ in find_conflicts(poster_day, poster_conflicts):\n",
    "    ni = len(poster_df.iloc[i]['Author Emails'].split(';'))\n",
    "    nj = len(poster_df.iloc[j]['Author Emails'].split(';'))\n",
    "    if ni == 1 or nj == 1:\n",
    "        print i,j,ni,nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "79512.18, 186\n",
      "1\n",
      "79590.84, 186\n",
      "2\n",
      "79683.57, 184\n",
      "3\n",
      "79780.75, 184\n",
      "4\n",
      "79881.14, 184\n",
      "5\n",
      "80024.91, 178\n",
      "6\n",
      "80165.12, 176\n",
      "7\n",
      "80286.04, 168\n",
      "8\n",
      "80390.09, 168\n",
      "9\n",
      "80561.63, 166\n",
      "10\n",
      "80749.75, 164\n",
      "11\n",
      "80781.21, 160\n",
      "12\n",
      "80881.42, 156\n",
      "13\n",
      "81054.12, 156\n",
      "14\n",
      "81190.36, 154\n",
      "15\n",
      "81359.00, 148\n",
      "16\n",
      "81514.38, 142\n",
      "17\n",
      "81744.73, 142\n",
      "18\n",
      "81931.88, 142\n",
      "19\n",
      "82141.19, 142\n",
      "20\n",
      "82273.57, 142\n",
      "21\n",
      "82519.25, 134\n",
      "22\n",
      "82705.31, 134\n",
      "23\n",
      "82951.89, 134\n",
      "24\n",
      "83123.45, 132\n",
      "25\n",
      "83247.63, 132\n",
      "26\n",
      "83426.24, 132\n",
      "27\n",
      "83647.67, 132\n",
      "28\n",
      "84101.04, 132\n",
      "29\n",
      "84254.24, 132\n",
      "30\n",
      "84305.46, 130\n",
      "31\n",
      "84516.31, 130\n",
      "32\n",
      "84749.94, 128\n",
      "33\n",
      "85051.96, 128\n",
      "34\n",
      "85115.54, 124\n",
      "35\n",
      "85393.56, 122\n",
      "36\n",
      "85597.13, 118\n",
      "37\n",
      "85677.16, 118\n",
      "38\n",
      "85941.78, 114\n",
      "39\n",
      "86056.02, 112\n",
      "40\n",
      "86135.97, 110\n",
      "41\n",
      "86485.82, 110\n",
      "42\n",
      "86638.45, 110\n",
      "43\n",
      "86813.80, 110\n",
      "44\n",
      "86863.06, 110\n",
      "45\n",
      "87112.83, 106\n",
      "46\n",
      "87311.92, 106\n",
      "47\n",
      "87493.90, 106\n",
      "48\n",
      "87585.96, 106\n",
      "49\n",
      "87664.42, 106\n",
      "50\n",
      "87899.82, 106\n",
      "51\n",
      "88289.22, 106\n",
      "52\n",
      "88509.63, 104\n",
      "53\n",
      "88786.12, 104\n",
      "54\n",
      "88974.22, 104\n",
      "55\n",
      "89058.66, 104\n",
      "56\n",
      "89221.99, 104\n",
      "57\n",
      "89539.58, 104\n",
      "58\n",
      "89905.04, 102\n",
      "59\n",
      "90114.03, 102\n",
      "60\n",
      "90265.63, 102\n",
      "61\n",
      "90510.27, 100\n",
      "62\n",
      "90736.35, 100\n",
      "63\n",
      "90907.24, 100\n",
      "64\n",
      "91042.73, 100\n",
      "65\n",
      "91139.91, 100\n",
      "66\n",
      "91257.53, 100\n",
      "67\n",
      "91528.64, 100\n",
      "68\n",
      "92001.64, 100\n",
      "69\n",
      "92203.22, 100\n",
      "70\n",
      "92428.06, 100\n",
      "71\n",
      "92530.31, 100\n",
      "72\n",
      "92699.59, 100\n",
      "73\n",
      "93137.72, 98\n",
      "74\n",
      "93305.09, 98\n",
      "75\n",
      "93429.47, 98\n",
      "76\n",
      "93501.71, 98\n",
      "77\n",
      "93522.22, 98\n",
      "78\n",
      "93888.27, 96\n",
      "79\n",
      "93983.15, 96\n",
      "80\n",
      "93983.15, 96\n",
      "81\n",
      "94097.96, 94\n",
      "82\n",
      "94303.09, 94\n",
      "83\n",
      "94479.62, 94\n",
      "84\n",
      "94599.33, 94\n",
      "85\n",
      "94599.33, 94\n",
      "86\n",
      "94706.38, 94\n",
      "87\n",
      "94989.26, 94\n",
      "88\n",
      "95117.90, 94\n",
      "89\n",
      "95180.46, 94\n",
      "90\n",
      "95325.12, 94\n",
      "91\n",
      "95460.50, 94\n",
      "92\n",
      "95464.74, 94\n",
      "93\n",
      "95468.20, 94\n",
      "94\n",
      "95582.02, 94\n",
      "95\n",
      "95843.12, 94\n",
      "96\n",
      "96021.73, 94\n",
      "97\n",
      "96138.96, 94\n",
      "98\n",
      "96211.66, 94\n",
      "99\n",
      "96306.94, 94\n",
      "100\n",
      "96353.82, 94\n",
      "101\n",
      "96385.29, 94\n",
      "102\n",
      "96480.22, 94\n",
      "103\n",
      "96629.61, 90\n",
      "104\n",
      "96661.83, 90\n",
      "105\n",
      "96791.12, 90\n",
      "106\n",
      "96927.38, 90\n",
      "107\n",
      "97051.98, 90\n",
      "108\n",
      "97134.16, 90\n",
      "109\n",
      "97244.09, 90\n",
      "110\n",
      "97517.43, 90\n",
      "111\n",
      "97517.43, 90\n",
      "112\n",
      "97541.58, 90\n",
      "113\n",
      "97551.80, 88\n",
      "114\n",
      "97647.28, 88\n",
      "115\n",
      "97765.02, 88\n",
      "116\n",
      "97793.98, 88\n",
      "117\n",
      "98035.13, 88\n",
      "118\n",
      "98051.28, 88\n",
      "119\n",
      "98160.54, 88\n",
      "120\n",
      "98248.50, 88\n",
      "121\n",
      "98275.81, 88\n",
      "122\n",
      "98427.88, 88\n",
      "123\n",
      "98494.38, 86\n",
      "124\n",
      "98769.70, 86\n",
      "125\n",
      "98769.70, 86\n",
      "126\n",
      "98988.38, 86\n",
      "127\n",
      "99146.77, 86\n",
      "128\n",
      "99146.77, 86\n",
      "129\n",
      "99159.59, 86\n",
      "130\n",
      "99262.24, 86\n",
      "131\n",
      "99262.24, 86\n",
      "132\n",
      "99298.44, 84\n",
      "133\n",
      "99310.65, 84\n",
      "134\n",
      "99446.54, 84\n",
      "135\n",
      "99470.02, 84\n",
      "136\n",
      "99534.58, 84\n",
      "137\n",
      "99685.65, 84\n",
      "138\n",
      "99738.75, 84\n",
      "139\n",
      "99750.64, 84\n",
      "140\n",
      "99768.47, 84\n",
      "141\n",
      "99901.12, 82\n",
      "142\n",
      "100021.62, 82\n",
      "143\n",
      "100158.91, 82\n",
      "144\n",
      "100194.23, 82\n",
      "145\n",
      "100194.23, 82\n",
      "146\n",
      "100211.09, 82\n",
      "147\n",
      "100259.76, 82\n",
      "148\n",
      "100371.50, 82\n",
      "149\n",
      "100425.64, 82\n",
      "150\n",
      "100462.04, 82\n",
      "151\n",
      "100503.82, 82\n",
      "152\n",
      "100578.00, 82\n",
      "153\n",
      "100593.33, 80\n",
      "154\n",
      "100611.13, 80\n",
      "155\n",
      "100630.58, 80\n",
      "156\n",
      "100830.00, 78\n",
      "157\n",
      "100868.04, 78\n",
      "158\n",
      "100975.54, 78\n",
      "159\n",
      "101103.13, 78\n",
      "160\n",
      "101348.24, 78\n",
      "161\n",
      "101505.33, 78\n",
      "162\n",
      "101617.86, 78\n",
      "163\n",
      "101652.95, 78\n",
      "164\n",
      "101671.78, 78\n",
      "165\n",
      "101817.83, 78\n",
      "166\n",
      "101826.11, 78\n",
      "167\n",
      "101925.29, 78\n",
      "168\n",
      "102124.31, 78\n",
      "169\n",
      "102330.55, 78\n",
      "170\n",
      "102421.72, 78\n",
      "171\n",
      "102512.01, 78\n",
      "172\n",
      "102512.01, 78\n",
      "173\n",
      "102599.39, 78\n",
      "174\n",
      "102628.69, 78\n",
      "175\n",
      "102722.16, 78\n",
      "176\n",
      "102910.60, 78\n",
      "177\n",
      "102976.93, 78\n",
      "178\n",
      "102976.93, 78\n",
      "179\n",
      "102981.81, 78\n",
      "180\n",
      "102981.81, 78\n",
      "181\n",
      "102981.81, 78\n",
      "182\n",
      "103172.44, 78\n",
      "183\n",
      "103300.67, 78\n",
      "184\n",
      "103301.76, 78\n",
      "185\n",
      "103324.56, 78\n",
      "186\n",
      "103446.05, 78\n",
      "187\n",
      "103462.36, 78\n",
      "188\n",
      "103645.88, 78\n",
      "189\n",
      "103728.36, 78\n",
      "190\n",
      "103728.36, 78\n",
      "191\n",
      "103867.89, 78\n",
      "192\n",
      "103867.89, 78\n",
      "193\n",
      "103943.05, 78\n",
      "194\n",
      "103946.69, 78\n",
      "195\n",
      "103946.69, 78\n",
      "196\n",
      "103997.73, 78\n",
      "197\n",
      "104001.40, 78\n",
      "198\n",
      "104010.31, 78\n",
      "199\n",
      "104032.09, 78\n",
      "200\n",
      "104044.14, 78\n",
      "201\n",
      "104132.32, 78\n",
      "202\n",
      "104148.86, 78\n",
      "203\n",
      "104161.26, 78\n",
      "204\n",
      "104166.06, 78\n",
      "205\n",
      "104166.06, 78\n",
      "206\n",
      "104166.06, 78\n",
      "207\n",
      "104290.15, 78\n",
      "208\n",
      "104311.27, 78\n",
      "209\n",
      "104330.21, 78\n",
      "210\n",
      "104431.00, 78\n",
      "211\n",
      "104431.00, 78\n",
      "212\n",
      "104472.65, 78\n",
      "213\n",
      "104499.77, 78\n",
      "214\n",
      "104509.20, 78\n",
      "215\n",
      "104521.56, 78\n",
      "216\n",
      "104576.63, 78\n",
      "217\n",
      "104594.94, 78\n",
      "218\n",
      "104663.71, 78\n",
      "219\n",
      "104663.71, 78\n",
      "220\n",
      "104752.25, 78\n",
      "221\n",
      "104774.21, 78\n",
      "222\n",
      "104775.99, 78\n",
      "223\n",
      "105038.64, 78\n",
      "224\n",
      "105066.24, 78\n",
      "225\n",
      "105066.24, 78\n",
      "226\n",
      "105072.26, 78\n",
      "227\n",
      "105192.60, 78\n",
      "228\n",
      "105192.60, 78\n",
      "229\n",
      "105199.19, 78\n",
      "230\n",
      "105212.42, 78\n",
      "231\n",
      "105268.22, 78\n",
      "232\n",
      "105296.23, 78\n",
      "233\n",
      "105299.75, 78\n",
      "234\n",
      "105299.75, 78\n",
      "235\n",
      "105299.75, 78\n",
      "236\n",
      "105387.35, 78\n",
      "237\n",
      "105452.33, 78\n",
      "238\n",
      "105468.15, 78\n",
      "239\n",
      "105468.15, 78\n",
      "240\n",
      "105504.93, 78\n",
      "241\n",
      "105504.93, 78\n",
      "242\n",
      "105522.50, 78\n",
      "243\n",
      "105618.84, 78\n",
      "244\n",
      "105727.71, 78\n",
      "245\n",
      "105727.71, 78\n",
      "246\n",
      "105727.71, 78\n",
      "247\n",
      "105769.31, 78\n",
      "248\n",
      "105779.95, 78\n",
      "249\n",
      "105779.95, 78\n",
      "250\n",
      "105872.81, 78\n",
      "251\n",
      "105884.86, 78\n",
      "252\n",
      "105884.86, 78\n",
      "253\n",
      "105884.86, 78\n",
      "254\n",
      "105884.86, 78\n",
      "255\n",
      "105884.86, 78\n",
      "256\n",
      "105914.02, 78\n",
      "257\n",
      "106012.17, 76\n",
      "258\n",
      "106100.51, 76\n",
      "259\n",
      "106100.51, 76\n",
      "260\n",
      "106100.51, 76\n",
      "261\n",
      "106100.51, 76\n",
      "262\n",
      "106139.60, 76\n",
      "263\n",
      "106158.35, 76\n",
      "264\n",
      "106315.06, 74\n",
      "265\n",
      "106315.06, 74\n",
      "266\n",
      "106315.06, 74\n",
      "267\n",
      "106348.60, 74\n",
      "268\n",
      "106376.10, 74\n",
      "269\n",
      "106376.10, 74\n",
      "270\n",
      "106412.25, 74\n",
      "271\n",
      "106413.15, 74\n",
      "272\n",
      "106428.38, 74\n",
      "273\n",
      "106429.95, 74\n",
      "274\n",
      "106429.95, 74\n",
      "275\n",
      "106429.95, 74\n",
      "276\n",
      "106429.95, 74\n",
      "277\n",
      "106429.95, 74\n",
      "278\n",
      "106448.53, 74\n",
      "279\n",
      "106476.60, 74\n",
      "280\n",
      "106476.60, 74\n",
      "281\n",
      "106480.73, 74\n",
      "282\n",
      "106567.96, 74\n",
      "283\n",
      "106568.92, 74\n",
      "284\n",
      "106568.92, 74\n",
      "285\n",
      "106568.92, 74\n",
      "286\n",
      "106592.79, 74\n",
      "287\n",
      "106592.79, 74\n",
      "288\n",
      "106628.37, 74\n",
      "289\n",
      "106628.37, 74\n",
      "290\n",
      "106628.37, 74\n",
      "291\n",
      "106651.38, 74\n",
      "292\n",
      "106670.55, 74\n",
      "293\n",
      "106670.55, 74\n",
      "294\n",
      "106888.37, 74\n",
      "295\n",
      "106897.28, 74\n",
      "296\n",
      "106897.28, 74\n",
      "297\n",
      "106899.80, 74\n",
      "298\n",
      "106899.80, 74\n",
      "299\n",
      "106999.54, 74\n",
      "300\n",
      "106999.54, 74\n",
      "301\n",
      "106999.54, 74\n",
      "302\n",
      "107080.34, 74\n",
      "303\n",
      "107080.48, 74\n",
      "304\n",
      "107123.88, 74\n",
      "305\n",
      "107123.88, 74\n",
      "306\n",
      "107123.88, 74\n",
      "307\n",
      "107129.48, 74\n",
      "308\n",
      "107129.48, 74\n",
      "309\n",
      "107134.74, 74\n",
      "310\n",
      "107137.68, 74\n",
      "311\n",
      "107137.68, 74\n",
      "312\n",
      "107179.52, 74\n",
      "313\n",
      "107179.52, 74\n",
      "314\n",
      "107187.51, 74\n",
      "315\n",
      "107187.51, 74\n",
      "316\n",
      "107187.51, 74\n",
      "317\n",
      "107205.06, 74\n",
      "318\n",
      "107206.32, 74\n",
      "319\n",
      "107206.32, 74\n",
      "320\n",
      "107315.94, 74\n",
      "321\n",
      "107349.60, 74\n",
      "322\n",
      "107426.41, 74\n",
      "323\n",
      "107426.41, 74\n",
      "324\n",
      "107426.41, 74\n",
      "325\n",
      "107426.41, 74\n",
      "326\n",
      "107433.25, 74\n",
      "327\n",
      "107433.25, 74\n",
      "328\n",
      "107433.25, 74\n",
      "329\n",
      "107433.25, 74\n",
      "330\n",
      "107433.25, 74\n",
      "331\n",
      "107433.25, 74\n",
      "332\n",
      "107433.25, 74\n",
      "333\n",
      "107476.69, 74\n",
      "334\n",
      "107476.69, 74\n",
      "335\n",
      "107499.60, 74\n",
      "336\n",
      "107499.60, 74\n",
      "337\n",
      "107506.12, 74\n",
      "338\n",
      "107506.12, 74\n",
      "339\n",
      "107506.12, 74\n",
      "340\n",
      "107506.12, 74\n",
      "341\n",
      "107508.35, 74\n",
      "342\n",
      "107509.01, 74\n",
      "343\n",
      "107509.01, 74\n",
      "344\n",
      "107517.54, 74\n",
      "345\n",
      "107517.54, 74\n",
      "346\n",
      "107611.82, 74\n",
      "347\n",
      "107611.82, 74\n",
      "348\n",
      "107620.40, 74\n",
      "349\n",
      "107620.40, 74\n",
      "350\n",
      "107620.40, 74\n",
      "351\n",
      "107620.40, 74\n",
      "352\n",
      "107642.91, 74\n",
      "353\n",
      "107642.91, 74\n",
      "354\n",
      "107642.91, 74\n",
      "355\n",
      "107655.29, 74\n",
      "356\n",
      "107822.91, 74\n",
      "357\n",
      "107822.91, 74\n",
      "358\n",
      "107822.91, 74\n",
      "359\n",
      "107822.91, 74\n",
      "360\n",
      "107860.69, 74\n",
      "361\n",
      "107860.69, 74\n",
      "362\n",
      "107860.69, 74\n",
      "363\n",
      "107860.69, 74\n",
      "364\n",
      "107860.96, 74\n",
      "365\n",
      "107860.96, 74\n",
      "366\n",
      "107863.07, 74\n",
      "367\n",
      "107863.07, 74\n",
      "368\n",
      "107949.83, 74\n",
      "369\n",
      "107949.83, 74\n",
      "370\n",
      "107949.83, 74\n",
      "371\n",
      "107949.83, 74\n",
      "372\n",
      "107949.83, 74\n",
      "373\n",
      "107949.83, 74\n",
      "374\n",
      "107949.83, 74\n",
      "375\n",
      "108014.81, 74\n",
      "376\n",
      "108070.59, 74\n",
      "377\n",
      "108099.78, 74\n",
      "378\n",
      "108099.78, 74\n",
      "379\n",
      "108099.78, 74\n",
      "380\n",
      "108099.78, 74\n",
      "381\n",
      "108099.78, 74\n",
      "382\n",
      "108099.78, 74\n",
      "383\n",
      "108159.29, 74\n",
      "384\n",
      "108159.29, 74\n",
      "385\n",
      "108159.29, 74\n",
      "386\n",
      "108159.29, 74\n",
      "387\n",
      "108159.95, 74\n",
      "388\n",
      "108159.95, 74\n",
      "389\n",
      "108159.95, 74\n",
      "390\n",
      "108159.95, 74\n",
      "391\n",
      "108163.91, 74\n",
      "392\n",
      "108163.91, 74\n",
      "393\n",
      "108163.91, 74\n",
      "394\n",
      "108166.69, 74\n",
      "395\n",
      "108166.69, 74\n",
      "396\n",
      "108201.52, 74\n",
      "397\n",
      "108201.52, 74\n",
      "398\n",
      "108201.52, 74\n",
      "399\n",
      "108201.52, 74\n"
     ]
    }
   ],
   "source": [
    "best_sim_score, best_conflict_loss = metric(poster_day, poster_sim, poster_conflicts)\n",
    "# set large number\n",
    "for epoch in range(400):\n",
    "    np.random.shuffle(poster_free)\n",
    "    for i,j in combinations(poster_free[:20], 2):\n",
    "        if (i not in poster_fixed) and (j not in poster_fixed) and (poster_day[i] != poster_day[j]):\n",
    "            poster_day[i], poster_day[j] = poster_day[j], poster_day[i]\n",
    "            s, c = metric(poster_day, poster_sim, poster_conflicts)\n",
    "            if s >= best_sim_score and c <= best_conflict_loss:\n",
    "                best_sim_score = s\n",
    "                best_conflict_loss = c\n",
    "            else:\n",
    "                poster_day[i], poster_day[j] = poster_day[j], poster_day[i]\n",
    "    print epoch\n",
    "    print '%.2f, %d' % metric(poster_day, poster_sim, poster_conflicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper ID</th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Author Emails</th>\n",
       "      <th>Subject Areas</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Primary Subject Area</th>\n",
       "      <th>Top-level Primary Subject Area</th>\n",
       "      <th>bow</th>\n",
       "      <th>pid</th>\n",
       "      <th>tpms</th>\n",
       "      <th>tsne_all</th>\n",
       "      <th>tsne_tpms</th>\n",
       "      <th>Session</th>\n",
       "      <th>PosterSession</th>\n",
       "      <th>tpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Efficient Algorithms for Non-convex Isotonic R...</td>\n",
       "      <td>We consider the minimization of submodular fun...</td>\n",
       "      <td>francis.bach@inria.fr</td>\n",
       "      <td>Optimization/Submodular Optimization*; Optimiz...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Optimization/Submodular Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[effici, algorithm, non, convex, isoton, regre...</td>\n",
       "      <td>29</td>\n",
       "      <td>[0.724210006, 0.547847061, 0.62121431, 0.69992...</td>\n",
       "      <td>29.950420</td>\n",
       "      <td>41.906616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Structure-Aware Convolutional Neural Networks</td>\n",
       "      <td>Convolutional neural networks (CNNs) are inher...</td>\n",
       "      <td>jianlong.chang@nlpr.ia.ac.cn;jie.gu@nlpr.ia.ac...</td>\n",
       "      <td>Deep Learning*; Deep Learning/CNN Architecture...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[structur, awar, convolut, neural, network, co...</td>\n",
       "      <td>33</td>\n",
       "      <td>[0.722796601, 0.7524726279999999, 0.681080612,...</td>\n",
       "      <td>69.435448</td>\n",
       "      <td>-41.231922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>Kalman Normalization</td>\n",
       "      <td>As an indispensable component, Batch Normaliza...</td>\n",
       "      <td>wanggrun@mail2.sysu.edu.cn;jiefengpeng@gmail.c...</td>\n",
       "      <td>Deep Learning/CNN Architectures*; Applications...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/CNN Architectures</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[kalman, normal, indispens, compon, batch, nor...</td>\n",
       "      <td>34</td>\n",
       "      <td>[0.605652029, 0.624528822, 0.5549479039999999,...</td>\n",
       "      <td>75.101242</td>\n",
       "      <td>-22.875866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>HOGWILD!-Gibbs can be PanAccurate</td>\n",
       "      <td>Asynchronous Gibbs sampling has been recently ...</td>\n",
       "      <td>costis@csail.mit.edu;ndikkala@mit.edu;jayanti@...</td>\n",
       "      <td>Probabilistic Methods/Distributed Inference*; ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Distributed Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[hogwild, gibb, panaccur, asynchron, gibb, sam...</td>\n",
       "      <td>37</td>\n",
       "      <td>[0.6039084920000001, 0.571028136, 0.547187392,...</td>\n",
       "      <td>-42.259544</td>\n",
       "      <td>22.692909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>Text-Adaptive Generative Adversarial Networks:...</td>\n",
       "      <td>This paper addresses the problem of manipulati...</td>\n",
       "      <td>shnnam@yonsei.ac.kr;kim_yunji@yonsei.ac.kr;seo...</td>\n",
       "      <td>Applications/Computational Photography*; Appli...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Applications/Computational Photography</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[text, adapt, gener, adversari, network, manip...</td>\n",
       "      <td>40</td>\n",
       "      <td>[0.6074082789999999, 0.604121554, 0.5843663610...</td>\n",
       "      <td>-8.646683</td>\n",
       "      <td>-43.590607</td>\n",
       "      <td>D3_S2_T2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59</td>\n",
       "      <td>IntroVAE: Introspective Variational Autoencode...</td>\n",
       "      <td>We present a novel introspective variational a...</td>\n",
       "      <td>huaibo.huang@cripac.ia.ac.cn;zhihang.li@nlpr.i...</td>\n",
       "      <td>Deep Learning/Generative Models*; Deep Learnin...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Generative Models</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[introva, introspect, variat, autoencod, photo...</td>\n",
       "      <td>59</td>\n",
       "      <td>[0.554898813, 0.566786583, 0.514959909, 0.5606...</td>\n",
       "      <td>81.031715</td>\n",
       "      <td>-14.190269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>Doubly Robust Bayesian Inference for Non-Stati...</td>\n",
       "      <td>We present the very first robust Bayesian Onli...</td>\n",
       "      <td>j.knoblauch@warwick.ac.uk;j.e.jewson@warwick.a...</td>\n",
       "      <td>Applications/Time Series Analysis*; Algorithms...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Time Series Analysis</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[doubli, robust, bayesian, infer, non, station...</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.811906661, 0.7286812490000001, 0.745909935,...</td>\n",
       "      <td>-18.716530</td>\n",
       "      <td>-3.146081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>Adapted Deep Embeddings: A Synthesis of Method...</td>\n",
       "      <td>The focus in machine learning has branched bey...</td>\n",
       "      <td>tysc7237@colorado.edu;karl.ridgeway@colorado.e...</td>\n",
       "      <td>Algorithms/Multitask and Transfer Learning*; A...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Multitask and Transfer Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[adapt, deep, embed, synthesi, method, shot, i...</td>\n",
       "      <td>75</td>\n",
       "      <td>[0.7246898359999999, 0.74860931, 0.72164041200...</td>\n",
       "      <td>-55.623451</td>\n",
       "      <td>-29.995140</td>\n",
       "      <td>D3_S1_T1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77</td>\n",
       "      <td>Generalized Inverse Optimization through Onlin...</td>\n",
       "      <td>Inverse optimization is a powerful paradigm fo...</td>\n",
       "      <td>chaosheng@pitt.edu;yiran.chen@duke.edu;bzeng@p...</td>\n",
       "      <td>Algorithms/Online Learning*; Applications/Quan...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Online Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[gener, invers, optim, onlin, learn, invers, o...</td>\n",
       "      <td>77</td>\n",
       "      <td>[0.8553071390000001, 0.729569048, 0.771284843,...</td>\n",
       "      <td>-79.361519</td>\n",
       "      <td>25.245207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>85</td>\n",
       "      <td>An Off-policy Policy Gradient Theorem Using Em...</td>\n",
       "      <td>Policy gradient methods are widely used for co...</td>\n",
       "      <td>imani@ualberta.ca;graves@ualberta.ca;whitem@ua...</td>\n",
       "      <td>Reinforcement Learning and Planning/Reinforcem...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Reinforcement Learning and Planning/Reinforcem...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>[polici, polici, gradient, theorem, use, empha...</td>\n",
       "      <td>85</td>\n",
       "      <td>[0.5770863589999999, 0.523376441, 0.518179388,...</td>\n",
       "      <td>44.501297</td>\n",
       "      <td>7.835011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>88</td>\n",
       "      <td>Supervised autoencoders: Improving generalizat...</td>\n",
       "      <td>Generalization performance is a central goal i...</td>\n",
       "      <td>leile@iu.edu;andnpatt@iu.edu;whitem@ualberta.ca</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learnin</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[supervis, autoencod, improv, gener, perform, ...</td>\n",
       "      <td>88</td>\n",
       "      <td>[0.7831208590000001, 0.8086628229999999, 0.745...</td>\n",
       "      <td>-58.400303</td>\n",
       "      <td>-27.623331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>92</td>\n",
       "      <td>Visual Object Networks: Image Generation with ...</td>\n",
       "      <td>Recent progress in deep generative models has ...</td>\n",
       "      <td>junyanz@mit.edu;ztzhang@mit.edu;ckzhang@mit.ed...</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[visual, object, network, imag, gener, disenta...</td>\n",
       "      <td>92</td>\n",
       "      <td>[0.622592223, 0.620137725, 0.574635252, 0.6193...</td>\n",
       "      <td>85.215065</td>\n",
       "      <td>-45.918297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>95</td>\n",
       "      <td>Understanding Weight Normalized Deep Neural Ne...</td>\n",
       "      <td>This paper presents a general framework for no...</td>\n",
       "      <td>xu573@purdue.edu;wangxiao@purdue.edu</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theor</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[understand, weight, normal, deep, neural, net...</td>\n",
       "      <td>95</td>\n",
       "      <td>[0.644970711, 0.6021990779999999, 0.611452154,...</td>\n",
       "      <td>9.355120</td>\n",
       "      <td>0.585828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>99</td>\n",
       "      <td>Learning Pipelines with Limited Data and Domai...</td>\n",
       "      <td>As machine learning becomes more widely used i...</td>\n",
       "      <td>mrinmayaster@gmail.com;avinava.dubey@gmail.com...</td>\n",
       "      <td>Applications*; Applications/Computer Vision</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[learn, pipelin, limit, data, domain, knowledg...</td>\n",
       "      <td>99</td>\n",
       "      <td>[0.825202962, 0.8357769540000001, 0.8245410609...</td>\n",
       "      <td>-15.508667</td>\n",
       "      <td>-35.415489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>102</td>\n",
       "      <td>Learning long-range spatial dependencies with ...</td>\n",
       "      <td>Progress in deep learning has spawned great su...</td>\n",
       "      <td>drew_linsley@brown.edu;junkyung_kim@brown.edu;...</td>\n",
       "      <td>Deep Learning/Biologically Plausible Deep Netw...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Biologically Plausible Deep Netw...</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[learn, long, rang, spatial, depend, horizont,...</td>\n",
       "      <td>102</td>\n",
       "      <td>[0.753889782, 0.8060686090000001, 0.7139329390...</td>\n",
       "      <td>66.520264</td>\n",
       "      <td>-39.277554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>110</td>\n",
       "      <td>Joint Sub-bands Learning with Clique Structure...</td>\n",
       "      <td>Convolutional neural networks (CNNs) have rece...</td>\n",
       "      <td>zszhong@pku.edu.cn;tianchengshen@pku.edu.cn;ib...</td>\n",
       "      <td>Applications/Computer Vision*; Deep Learning/C...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[joint, sub, band, learn, cliqu, structur, wav...</td>\n",
       "      <td>110</td>\n",
       "      <td>[0.665462302, 0.631348907, 0.61443569, 0.65938...</td>\n",
       "      <td>-3.620618</td>\n",
       "      <td>-41.783928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>142</td>\n",
       "      <td>Fast Similarity Search via Optimal Sparse Lifting</td>\n",
       "      <td>Similarity search is a fundamental problem in ...</td>\n",
       "      <td>wyli@cuhk.edu.cn;216019005@link.cuhk.edu.cn;yi...</td>\n",
       "      <td>Algorithms/Sparse Coding and Dimensionality Ex...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Sparse Coding and Dimensionality Ex...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[fast, similar, search, via, optim, spars, lif...</td>\n",
       "      <td>142</td>\n",
       "      <td>[0.8577442009999999, 0.7920245159999999, 0.809...</td>\n",
       "      <td>-59.549507</td>\n",
       "      <td>-19.159504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>145</td>\n",
       "      <td>Learning Deep Disentangled Embeddings With the...</td>\n",
       "      <td>Deep-embedding methods aim to discover represe...</td>\n",
       "      <td>karl.ridgeway@colorado.edu;mozer@colorado.edu</td>\n",
       "      <td>Algorithms/Representation Learning*; Algorithm...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[learn, deep, disentangl, embed, statist, loss...</td>\n",
       "      <td>145</td>\n",
       "      <td>[0.801685634, 0.791540459, 0.772199449, 0.8187...</td>\n",
       "      <td>-52.455151</td>\n",
       "      <td>-29.709421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>153</td>\n",
       "      <td>Geometrically Coupled Monte Carlo Sampling</td>\n",
       "      <td>Monte Carlo sampling in high-dimensional, low-...</td>\n",
       "      <td>mr504@cam.ac.uk;kchoro@google.com;chalusf3@gma...</td>\n",
       "      <td>Algorithms/Stochastic Methods*; Reinforcement ...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Stochastic Methods</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[geometr, coupl, mont, carlo, sampl, mont, car...</td>\n",
       "      <td>153</td>\n",
       "      <td>[0.796080575, 0.669703717, 0.714382987, 0.7818...</td>\n",
       "      <td>-72.128998</td>\n",
       "      <td>22.797417</td>\n",
       "      <td>D2_S2_T1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>175</td>\n",
       "      <td>Cooperative Holistic 3D Scene Understanding fr...</td>\n",
       "      <td>Holistic 3D indoor scene understanding involve...</td>\n",
       "      <td>huangsiyuan@ucla.edu;syqi@cs.ucla.edu;yinxuex@...</td>\n",
       "      <td>Applications/Visual Scene Analysis and Interpr...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Visual Scene Analysis and Interpr...</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[cooper, holist, 3d, scene, understand, singl,...</td>\n",
       "      <td>175</td>\n",
       "      <td>[0.635211113, 0.587038424, 0.582188994, 0.6233...</td>\n",
       "      <td>-7.480874</td>\n",
       "      <td>-46.575882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>177</td>\n",
       "      <td>An Efficient Pruning Algorithm for Robust Isot...</td>\n",
       "      <td>We study a generalization of the classic isoto...</td>\n",
       "      <td>clim9@wisc.edu</td>\n",
       "      <td>Algorithms/Regression</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Regressio</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[effici, prune, algorithm, robust, isoton, reg...</td>\n",
       "      <td>177</td>\n",
       "      <td>[0.8350809440000001, 0.641266087, 0.761110935,...</td>\n",
       "      <td>-74.375404</td>\n",
       "      <td>41.805172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>178</td>\n",
       "      <td>PAC-learning in the presence of adversaries</td>\n",
       "      <td>The existence of evasion attacks during the te...</td>\n",
       "      <td>dcullina@princeton.edu;abhagoji@princeton.edu;...</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theor</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[pac, learn, presenc, adversari, exist, evas, ...</td>\n",
       "      <td>178</td>\n",
       "      <td>[0.5843463000000001, 0.563068797, 0.533589984,...</td>\n",
       "      <td>9.359765</td>\n",
       "      <td>-20.007828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>182</td>\n",
       "      <td>Sparse DNNs with Improved Adversarial Robustness</td>\n",
       "      <td>Deep neural networks (DNNs) are computationall...</td>\n",
       "      <td>yiwen.guo@intel.com;pkuzc@pku.edu.cn;zcs@mail....</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Algorithm...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[spars, dnn, improv, adversari, robust, deep, ...</td>\n",
       "      <td>182</td>\n",
       "      <td>[0.666966905, 0.637015755, 0.638722607, 0.7032...</td>\n",
       "      <td>84.842842</td>\n",
       "      <td>-20.159740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>185</td>\n",
       "      <td>Snap ML: A Hierarchical Framework for Machine ...</td>\n",
       "      <td>We describe a new software framework for fast ...</td>\n",
       "      <td>cdu@zurich.ibm.com;tpa@zurich.ibm.com;rig@zuri...</td>\n",
       "      <td>Applications/Hardware and Systems*; Data, Comp...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Hardware and Systems</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[snap, ml, hierarch, framework, machin, learn,...</td>\n",
       "      <td>185</td>\n",
       "      <td>[0.657971973, 0.853205806, 0.618791222, 0.6497...</td>\n",
       "      <td>-16.822359</td>\n",
       "      <td>-20.884203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>186</td>\n",
       "      <td>See and Think: Disentangling Semantic Scene Co...</td>\n",
       "      <td>Semantic scene completion predicts volumetric ...</td>\n",
       "      <td>liushice@ict.ac.cn;huyu@ict.ac.cn;zengyiming@i...</td>\n",
       "      <td>Applications/Computer Vision*; Deep Learning/C...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[see, think, disentangl, semant, scene, comple...</td>\n",
       "      <td>186</td>\n",
       "      <td>[0.657856715, 0.632397676, 0.6396587229999999,...</td>\n",
       "      <td>-4.536843</td>\n",
       "      <td>-46.435524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>187</td>\n",
       "      <td>Chain of Reasoning for Visual Question Answering</td>\n",
       "      <td>Reasoning plays an essential role in Visual Qu...</td>\n",
       "      <td>wuchenfei@bupt.edu.cn;liujinlai@bupt.edu.cn;xj...</td>\n",
       "      <td>Applications/Visual Question Answering*; Neuro...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Visual Question Answering</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[chain, reason, visual, question, answer, reas...</td>\n",
       "      <td>187</td>\n",
       "      <td>[0.632062365, 0.6729400529999999, 0.603445259,...</td>\n",
       "      <td>-10.336796</td>\n",
       "      <td>-36.345360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>188</td>\n",
       "      <td>Sigsoftmax: Reanalysis of the Softmax Bottleneck</td>\n",
       "      <td>Softmax is an output activation function for m...</td>\n",
       "      <td>kanai.sekitoshi@lab.ntt.co.jp;fujiwara.yasuhir...</td>\n",
       "      <td>Deep Learning*; Deep Learning/Recurrent Networ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[sigsoftmax, reanalysi, softmax, bottleneck, s...</td>\n",
       "      <td>188</td>\n",
       "      <td>[0.692489644, 0.790134204, 0.660755629, 0.7194...</td>\n",
       "      <td>69.954987</td>\n",
       "      <td>-24.284136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>191</td>\n",
       "      <td>Deep Non-Blind Deconvolution via Generalized L...</td>\n",
       "      <td>In this paper, we present a deep convolutional...</td>\n",
       "      <td>rwq.renwenqi@gmail.com;zhjw1988@gmail.com;fore...</td>\n",
       "      <td>Applications/Computer Vision*; Applications/De...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[deep, non, blind, deconvolut, via, gener, low...</td>\n",
       "      <td>191</td>\n",
       "      <td>[0.562258779, 0.5202836, 0.506214686, 0.550357...</td>\n",
       "      <td>-3.312739</td>\n",
       "      <td>-42.153278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>192</td>\n",
       "      <td>Probabilistic Pose Graph Optimization via Bing...</td>\n",
       "      <td>We introduce Tempered Geodesic MCMC (TG-MCMC) ...</td>\n",
       "      <td>tolga.birdal@tum.de;umut.simsekli@telecom-pari...</td>\n",
       "      <td>Applications/Computer Vision*; Applications/Ro...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Computer Vision</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[probabilist, pose, graph, optim, via, bingham...</td>\n",
       "      <td>192</td>\n",
       "      <td>[0.9113688670000001, 0.7563436379999999, 0.820...</td>\n",
       "      <td>-2.593879</td>\n",
       "      <td>27.874113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>207</td>\n",
       "      <td>MetaAnchor: Learning to Detect Objects with Cu...</td>\n",
       "      <td>We propose a novel and flexible anchor mechani...</td>\n",
       "      <td>yangt15@fudan.edu.cn;zhangxiangyu@megvii.com;l...</td>\n",
       "      <td>Applications/Object Detection</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Object Detectio</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[metaanchor, learn, detect, object, custom, an...</td>\n",
       "      <td>207</td>\n",
       "      <td>[0.620705712, 0.593533387, 0.572714624, 0.6164...</td>\n",
       "      <td>-6.911834</td>\n",
       "      <td>-44.603474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>6787</td>\n",
       "      <td>Thermostat-assisted continuously-tempered Hami...</td>\n",
       "      <td>In this paper, we propose a novel sampling met...</td>\n",
       "      <td>r.luo@cs.ucl.ac.uk;jianhong.wang.17@ucl.ac.uk;...</td>\n",
       "      <td>Probabilistic Methods/MCMC</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/MCM</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[thermostat, assist, continu, temper, hamilton...</td>\n",
       "      <td>6787</td>\n",
       "      <td>[0.646289553, 0.620857109, 0.586481252, 0.6541...</td>\n",
       "      <td>-43.545441</td>\n",
       "      <td>-4.772652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>6793</td>\n",
       "      <td>Robust Subspace Approximation in a Stream</td>\n",
       "      <td>We study robust subspace estimation in the str...</td>\n",
       "      <td>roiel@cs.cmu.edu;asevekar@andrew.cmu.edu;dwood...</td>\n",
       "      <td>Algorithms*; Algorithms/Regression</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[robust, subspac, approxim, stream, studi, rob...</td>\n",
       "      <td>6793</td>\n",
       "      <td>[0.540987701, 0.441798132, 0.49352610399999997...</td>\n",
       "      <td>-75.541176</td>\n",
       "      <td>31.828382</td>\n",
       "      <td>D3_S1_T3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>6802</td>\n",
       "      <td>Mean Field for the Stochastic Blockmodel: Opti...</td>\n",
       "      <td>Variational approximation has been widely used...</td>\n",
       "      <td>soumendu041@gmail.com;purna.sarkar@austin.utex...</td>\n",
       "      <td>Probabilistic Methods/Variational Inference*; ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Variational Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[mean, field, stochast, blockmodel, optim, lan...</td>\n",
       "      <td>6802</td>\n",
       "      <td>[0.735002521, 0.627056098, 0.647996389, 0.7320...</td>\n",
       "      <td>-45.091202</td>\n",
       "      <td>22.743847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>6832</td>\n",
       "      <td>Analysis of Krylov Subspace Solutions of  Regu...</td>\n",
       "      <td>We provide convergence rates for Krylov subspa...</td>\n",
       "      <td>ycarmon@gmail.com;jduchi@stanford.edu</td>\n",
       "      <td>Optimization/Non-Convex Optimization*; Algorit...</td>\n",
       "      <td>Oral</td>\n",
       "      <td>Optimization/Non-Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[analysi, krylov, subspac, solut, regular, non...</td>\n",
       "      <td>6832</td>\n",
       "      <td>[0.644204279, 0.46829059700000003, 0.536020003...</td>\n",
       "      <td>26.129072</td>\n",
       "      <td>43.834412</td>\n",
       "      <td>D2_S2_T3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>6836</td>\n",
       "      <td>Autoconj: Recognizing and Exploiting Conjugacy...</td>\n",
       "      <td>Deriving conditional and marginal distribution...</td>\n",
       "      <td>mdhoffma@cs.princeton.edu;mattjj@google.com;tr...</td>\n",
       "      <td>Probabilistic Methods/Graphical Models*; Data,...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Graphical Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[autoconj, recogn, exploit, conjugaci, without...</td>\n",
       "      <td>6836</td>\n",
       "      <td>[0.644937403, 0.646330124, 0.606580474, 0.6317...</td>\n",
       "      <td>-36.022869</td>\n",
       "      <td>-2.977412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>6839</td>\n",
       "      <td>DropBlock: A regularization method for convolu...</td>\n",
       "      <td>Deep neural networks often work well when they...</td>\n",
       "      <td>golnazg@google.com;tsungyi@google.com;qvl@goog...</td>\n",
       "      <td>Theory/Regularization*; Deep Learning/CNN Arch...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Regularization</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[dropblock, regular, method, convolut, network...</td>\n",
       "      <td>6839</td>\n",
       "      <td>[0.602325926, 0.709435875, 0.611376699, 0.6140...</td>\n",
       "      <td>10.156830</td>\n",
       "      <td>-40.257950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>6843</td>\n",
       "      <td>Forward Modeling for Partial Observation Strat...</td>\n",
       "      <td>We formulate the problem of \\emph{defogging} a...</td>\n",
       "      <td>gab@fb.com;zlin@fb.com;jgehring@fb.com;dangant...</td>\n",
       "      <td>Applications/Game Playing</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Game Playin</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[forward, model, partial, observ, strategi, ga...</td>\n",
       "      <td>6843</td>\n",
       "      <td>[0.64940197, 0.696797065, 0.612499372, 0.66309...</td>\n",
       "      <td>-10.947182</td>\n",
       "      <td>-31.871689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>6847</td>\n",
       "      <td>With Friends Like These, Who Needs Adversaries?</td>\n",
       "      <td>The vulnerability of deep networks to adversar...</td>\n",
       "      <td>sjetley@robots.ox.ac.uk;nicklord@robots.ox.ac....</td>\n",
       "      <td>Deep Learning*; Algorithms/Classification; Alg...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[friend, like, need, adversari, vulner, deep, ...</td>\n",
       "      <td>6847</td>\n",
       "      <td>[0.596239485, 0.552854089, 0.56523045, 0.61261...</td>\n",
       "      <td>69.137093</td>\n",
       "      <td>-26.654100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>6859</td>\n",
       "      <td>Decentralize and Randomize: Faster Algorithm f...</td>\n",
       "      <td>We study the problem of decentralized distribu...</td>\n",
       "      <td>pavel.dvurechensky@gmail.com;darina.dvinskikh@...</td>\n",
       "      <td>Optimization/Convex Optimization*; Algorithms/...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Optimization/Convex Optimization</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>[decentr, random, faster, algorithm, wasserste...</td>\n",
       "      <td>6859</td>\n",
       "      <td>[0.649590907, 0.572511066, 0.579816594, 0.6330...</td>\n",
       "      <td>32.173798</td>\n",
       "      <td>28.452133</td>\n",
       "      <td>D3_S2_T3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>6863</td>\n",
       "      <td>Joint Autoregressive and Hierarchical Priors f...</td>\n",
       "      <td>Recent models for learned image compression ar...</td>\n",
       "      <td>dminnen@google.com;jballe@google.com;gtoderici...</td>\n",
       "      <td>Algorithms/Representation Learning*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Representation Learning</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[joint, autoregress, hierarch, prior, learn, i...</td>\n",
       "      <td>6863</td>\n",
       "      <td>[0.5645583710000001, 0.599846334, 0.522823875,...</td>\n",
       "      <td>-52.424301</td>\n",
       "      <td>-30.890600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>6874</td>\n",
       "      <td>Learning Temporal Point Processes via Reinforc...</td>\n",
       "      <td>Many real world problems from sustainability, ...</td>\n",
       "      <td>sli370@gatech.edu;benjaminforever@sjtu.edu.cn;...</td>\n",
       "      <td>Applications/Time Series Analysis</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Applications/Time Series Analysi</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[learn, tempor, point, process, via, reinforc,...</td>\n",
       "      <td>6874</td>\n",
       "      <td>[0.6848055690000001, 0.606161123, 0.618028853,...</td>\n",
       "      <td>-19.862894</td>\n",
       "      <td>8.033325</td>\n",
       "      <td>D2_S1_T2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>6882</td>\n",
       "      <td>Bias and Generalization in Deep Generative Mod...</td>\n",
       "      <td>In high dimensional settings, density estimati...</td>\n",
       "      <td>sjzhao@stanford.edu;hyren@cs.stanford.edu;xfyu...</td>\n",
       "      <td>Deep Learning/Generative Models*; Deep Learnin...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Deep Learning/Generative Models</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[bia, gener, deep, gener, model, empir, studi,...</td>\n",
       "      <td>6882</td>\n",
       "      <td>[0.825245676, 0.77820804, 0.764052464, 0.83451...</td>\n",
       "      <td>80.826553</td>\n",
       "      <td>-38.422794</td>\n",
       "      <td>D2_S2_T2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>6892</td>\n",
       "      <td>Fast and Effective Robustness Certification</td>\n",
       "      <td>We present a new method and system for certify...</td>\n",
       "      <td>gsingh@inf.ethz.ch;timon.gehr@inf.ethz.ch;matt...</td>\n",
       "      <td>Deep Learning/Adversarial Networks*; Applicati...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Adversarial Networks</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[fast, effect, robust, certif, present, new, m...</td>\n",
       "      <td>6892</td>\n",
       "      <td>[0.656920721, 0.7048807429999999, 0.624150393,...</td>\n",
       "      <td>84.853836</td>\n",
       "      <td>-20.459106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>6901</td>\n",
       "      <td>Support Recovery for Orthogonal Matching Pursu...</td>\n",
       "      <td>This paper studies the problem of sparse regre...</td>\n",
       "      <td>raghavsomani1995@gmail.com;chiragpvg@gmail.com...</td>\n",
       "      <td>Algorithms/Sparsity and Compressed Sensing*; A...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Algorithms/Sparsity and Compressed Sensing</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[support, recoveri, orthogon, match, pursuit, ...</td>\n",
       "      <td>6901</td>\n",
       "      <td>[0.6322439089999999, 0.5179587760000001, 0.563...</td>\n",
       "      <td>-71.281883</td>\n",
       "      <td>30.983622</td>\n",
       "      <td>D2_S2_T3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>6905</td>\n",
       "      <td>Differentially Private Change-Point Detection</td>\n",
       "      <td>The change-point detection problem seeks to id...</td>\n",
       "      <td>krehbiel@richmond.edu;rachelc@gatech.edu;wanro...</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security*...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[differenti, privat, chang, point, detect, cha...</td>\n",
       "      <td>6905</td>\n",
       "      <td>[0.6977355690000001, 0.557927934, 0.63827413, ...</td>\n",
       "      <td>-28.408152</td>\n",
       "      <td>34.926235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>6913</td>\n",
       "      <td>Multi-value Rule Sets for Interpretable Classi...</td>\n",
       "      <td>We present Multi-value Rule Sets (MRS) for int...</td>\n",
       "      <td>tong-wang@uiowa.edu</td>\n",
       "      <td>Probabilistic Methods/Hierarchical Models*; Ap...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Hierarchical Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[multi, valu, rule, set, interpret, classif, f...</td>\n",
       "      <td>6913</td>\n",
       "      <td>[0.823699588, 0.7256162290000001, 0.770973646,...</td>\n",
       "      <td>-37.061535</td>\n",
       "      <td>16.019241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6921</td>\n",
       "      <td>Domain Adaptation by Using Causal Inference to...</td>\n",
       "      <td>An important goal common to domain adaptation ...</td>\n",
       "      <td>sara.magliacane@gmail.com;thijsvanommen@gmail....</td>\n",
       "      <td>Probabilistic Methods/Causal Inference*; Deep ...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Probabilistic Methods/Causal Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[domain, adapt, use, causal, infer, predict, i...</td>\n",
       "      <td>6921</td>\n",
       "      <td>[0.534160482, 0.482813768, 0.514349219, 0.5274...</td>\n",
       "      <td>-33.443409</td>\n",
       "      <td>13.715412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>6923</td>\n",
       "      <td>Smoothed Analysis of Discrete Tensor Decomposi...</td>\n",
       "      <td>We analyze linear independence of rank one ten...</td>\n",
       "      <td>anari.nima@gmail.com;costis@csail.mit.edu;maas...</td>\n",
       "      <td>Theory*; Algorithms/Components Analysis (e.g.,...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[smooth, analysi, discret, tensor, decomposit,...</td>\n",
       "      <td>6923</td>\n",
       "      <td>[0.693092713, 0.629186489, 0.656472765, 0.7012...</td>\n",
       "      <td>4.982391</td>\n",
       "      <td>19.488535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>6961</td>\n",
       "      <td>MixLasso: Generalized Mixed Regression via Con...</td>\n",
       "      <td>We consider a generalization of mixed regressi...</td>\n",
       "      <td>eyan@cs.cmu.edu;b01902065@ntu.edu.tw;kaizhong8...</td>\n",
       "      <td>Optimization</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Optimizatio</td>\n",
       "      <td>Optimizatio</td>\n",
       "      <td>[mixlasso, gener, mix, regress, via, convex, a...</td>\n",
       "      <td>6961</td>\n",
       "      <td>[0.791815187, 0.657667486, 0.70105964, 0.77798...</td>\n",
       "      <td>11.150247</td>\n",
       "      <td>29.388924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>6968</td>\n",
       "      <td>Semidefinite relaxations for certifying robust...</td>\n",
       "      <td>Research on adversarial examples are evolved i...</td>\n",
       "      <td>aditir1994@gmail.com;jacob.steinhardt@gmail.co...</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Security</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Privacy, Anonymity, and Securit</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[semidefinit, relax, certifi, robust, adversar...</td>\n",
       "      <td>6968</td>\n",
       "      <td>[0.612903855, 0.584632164, 0.580678234, 0.6383...</td>\n",
       "      <td>-26.983023</td>\n",
       "      <td>-19.791059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>6972</td>\n",
       "      <td>Removing Hidden Confounding by Experimental Gr...</td>\n",
       "      <td>Observational data is being increasingly used ...</td>\n",
       "      <td>kallus@cornell.edu;apm470@nyu.edu;urishalit@te...</td>\n",
       "      <td>Probabilistic Methods/Causal Inference*; Algor...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Probabilistic Methods/Causal Inference</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[remov, hidden, confound, experiment, ground, ...</td>\n",
       "      <td>6972</td>\n",
       "      <td>[0.586181571, 0.490689461, 0.549189971, 0.5911...</td>\n",
       "      <td>-33.386219</td>\n",
       "      <td>14.227854</td>\n",
       "      <td>D3_S1_T1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>6978</td>\n",
       "      <td>Topkapi: Parallel and Fast Sketches for Findin...</td>\n",
       "      <td>Identifying the top-K frequent items is one of...</td>\n",
       "      <td>ankush@gatech.edu;cary.jiang@rice.edu;anshumal...</td>\n",
       "      <td>Applications/Web Applications and Internet Dat...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Web Applications and Internet Data</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[topkapi, parallel, fast, sketch, find, top, f...</td>\n",
       "      <td>6978</td>\n",
       "      <td>[0.672761353, 0.6915534390000001, 0.673524338,...</td>\n",
       "      <td>-24.045568</td>\n",
       "      <td>1.927942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>7985</td>\n",
       "      <td>Contrastive Learning from Pairwise Measurements</td>\n",
       "      <td>Learning from pairwise measurements naturally ...</td>\n",
       "      <td>yichen2016@u.northwestern.edu;zy6@princeton.ed...</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[contrast, learn, pairwis, measur, learn, pair...</td>\n",
       "      <td>7985</td>\n",
       "      <td>[0.801794205, 0.6445370810000001, 0.70768539, ...</td>\n",
       "      <td>-70.215393</td>\n",
       "      <td>24.161211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>7992</td>\n",
       "      <td>Point process latent variable models of freely...</td>\n",
       "      <td>A fundamental goal of systems neuroscience is ...</td>\n",
       "      <td>as4529@columbia.edu;scott.linderman@columbia.e...</td>\n",
       "      <td>Probabilistic Methods/Latent Variable Models*;...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>Probabilistic Methods/Latent Variable Models</td>\n",
       "      <td>Probabilistic Methods</td>\n",
       "      <td>[point, process, latent, variabl, model, freel...</td>\n",
       "      <td>7992</td>\n",
       "      <td>[0.78844959, 0.730344946, 0.7138572390000001, ...</td>\n",
       "      <td>-47.077015</td>\n",
       "      <td>-6.283218</td>\n",
       "      <td>D1_S2_T1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>7994</td>\n",
       "      <td>Computationally and Statistically Efficient Le...</td>\n",
       "      <td>Causal discovery from empirical data is a fund...</td>\n",
       "      <td>kbellome@purdue.edu;jhonorio@purdue.edu</td>\n",
       "      <td>Theory/Learning Theory*; Probabilistic Methods...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Theory/Learning Theory</td>\n",
       "      <td>Theory</td>\n",
       "      <td>[comput, statist, effici, learn, bay, net, use...</td>\n",
       "      <td>7994</td>\n",
       "      <td>[0.442452024, 0.376913364, 0.45425219, 0.45383...</td>\n",
       "      <td>13.572625</td>\n",
       "      <td>14.079021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>7997</td>\n",
       "      <td>Sparse PCA from Sparse Linear Regression</td>\n",
       "      <td>Sparse Principal Component Analysis (SPCA) and...</td>\n",
       "      <td>guy@mit.edu;sp765@mit.edu;mpersu@mit.edu</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Algorithms/Components Analysis (e.g., CCA, ICA...</td>\n",
       "      <td>Algorithms</td>\n",
       "      <td>[spars, pca, spars, linear, regress, spars, pr...</td>\n",
       "      <td>7997</td>\n",
       "      <td>[0.755127242, 0.609168548, 0.665014251, 0.7336...</td>\n",
       "      <td>-70.626175</td>\n",
       "      <td>30.425714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>8002</td>\n",
       "      <td>Sequential Data Classification for Resource-co...</td>\n",
       "      <td>We study the problem of fast and efficient cla...</td>\n",
       "      <td>t-dodenn@microsoft.com;chiragramdas@gmail.com;...</td>\n",
       "      <td>Deep Learning/Efficient Inference Methods*; De...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Deep Learning/Efficient Inference Methods</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>[sequenti, data, classif, resourc, constrain, ...</td>\n",
       "      <td>8002</td>\n",
       "      <td>[0.849686171, 0.9341852970000001, 0.7916773859...</td>\n",
       "      <td>77.401146</td>\n",
       "      <td>-28.128359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>8009</td>\n",
       "      <td>Transfer of Deep Reactive Policies for MDP Pla...</td>\n",
       "      <td>Domain-independent probabilistic planners inpu...</td>\n",
       "      <td>quantum.computing96@gmail.com;sankalp2621998@g...</td>\n",
       "      <td>Reinforcement Learning and Planning</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Reinforcement Learning and Plannin</td>\n",
       "      <td>Reinforcement Learning and Plannin</td>\n",
       "      <td>[transfer, deep, reactiv, polici, mdp, plan, d...</td>\n",
       "      <td>8009</td>\n",
       "      <td>[0.7646644690000001, 0.7638223829999999, 0.729...</td>\n",
       "      <td>41.460049</td>\n",
       "      <td>4.912152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>8034</td>\n",
       "      <td>The Price of Fair PCA: One Extra dimension</td>\n",
       "      <td>In this paper, we investigate the possibility ...</td>\n",
       "      <td>s.samadi@gmail.com;tao@gatech.edu;jamiemor@cis...</td>\n",
       "      <td>Applications/Fairness, Accountability, and Tra...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Fairness, Accountability, and Tra...</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[price, fair, pca, one, extra, dimens, thi, pa...</td>\n",
       "      <td>8034</td>\n",
       "      <td>[0.7302362170000001, 0.631884585, 0.691013077,...</td>\n",
       "      <td>-22.797361</td>\n",
       "      <td>26.325262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>8035</td>\n",
       "      <td>GroupReduce: Block-Wise Low-Rank Approximation...</td>\n",
       "      <td>Model compression is essential for serving lar...</td>\n",
       "      <td>phpchen@ucdavis.edu;sisidaisy@google.com;liyan...</td>\n",
       "      <td>Applications/Natural Language Processing</td>\n",
       "      <td>Poster</td>\n",
       "      <td>Applications/Natural Language Processin</td>\n",
       "      <td>Applications</td>\n",
       "      <td>[groupreduc, block, wise, low, rank, approxim,...</td>\n",
       "      <td>8035</td>\n",
       "      <td>[0.7068314809999999, 0.8144392220000001, 0.691...</td>\n",
       "      <td>-13.926091</td>\n",
       "      <td>-24.498652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Paper ID                                        Paper Title  \\\n",
       "0           29  Efficient Algorithms for Non-convex Isotonic R...   \n",
       "1           33      Structure-Aware Convolutional Neural Networks   \n",
       "2           34                               Kalman Normalization   \n",
       "3           37                  HOGWILD!-Gibbs can be PanAccurate   \n",
       "4           40  Text-Adaptive Generative Adversarial Networks:...   \n",
       "5           59  IntroVAE: Introspective Variational Autoencode...   \n",
       "6           68  Doubly Robust Bayesian Inference for Non-Stati...   \n",
       "7           75  Adapted Deep Embeddings: A Synthesis of Method...   \n",
       "8           77  Generalized Inverse Optimization through Onlin...   \n",
       "9           85  An Off-policy Policy Gradient Theorem Using Em...   \n",
       "10          88  Supervised autoencoders: Improving generalizat...   \n",
       "11          92  Visual Object Networks: Image Generation with ...   \n",
       "12          95  Understanding Weight Normalized Deep Neural Ne...   \n",
       "13          99  Learning Pipelines with Limited Data and Domai...   \n",
       "14         102  Learning long-range spatial dependencies with ...   \n",
       "15         110  Joint Sub-bands Learning with Clique Structure...   \n",
       "16         142  Fast Similarity Search via Optimal Sparse Lifting   \n",
       "17         145  Learning Deep Disentangled Embeddings With the...   \n",
       "18         153         Geometrically Coupled Monte Carlo Sampling   \n",
       "19         175  Cooperative Holistic 3D Scene Understanding fr...   \n",
       "20         177  An Efficient Pruning Algorithm for Robust Isot...   \n",
       "21         178        PAC-learning in the presence of adversaries   \n",
       "22         182   Sparse DNNs with Improved Adversarial Robustness   \n",
       "23         185  Snap ML: A Hierarchical Framework for Machine ...   \n",
       "24         186  See and Think: Disentangling Semantic Scene Co...   \n",
       "25         187   Chain of Reasoning for Visual Question Answering   \n",
       "26         188   Sigsoftmax: Reanalysis of the Softmax Bottleneck   \n",
       "27         191  Deep Non-Blind Deconvolution via Generalized L...   \n",
       "28         192  Probabilistic Pose Graph Optimization via Bing...   \n",
       "29         207  MetaAnchor: Learning to Detect Objects with Cu...   \n",
       "...        ...                                                ...   \n",
       "982       6787  Thermostat-assisted continuously-tempered Hami...   \n",
       "983       6793          Robust Subspace Approximation in a Stream   \n",
       "984       6802  Mean Field for the Stochastic Blockmodel: Opti...   \n",
       "985       6832  Analysis of Krylov Subspace Solutions of  Regu...   \n",
       "986       6836  Autoconj: Recognizing and Exploiting Conjugacy...   \n",
       "987       6839  DropBlock: A regularization method for convolu...   \n",
       "988       6843  Forward Modeling for Partial Observation Strat...   \n",
       "989       6847    With Friends Like These, Who Needs Adversaries?   \n",
       "990       6859  Decentralize and Randomize: Faster Algorithm f...   \n",
       "991       6863  Joint Autoregressive and Hierarchical Priors f...   \n",
       "992       6874  Learning Temporal Point Processes via Reinforc...   \n",
       "993       6882  Bias and Generalization in Deep Generative Mod...   \n",
       "994       6892        Fast and Effective Robustness Certification   \n",
       "995       6901  Support Recovery for Orthogonal Matching Pursu...   \n",
       "996       6905      Differentially Private Change-Point Detection   \n",
       "997       6913  Multi-value Rule Sets for Interpretable Classi...   \n",
       "998       6921  Domain Adaptation by Using Causal Inference to...   \n",
       "999       6923  Smoothed Analysis of Discrete Tensor Decomposi...   \n",
       "1000      6961  MixLasso: Generalized Mixed Regression via Con...   \n",
       "1001      6968  Semidefinite relaxations for certifying robust...   \n",
       "1002      6972  Removing Hidden Confounding by Experimental Gr...   \n",
       "1003      6978  Topkapi: Parallel and Fast Sketches for Findin...   \n",
       "1004      7985    Contrastive Learning from Pairwise Measurements   \n",
       "1005      7992  Point process latent variable models of freely...   \n",
       "1006      7994  Computationally and Statistically Efficient Le...   \n",
       "1007      7997           Sparse PCA from Sparse Linear Regression   \n",
       "1008      8002  Sequential Data Classification for Resource-co...   \n",
       "1009      8009  Transfer of Deep Reactive Policies for MDP Pla...   \n",
       "1010      8034         The Price of Fair PCA: One Extra dimension   \n",
       "1011      8035  GroupReduce: Block-Wise Low-Rank Approximation...   \n",
       "\n",
       "                                               Abstract  \\\n",
       "0     We consider the minimization of submodular fun...   \n",
       "1     Convolutional neural networks (CNNs) are inher...   \n",
       "2     As an indispensable component, Batch Normaliza...   \n",
       "3     Asynchronous Gibbs sampling has been recently ...   \n",
       "4     This paper addresses the problem of manipulati...   \n",
       "5     We present a novel introspective variational a...   \n",
       "6     We present the very first robust Bayesian Onli...   \n",
       "7     The focus in machine learning has branched bey...   \n",
       "8     Inverse optimization is a powerful paradigm fo...   \n",
       "9     Policy gradient methods are widely used for co...   \n",
       "10    Generalization performance is a central goal i...   \n",
       "11    Recent progress in deep generative models has ...   \n",
       "12    This paper presents a general framework for no...   \n",
       "13    As machine learning becomes more widely used i...   \n",
       "14    Progress in deep learning has spawned great su...   \n",
       "15    Convolutional neural networks (CNNs) have rece...   \n",
       "16    Similarity search is a fundamental problem in ...   \n",
       "17    Deep-embedding methods aim to discover represe...   \n",
       "18    Monte Carlo sampling in high-dimensional, low-...   \n",
       "19    Holistic 3D indoor scene understanding involve...   \n",
       "20    We study a generalization of the classic isoto...   \n",
       "21    The existence of evasion attacks during the te...   \n",
       "22    Deep neural networks (DNNs) are computationall...   \n",
       "23    We describe a new software framework for fast ...   \n",
       "24    Semantic scene completion predicts volumetric ...   \n",
       "25    Reasoning plays an essential role in Visual Qu...   \n",
       "26    Softmax is an output activation function for m...   \n",
       "27    In this paper, we present a deep convolutional...   \n",
       "28    We introduce Tempered Geodesic MCMC (TG-MCMC) ...   \n",
       "29    We propose a novel and flexible anchor mechani...   \n",
       "...                                                 ...   \n",
       "982   In this paper, we propose a novel sampling met...   \n",
       "983   We study robust subspace estimation in the str...   \n",
       "984   Variational approximation has been widely used...   \n",
       "985   We provide convergence rates for Krylov subspa...   \n",
       "986   Deriving conditional and marginal distribution...   \n",
       "987   Deep neural networks often work well when they...   \n",
       "988   We formulate the problem of \\emph{defogging} a...   \n",
       "989   The vulnerability of deep networks to adversar...   \n",
       "990   We study the problem of decentralized distribu...   \n",
       "991   Recent models for learned image compression ar...   \n",
       "992   Many real world problems from sustainability, ...   \n",
       "993   In high dimensional settings, density estimati...   \n",
       "994   We present a new method and system for certify...   \n",
       "995   This paper studies the problem of sparse regre...   \n",
       "996   The change-point detection problem seeks to id...   \n",
       "997   We present Multi-value Rule Sets (MRS) for int...   \n",
       "998   An important goal common to domain adaptation ...   \n",
       "999   We analyze linear independence of rank one ten...   \n",
       "1000  We consider a generalization of mixed regressi...   \n",
       "1001  Research on adversarial examples are evolved i...   \n",
       "1002  Observational data is being increasingly used ...   \n",
       "1003  Identifying the top-K frequent items is one of...   \n",
       "1004  Learning from pairwise measurements naturally ...   \n",
       "1005  A fundamental goal of systems neuroscience is ...   \n",
       "1006  Causal discovery from empirical data is a fund...   \n",
       "1007  Sparse Principal Component Analysis (SPCA) and...   \n",
       "1008  We study the problem of fast and efficient cla...   \n",
       "1009  Domain-independent probabilistic planners inpu...   \n",
       "1010  In this paper, we investigate the possibility ...   \n",
       "1011  Model compression is essential for serving lar...   \n",
       "\n",
       "                                          Author Emails  \\\n",
       "0                                 francis.bach@inria.fr   \n",
       "1     jianlong.chang@nlpr.ia.ac.cn;jie.gu@nlpr.ia.ac...   \n",
       "2     wanggrun@mail2.sysu.edu.cn;jiefengpeng@gmail.c...   \n",
       "3     costis@csail.mit.edu;ndikkala@mit.edu;jayanti@...   \n",
       "4     shnnam@yonsei.ac.kr;kim_yunji@yonsei.ac.kr;seo...   \n",
       "5     huaibo.huang@cripac.ia.ac.cn;zhihang.li@nlpr.i...   \n",
       "6     j.knoblauch@warwick.ac.uk;j.e.jewson@warwick.a...   \n",
       "7     tysc7237@colorado.edu;karl.ridgeway@colorado.e...   \n",
       "8     chaosheng@pitt.edu;yiran.chen@duke.edu;bzeng@p...   \n",
       "9     imani@ualberta.ca;graves@ualberta.ca;whitem@ua...   \n",
       "10      leile@iu.edu;andnpatt@iu.edu;whitem@ualberta.ca   \n",
       "11    junyanz@mit.edu;ztzhang@mit.edu;ckzhang@mit.ed...   \n",
       "12                 xu573@purdue.edu;wangxiao@purdue.edu   \n",
       "13    mrinmayaster@gmail.com;avinava.dubey@gmail.com...   \n",
       "14    drew_linsley@brown.edu;junkyung_kim@brown.edu;...   \n",
       "15    zszhong@pku.edu.cn;tianchengshen@pku.edu.cn;ib...   \n",
       "16    wyli@cuhk.edu.cn;216019005@link.cuhk.edu.cn;yi...   \n",
       "17        karl.ridgeway@colorado.edu;mozer@colorado.edu   \n",
       "18    mr504@cam.ac.uk;kchoro@google.com;chalusf3@gma...   \n",
       "19    huangsiyuan@ucla.edu;syqi@cs.ucla.edu;yinxuex@...   \n",
       "20                                       clim9@wisc.edu   \n",
       "21    dcullina@princeton.edu;abhagoji@princeton.edu;...   \n",
       "22    yiwen.guo@intel.com;pkuzc@pku.edu.cn;zcs@mail....   \n",
       "23    cdu@zurich.ibm.com;tpa@zurich.ibm.com;rig@zuri...   \n",
       "24    liushice@ict.ac.cn;huyu@ict.ac.cn;zengyiming@i...   \n",
       "25    wuchenfei@bupt.edu.cn;liujinlai@bupt.edu.cn;xj...   \n",
       "26    kanai.sekitoshi@lab.ntt.co.jp;fujiwara.yasuhir...   \n",
       "27    rwq.renwenqi@gmail.com;zhjw1988@gmail.com;fore...   \n",
       "28    tolga.birdal@tum.de;umut.simsekli@telecom-pari...   \n",
       "29    yangt15@fudan.edu.cn;zhangxiangyu@megvii.com;l...   \n",
       "...                                                 ...   \n",
       "982   r.luo@cs.ucl.ac.uk;jianhong.wang.17@ucl.ac.uk;...   \n",
       "983   roiel@cs.cmu.edu;asevekar@andrew.cmu.edu;dwood...   \n",
       "984   soumendu041@gmail.com;purna.sarkar@austin.utex...   \n",
       "985               ycarmon@gmail.com;jduchi@stanford.edu   \n",
       "986   mdhoffma@cs.princeton.edu;mattjj@google.com;tr...   \n",
       "987   golnazg@google.com;tsungyi@google.com;qvl@goog...   \n",
       "988   gab@fb.com;zlin@fb.com;jgehring@fb.com;dangant...   \n",
       "989   sjetley@robots.ox.ac.uk;nicklord@robots.ox.ac....   \n",
       "990   pavel.dvurechensky@gmail.com;darina.dvinskikh@...   \n",
       "991   dminnen@google.com;jballe@google.com;gtoderici...   \n",
       "992   sli370@gatech.edu;benjaminforever@sjtu.edu.cn;...   \n",
       "993   sjzhao@stanford.edu;hyren@cs.stanford.edu;xfyu...   \n",
       "994   gsingh@inf.ethz.ch;timon.gehr@inf.ethz.ch;matt...   \n",
       "995   raghavsomani1995@gmail.com;chiragpvg@gmail.com...   \n",
       "996   krehbiel@richmond.edu;rachelc@gatech.edu;wanro...   \n",
       "997                                 tong-wang@uiowa.edu   \n",
       "998   sara.magliacane@gmail.com;thijsvanommen@gmail....   \n",
       "999   anari.nima@gmail.com;costis@csail.mit.edu;maas...   \n",
       "1000  eyan@cs.cmu.edu;b01902065@ntu.edu.tw;kaizhong8...   \n",
       "1001  aditir1994@gmail.com;jacob.steinhardt@gmail.co...   \n",
       "1002  kallus@cornell.edu;apm470@nyu.edu;urishalit@te...   \n",
       "1003  ankush@gatech.edu;cary.jiang@rice.edu;anshumal...   \n",
       "1004  yichen2016@u.northwestern.edu;zy6@princeton.ed...   \n",
       "1005  as4529@columbia.edu;scott.linderman@columbia.e...   \n",
       "1006            kbellome@purdue.edu;jhonorio@purdue.edu   \n",
       "1007           guy@mit.edu;sp765@mit.edu;mpersu@mit.edu   \n",
       "1008  t-dodenn@microsoft.com;chiragramdas@gmail.com;...   \n",
       "1009  quantum.computing96@gmail.com;sankalp2621998@g...   \n",
       "1010  s.samadi@gmail.com;tao@gatech.edu;jamiemor@cis...   \n",
       "1011  phpchen@ucdavis.edu;sisidaisy@google.com;liyan...   \n",
       "\n",
       "                                          Subject Areas   Decision  \\\n",
       "0     Optimization/Submodular Optimization*; Optimiz...     Poster   \n",
       "1     Deep Learning*; Deep Learning/CNN Architecture...     Poster   \n",
       "2     Deep Learning/CNN Architectures*; Applications...     Poster   \n",
       "3     Probabilistic Methods/Distributed Inference*; ...     Poster   \n",
       "4     Applications/Computational Photography*; Appli...  Spotlight   \n",
       "5     Deep Learning/Generative Models*; Deep Learnin...     Poster   \n",
       "6     Applications/Time Series Analysis*; Algorithms...     Poster   \n",
       "7     Algorithms/Multitask and Transfer Learning*; A...  Spotlight   \n",
       "8     Algorithms/Online Learning*; Applications/Quan...     Poster   \n",
       "9     Reinforcement Learning and Planning/Reinforcem...     Poster   \n",
       "10                   Algorithms/Representation Learning     Poster   \n",
       "11    Deep Learning/Adversarial Networks*; Applicati...     Poster   \n",
       "12                               Theory/Learning Theory     Poster   \n",
       "13          Applications*; Applications/Computer Vision     Poster   \n",
       "14    Deep Learning/Biologically Plausible Deep Netw...     Poster   \n",
       "15    Applications/Computer Vision*; Deep Learning/C...     Poster   \n",
       "16    Algorithms/Sparse Coding and Dimensionality Ex...     Poster   \n",
       "17    Algorithms/Representation Learning*; Algorithm...     Poster   \n",
       "18    Algorithms/Stochastic Methods*; Reinforcement ...  Spotlight   \n",
       "19    Applications/Visual Scene Analysis and Interpr...     Poster   \n",
       "20                                Algorithms/Regression     Poster   \n",
       "21                               Theory/Learning Theory     Poster   \n",
       "22    Deep Learning/Adversarial Networks*; Algorithm...     Poster   \n",
       "23    Applications/Hardware and Systems*; Data, Comp...     Poster   \n",
       "24    Applications/Computer Vision*; Deep Learning/C...     Poster   \n",
       "25    Applications/Visual Question Answering*; Neuro...     Poster   \n",
       "26    Deep Learning*; Deep Learning/Recurrent Networ...     Poster   \n",
       "27    Applications/Computer Vision*; Applications/De...     Poster   \n",
       "28    Applications/Computer Vision*; Applications/Ro...     Poster   \n",
       "29                        Applications/Object Detection     Poster   \n",
       "...                                                 ...        ...   \n",
       "982                          Probabilistic Methods/MCMC     Poster   \n",
       "983                  Algorithms*; Algorithms/Regression  Spotlight   \n",
       "984   Probabilistic Methods/Variational Inference*; ...     Poster   \n",
       "985   Optimization/Non-Convex Optimization*; Algorit...       Oral   \n",
       "986   Probabilistic Methods/Graphical Models*; Data,...     Poster   \n",
       "987   Theory/Regularization*; Deep Learning/CNN Arch...     Poster   \n",
       "988                           Applications/Game Playing     Poster   \n",
       "989   Deep Learning*; Algorithms/Classification; Alg...     Poster   \n",
       "990   Optimization/Convex Optimization*; Algorithms/...  Spotlight   \n",
       "991   Algorithms/Representation Learning*; Applicati...     Poster   \n",
       "992                   Applications/Time Series Analysis  Spotlight   \n",
       "993   Deep Learning/Generative Models*; Deep Learnin...  Spotlight   \n",
       "994   Deep Learning/Adversarial Networks*; Applicati...     Poster   \n",
       "995   Algorithms/Sparsity and Compressed Sensing*; A...  Spotlight   \n",
       "996   Applications/Privacy, Anonymity, and Security*...     Poster   \n",
       "997   Probabilistic Methods/Hierarchical Models*; Ap...     Poster   \n",
       "998   Probabilistic Methods/Causal Inference*; Deep ...     Poster   \n",
       "999   Theory*; Algorithms/Components Analysis (e.g.,...     Poster   \n",
       "1000                                       Optimization     Poster   \n",
       "1001      Applications/Privacy, Anonymity, and Security     Poster   \n",
       "1002  Probabilistic Methods/Causal Inference*; Algor...  Spotlight   \n",
       "1003  Applications/Web Applications and Internet Dat...     Poster   \n",
       "1004  Algorithms/Components Analysis (e.g., CCA, ICA...     Poster   \n",
       "1005  Probabilistic Methods/Latent Variable Models*;...  Spotlight   \n",
       "1006  Theory/Learning Theory*; Probabilistic Methods...     Poster   \n",
       "1007  Algorithms/Components Analysis (e.g., CCA, ICA...     Poster   \n",
       "1008  Deep Learning/Efficient Inference Methods*; De...     Poster   \n",
       "1009                Reinforcement Learning and Planning     Poster   \n",
       "1010  Applications/Fairness, Accountability, and Tra...     Poster   \n",
       "1011           Applications/Natural Language Processing     Poster   \n",
       "\n",
       "                                   Primary Subject Area  \\\n",
       "0                  Optimization/Submodular Optimization   \n",
       "1                                         Deep Learning   \n",
       "2                       Deep Learning/CNN Architectures   \n",
       "3           Probabilistic Methods/Distributed Inference   \n",
       "4                Applications/Computational Photography   \n",
       "5                       Deep Learning/Generative Models   \n",
       "6                     Applications/Time Series Analysis   \n",
       "7            Algorithms/Multitask and Transfer Learning   \n",
       "8                            Algorithms/Online Learning   \n",
       "9     Reinforcement Learning and Planning/Reinforcem...   \n",
       "10                    Algorithms/Representation Learnin   \n",
       "11                   Deep Learning/Adversarial Networks   \n",
       "12                                Theory/Learning Theor   \n",
       "13                                         Applications   \n",
       "14    Deep Learning/Biologically Plausible Deep Netw...   \n",
       "15                         Applications/Computer Vision   \n",
       "16    Algorithms/Sparse Coding and Dimensionality Ex...   \n",
       "17                   Algorithms/Representation Learning   \n",
       "18                        Algorithms/Stochastic Methods   \n",
       "19    Applications/Visual Scene Analysis and Interpr...   \n",
       "20                                 Algorithms/Regressio   \n",
       "21                                Theory/Learning Theor   \n",
       "22                   Deep Learning/Adversarial Networks   \n",
       "23                    Applications/Hardware and Systems   \n",
       "24                         Applications/Computer Vision   \n",
       "25               Applications/Visual Question Answering   \n",
       "26                                        Deep Learning   \n",
       "27                         Applications/Computer Vision   \n",
       "28                         Applications/Computer Vision   \n",
       "29                         Applications/Object Detectio   \n",
       "...                                                 ...   \n",
       "982                           Probabilistic Methods/MCM   \n",
       "983                                          Algorithms   \n",
       "984         Probabilistic Methods/Variational Inference   \n",
       "985                Optimization/Non-Convex Optimization   \n",
       "986              Probabilistic Methods/Graphical Models   \n",
       "987                               Theory/Regularization   \n",
       "988                            Applications/Game Playin   \n",
       "989                                       Deep Learning   \n",
       "990                    Optimization/Convex Optimization   \n",
       "991                  Algorithms/Representation Learning   \n",
       "992                    Applications/Time Series Analysi   \n",
       "993                     Deep Learning/Generative Models   \n",
       "994                  Deep Learning/Adversarial Networks   \n",
       "995          Algorithms/Sparsity and Compressed Sensing   \n",
       "996       Applications/Privacy, Anonymity, and Security   \n",
       "997           Probabilistic Methods/Hierarchical Models   \n",
       "998              Probabilistic Methods/Causal Inference   \n",
       "999                                              Theory   \n",
       "1000                                        Optimizatio   \n",
       "1001       Applications/Privacy, Anonymity, and Securit   \n",
       "1002             Probabilistic Methods/Causal Inference   \n",
       "1003    Applications/Web Applications and Internet Data   \n",
       "1004  Algorithms/Components Analysis (e.g., CCA, ICA...   \n",
       "1005       Probabilistic Methods/Latent Variable Models   \n",
       "1006                             Theory/Learning Theory   \n",
       "1007  Algorithms/Components Analysis (e.g., CCA, ICA...   \n",
       "1008          Deep Learning/Efficient Inference Methods   \n",
       "1009                 Reinforcement Learning and Plannin   \n",
       "1010  Applications/Fairness, Accountability, and Tra...   \n",
       "1011            Applications/Natural Language Processin   \n",
       "\n",
       "           Top-level Primary Subject Area  \\\n",
       "0                            Optimization   \n",
       "1                           Deep Learning   \n",
       "2                           Deep Learning   \n",
       "3                   Probabilistic Methods   \n",
       "4                            Applications   \n",
       "5                           Deep Learning   \n",
       "6                            Applications   \n",
       "7                              Algorithms   \n",
       "8                              Algorithms   \n",
       "9     Reinforcement Learning and Planning   \n",
       "10                             Algorithms   \n",
       "11                          Deep Learning   \n",
       "12                                 Theory   \n",
       "13                           Applications   \n",
       "14                          Deep Learning   \n",
       "15                           Applications   \n",
       "16                             Algorithms   \n",
       "17                             Algorithms   \n",
       "18                             Algorithms   \n",
       "19                           Applications   \n",
       "20                             Algorithms   \n",
       "21                                 Theory   \n",
       "22                          Deep Learning   \n",
       "23                           Applications   \n",
       "24                           Applications   \n",
       "25                           Applications   \n",
       "26                          Deep Learning   \n",
       "27                           Applications   \n",
       "28                           Applications   \n",
       "29                           Applications   \n",
       "...                                   ...   \n",
       "982                 Probabilistic Methods   \n",
       "983                            Algorithms   \n",
       "984                 Probabilistic Methods   \n",
       "985                          Optimization   \n",
       "986                 Probabilistic Methods   \n",
       "987                                Theory   \n",
       "988                          Applications   \n",
       "989                         Deep Learning   \n",
       "990                          Optimization   \n",
       "991                            Algorithms   \n",
       "992                          Applications   \n",
       "993                         Deep Learning   \n",
       "994                         Deep Learning   \n",
       "995                            Algorithms   \n",
       "996                          Applications   \n",
       "997                 Probabilistic Methods   \n",
       "998                 Probabilistic Methods   \n",
       "999                                Theory   \n",
       "1000                          Optimizatio   \n",
       "1001                         Applications   \n",
       "1002                Probabilistic Methods   \n",
       "1003                         Applications   \n",
       "1004                           Algorithms   \n",
       "1005                Probabilistic Methods   \n",
       "1006                               Theory   \n",
       "1007                           Algorithms   \n",
       "1008                        Deep Learning   \n",
       "1009   Reinforcement Learning and Plannin   \n",
       "1010                         Applications   \n",
       "1011                         Applications   \n",
       "\n",
       "                                                    bow   pid  \\\n",
       "0     [effici, algorithm, non, convex, isoton, regre...    29   \n",
       "1     [structur, awar, convolut, neural, network, co...    33   \n",
       "2     [kalman, normal, indispens, compon, batch, nor...    34   \n",
       "3     [hogwild, gibb, panaccur, asynchron, gibb, sam...    37   \n",
       "4     [text, adapt, gener, adversari, network, manip...    40   \n",
       "5     [introva, introspect, variat, autoencod, photo...    59   \n",
       "6     [doubli, robust, bayesian, infer, non, station...    68   \n",
       "7     [adapt, deep, embed, synthesi, method, shot, i...    75   \n",
       "8     [gener, invers, optim, onlin, learn, invers, o...    77   \n",
       "9     [polici, polici, gradient, theorem, use, empha...    85   \n",
       "10    [supervis, autoencod, improv, gener, perform, ...    88   \n",
       "11    [visual, object, network, imag, gener, disenta...    92   \n",
       "12    [understand, weight, normal, deep, neural, net...    95   \n",
       "13    [learn, pipelin, limit, data, domain, knowledg...    99   \n",
       "14    [learn, long, rang, spatial, depend, horizont,...   102   \n",
       "15    [joint, sub, band, learn, cliqu, structur, wav...   110   \n",
       "16    [fast, similar, search, via, optim, spars, lif...   142   \n",
       "17    [learn, deep, disentangl, embed, statist, loss...   145   \n",
       "18    [geometr, coupl, mont, carlo, sampl, mont, car...   153   \n",
       "19    [cooper, holist, 3d, scene, understand, singl,...   175   \n",
       "20    [effici, prune, algorithm, robust, isoton, reg...   177   \n",
       "21    [pac, learn, presenc, adversari, exist, evas, ...   178   \n",
       "22    [spars, dnn, improv, adversari, robust, deep, ...   182   \n",
       "23    [snap, ml, hierarch, framework, machin, learn,...   185   \n",
       "24    [see, think, disentangl, semant, scene, comple...   186   \n",
       "25    [chain, reason, visual, question, answer, reas...   187   \n",
       "26    [sigsoftmax, reanalysi, softmax, bottleneck, s...   188   \n",
       "27    [deep, non, blind, deconvolut, via, gener, low...   191   \n",
       "28    [probabilist, pose, graph, optim, via, bingham...   192   \n",
       "29    [metaanchor, learn, detect, object, custom, an...   207   \n",
       "...                                                 ...   ...   \n",
       "982   [thermostat, assist, continu, temper, hamilton...  6787   \n",
       "983   [robust, subspac, approxim, stream, studi, rob...  6793   \n",
       "984   [mean, field, stochast, blockmodel, optim, lan...  6802   \n",
       "985   [analysi, krylov, subspac, solut, regular, non...  6832   \n",
       "986   [autoconj, recogn, exploit, conjugaci, without...  6836   \n",
       "987   [dropblock, regular, method, convolut, network...  6839   \n",
       "988   [forward, model, partial, observ, strategi, ga...  6843   \n",
       "989   [friend, like, need, adversari, vulner, deep, ...  6847   \n",
       "990   [decentr, random, faster, algorithm, wasserste...  6859   \n",
       "991   [joint, autoregress, hierarch, prior, learn, i...  6863   \n",
       "992   [learn, tempor, point, process, via, reinforc,...  6874   \n",
       "993   [bia, gener, deep, gener, model, empir, studi,...  6882   \n",
       "994   [fast, effect, robust, certif, present, new, m...  6892   \n",
       "995   [support, recoveri, orthogon, match, pursuit, ...  6901   \n",
       "996   [differenti, privat, chang, point, detect, cha...  6905   \n",
       "997   [multi, valu, rule, set, interpret, classif, f...  6913   \n",
       "998   [domain, adapt, use, causal, infer, predict, i...  6921   \n",
       "999   [smooth, analysi, discret, tensor, decomposit,...  6923   \n",
       "1000  [mixlasso, gener, mix, regress, via, convex, a...  6961   \n",
       "1001  [semidefinit, relax, certifi, robust, adversar...  6968   \n",
       "1002  [remov, hidden, confound, experiment, ground, ...  6972   \n",
       "1003  [topkapi, parallel, fast, sketch, find, top, f...  6978   \n",
       "1004  [contrast, learn, pairwis, measur, learn, pair...  7985   \n",
       "1005  [point, process, latent, variabl, model, freel...  7992   \n",
       "1006  [comput, statist, effici, learn, bay, net, use...  7994   \n",
       "1007  [spars, pca, spars, linear, regress, spars, pr...  7997   \n",
       "1008  [sequenti, data, classif, resourc, constrain, ...  8002   \n",
       "1009  [transfer, deep, reactiv, polici, mdp, plan, d...  8009   \n",
       "1010  [price, fair, pca, one, extra, dimens, thi, pa...  8034   \n",
       "1011  [groupreduc, block, wise, low, rank, approxim,...  8035   \n",
       "\n",
       "                                                   tpms   tsne_all  tsne_tpms  \\\n",
       "0     [0.724210006, 0.547847061, 0.62121431, 0.69992...  29.950420  41.906616   \n",
       "1     [0.722796601, 0.7524726279999999, 0.681080612,...  69.435448 -41.231922   \n",
       "2     [0.605652029, 0.624528822, 0.5549479039999999,...  75.101242 -22.875866   \n",
       "3     [0.6039084920000001, 0.571028136, 0.547187392,... -42.259544  22.692909   \n",
       "4     [0.6074082789999999, 0.604121554, 0.5843663610...  -8.646683 -43.590607   \n",
       "5     [0.554898813, 0.566786583, 0.514959909, 0.5606...  81.031715 -14.190269   \n",
       "6     [0.811906661, 0.7286812490000001, 0.745909935,... -18.716530  -3.146081   \n",
       "7     [0.7246898359999999, 0.74860931, 0.72164041200... -55.623451 -29.995140   \n",
       "8     [0.8553071390000001, 0.729569048, 0.771284843,... -79.361519  25.245207   \n",
       "9     [0.5770863589999999, 0.523376441, 0.518179388,...  44.501297   7.835011   \n",
       "10    [0.7831208590000001, 0.8086628229999999, 0.745... -58.400303 -27.623331   \n",
       "11    [0.622592223, 0.620137725, 0.574635252, 0.6193...  85.215065 -45.918297   \n",
       "12    [0.644970711, 0.6021990779999999, 0.611452154,...   9.355120   0.585828   \n",
       "13    [0.825202962, 0.8357769540000001, 0.8245410609... -15.508667 -35.415489   \n",
       "14    [0.753889782, 0.8060686090000001, 0.7139329390...  66.520264 -39.277554   \n",
       "15    [0.665462302, 0.631348907, 0.61443569, 0.65938...  -3.620618 -41.783928   \n",
       "16    [0.8577442009999999, 0.7920245159999999, 0.809... -59.549507 -19.159504   \n",
       "17    [0.801685634, 0.791540459, 0.772199449, 0.8187... -52.455151 -29.709421   \n",
       "18    [0.796080575, 0.669703717, 0.714382987, 0.7818... -72.128998  22.797417   \n",
       "19    [0.635211113, 0.587038424, 0.582188994, 0.6233...  -7.480874 -46.575882   \n",
       "20    [0.8350809440000001, 0.641266087, 0.761110935,... -74.375404  41.805172   \n",
       "21    [0.5843463000000001, 0.563068797, 0.533589984,...   9.359765 -20.007828   \n",
       "22    [0.666966905, 0.637015755, 0.638722607, 0.7032...  84.842842 -20.159740   \n",
       "23    [0.657971973, 0.853205806, 0.618791222, 0.6497... -16.822359 -20.884203   \n",
       "24    [0.657856715, 0.632397676, 0.6396587229999999,...  -4.536843 -46.435524   \n",
       "25    [0.632062365, 0.6729400529999999, 0.603445259,... -10.336796 -36.345360   \n",
       "26    [0.692489644, 0.790134204, 0.660755629, 0.7194...  69.954987 -24.284136   \n",
       "27    [0.562258779, 0.5202836, 0.506214686, 0.550357...  -3.312739 -42.153278   \n",
       "28    [0.9113688670000001, 0.7563436379999999, 0.820...  -2.593879  27.874113   \n",
       "29    [0.620705712, 0.593533387, 0.572714624, 0.6164...  -6.911834 -44.603474   \n",
       "...                                                 ...        ...        ...   \n",
       "982   [0.646289553, 0.620857109, 0.586481252, 0.6541... -43.545441  -4.772652   \n",
       "983   [0.540987701, 0.441798132, 0.49352610399999997... -75.541176  31.828382   \n",
       "984   [0.735002521, 0.627056098, 0.647996389, 0.7320... -45.091202  22.743847   \n",
       "985   [0.644204279, 0.46829059700000003, 0.536020003...  26.129072  43.834412   \n",
       "986   [0.644937403, 0.646330124, 0.606580474, 0.6317... -36.022869  -2.977412   \n",
       "987   [0.602325926, 0.709435875, 0.611376699, 0.6140...  10.156830 -40.257950   \n",
       "988   [0.64940197, 0.696797065, 0.612499372, 0.66309... -10.947182 -31.871689   \n",
       "989   [0.596239485, 0.552854089, 0.56523045, 0.61261...  69.137093 -26.654100   \n",
       "990   [0.649590907, 0.572511066, 0.579816594, 0.6330...  32.173798  28.452133   \n",
       "991   [0.5645583710000001, 0.599846334, 0.522823875,... -52.424301 -30.890600   \n",
       "992   [0.6848055690000001, 0.606161123, 0.618028853,... -19.862894   8.033325   \n",
       "993   [0.825245676, 0.77820804, 0.764052464, 0.83451...  80.826553 -38.422794   \n",
       "994   [0.656920721, 0.7048807429999999, 0.624150393,...  84.853836 -20.459106   \n",
       "995   [0.6322439089999999, 0.5179587760000001, 0.563... -71.281883  30.983622   \n",
       "996   [0.6977355690000001, 0.557927934, 0.63827413, ... -28.408152  34.926235   \n",
       "997   [0.823699588, 0.7256162290000001, 0.770973646,... -37.061535  16.019241   \n",
       "998   [0.534160482, 0.482813768, 0.514349219, 0.5274... -33.443409  13.715412   \n",
       "999   [0.693092713, 0.629186489, 0.656472765, 0.7012...   4.982391  19.488535   \n",
       "1000  [0.791815187, 0.657667486, 0.70105964, 0.77798...  11.150247  29.388924   \n",
       "1001  [0.612903855, 0.584632164, 0.580678234, 0.6383... -26.983023 -19.791059   \n",
       "1002  [0.586181571, 0.490689461, 0.549189971, 0.5911... -33.386219  14.227854   \n",
       "1003  [0.672761353, 0.6915534390000001, 0.673524338,... -24.045568   1.927942   \n",
       "1004  [0.801794205, 0.6445370810000001, 0.70768539, ... -70.215393  24.161211   \n",
       "1005  [0.78844959, 0.730344946, 0.7138572390000001, ... -47.077015  -6.283218   \n",
       "1006  [0.442452024, 0.376913364, 0.45425219, 0.45383...  13.572625  14.079021   \n",
       "1007  [0.755127242, 0.609168548, 0.665014251, 0.7336... -70.626175  30.425714   \n",
       "1008  [0.849686171, 0.9341852970000001, 0.7916773859...  77.401146 -28.128359   \n",
       "1009  [0.7646644690000001, 0.7638223829999999, 0.729...  41.460049   4.912152   \n",
       "1010  [0.7302362170000001, 0.631884585, 0.691013077,... -22.797361  26.325262   \n",
       "1011  [0.7068314809999999, 0.8144392220000001, 0.691... -13.926091 -24.498652   \n",
       "\n",
       "       Session  PosterSession  tpsa  \n",
       "0          NaN              0     6  \n",
       "1          NaN              0     1  \n",
       "2          NaN              0     1  \n",
       "3          NaN              0     3  \n",
       "4     D3_S2_T2              6     2  \n",
       "5          NaN              0     1  \n",
       "6          NaN              0     2  \n",
       "7     D3_S1_T1              5     0  \n",
       "8          NaN              0     0  \n",
       "9          NaN              0     5  \n",
       "10         NaN              0     0  \n",
       "11         NaN              0     1  \n",
       "12         NaN              0     4  \n",
       "13         NaN              0     2  \n",
       "14         NaN              0     1  \n",
       "15         NaN              0     2  \n",
       "16         NaN              0     0  \n",
       "17         NaN              0     0  \n",
       "18    D2_S2_T1              4     0  \n",
       "19         NaN              0     2  \n",
       "20         NaN              0     0  \n",
       "21         NaN              0     4  \n",
       "22         NaN              0     1  \n",
       "23         NaN              0     2  \n",
       "24         NaN              0     2  \n",
       "25         NaN              0     2  \n",
       "26         NaN              0     1  \n",
       "27         NaN              0     2  \n",
       "28         NaN              0     2  \n",
       "29         NaN              0     2  \n",
       "...        ...            ...   ...  \n",
       "982        NaN              0     3  \n",
       "983   D3_S1_T3              5     0  \n",
       "984        NaN              0     3  \n",
       "985   D2_S2_T3              4     6  \n",
       "986        NaN              0     3  \n",
       "987        NaN              0     4  \n",
       "988        NaN              0     2  \n",
       "989        NaN              0     1  \n",
       "990   D3_S2_T3              6     6  \n",
       "991        NaN              0     0  \n",
       "992   D2_S1_T2              3     2  \n",
       "993   D2_S2_T2              4     1  \n",
       "994        NaN              0     1  \n",
       "995   D2_S2_T3              4     0  \n",
       "996        NaN              0     2  \n",
       "997        NaN              0     3  \n",
       "998        NaN              0     3  \n",
       "999        NaN              0     4  \n",
       "1000       NaN              0    11  \n",
       "1001       NaN              0     2  \n",
       "1002  D3_S1_T1              5     3  \n",
       "1003       NaN              0     2  \n",
       "1004       NaN              0     0  \n",
       "1005  D1_S2_T1              2     3  \n",
       "1006       NaN              0     4  \n",
       "1007       NaN              0     0  \n",
       "1008       NaN              0     1  \n",
       "1009       NaN              0    12  \n",
       "1010       NaN              0     2  \n",
       "1011       NaN              0     2  \n",
       "\n",
       "[1012 rows x 16 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paper ID                          325\n",
       "Paper Title                       325\n",
       "Abstract                          325\n",
       "Author Emails                     325\n",
       "Subject Areas                     325\n",
       "Decision                          325\n",
       "Primary Subject Area              325\n",
       "Top-level Primary Subject Area    325\n",
       "bow                               325\n",
       "pid                               325\n",
       "tpms                              325\n",
       "tsne_all                          325\n",
       "tsne_tpms                         325\n",
       "Session                             0\n",
       "PosterSession                     325\n",
       "day_v3                            325\n",
       "tpsa                              325\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_df[poster_df['PosterSession']==0].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Oral Session'] not in index\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-c0a4d162e924>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mposter_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Top-level Primary Subject Area'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Decision'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Session'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Oral Session'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PosterSession'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jeshu\\pycharmprojects\\scheduler\\venv1\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeshu\\pycharmprojects\\scheduler\\venv1\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeshu\\pycharmprojects\\scheduler\\venv1\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Oral Session'] not in index\""
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "poster_df[['Top-level Primary Subject Area', 'Decision', 'Session', 'Oral Session', 'PosterSession']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'day'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-2bd2a06dbabb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mposter_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Top-level Primary Subject Area'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposter_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jeshu\\pycharmprojects\\scheduler\\venv1\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'day'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "poster_df['Top-level Primary Subject Area'].groupby(poster_df.day).apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poster_df.to_csv('../../data/session_arrangement_20171012.csv',\n",
    "#                  index=False, columns=['Paper ID', 'Paper Title',\n",
    "#                                 'Abstract', 'Subject Areas',\n",
    "#                                 'Primary Subject Area', 'Top-level Primary Subject Area',\n",
    "#                                 'tsne_all', 'tsne_tpms', 'Decision',\n",
    "#                                 'Session', 'PosterSession'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually group a few posters to the same day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-level Primary Subject Area</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Session</th>\n",
       "      <th>PosterSession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Data, Competitions, Implementations, and Software</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>D3_S1_T1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>Data, Competitions, Implementations, and Software</td>\n",
       "      <td>Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Data, Competitions, Implementations, and Software</td>\n",
       "      <td>Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>Data, Competitions, Implementations, and Software</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>D3_S1_T1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>Data, Competitions, Implementations, and Software</td>\n",
       "      <td>Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>Data, Competitions, Implementations, and Software</td>\n",
       "      <td>Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Top-level Primary Subject Area   Decision   Session  \\\n",
       "299  Data, Competitions, Implementations, and Software  Spotlight  D3_S1_T1   \n",
       "578  Data, Competitions, Implementations, and Software     Poster       NaN   \n",
       "702  Data, Competitions, Implementations, and Software     Poster       NaN   \n",
       "808  Data, Competitions, Implementations, and Software  Spotlight  D3_S1_T1   \n",
       "905  Data, Competitions, Implementations, and Software     Poster       NaN   \n",
       "937  Data, Competitions, Implementations, and Software     Poster       NaN   \n",
       "\n",
       "     PosterSession  \n",
       "299              3  \n",
       "578              0  \n",
       "702              0  \n",
       "808              3  \n",
       "905              1  \n",
       "937              0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_df[poster_df['Top-level Primary Subject Area'].isin(['None of the above', 'Data, Competitions, Implementations, and Software'])][['Top-level Primary Subject Area', 'Decision', 'Session', 'PosterSession']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Session</th>\n",
       "      <th>PosterSession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>Learning to Multitask</td>\n",
       "      <td>Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>When do random forests fail?</td>\n",
       "      <td>Poster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Paper Title Decision Session  PosterSession\n",
       "534         Learning to Multitask   Poster     NaN              3\n",
       "276  When do random forests fail?   Poster     NaN              3"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_df[poster_df['Top-level Primary Subject Area'].isin(['Algorithms']) & (poster_df.Decision == 'Poster') & (poster_df.PosterSession == 3)][['Paper Title', 'Decision', 'Session', 'PosterSession']].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72999.511335739619, 85, 63.25)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.update(325, 330, 'force')\n",
    "searcher.update(677, 476, 'force')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_fixed.update([325, 677])\n",
    "poster_free.remove(325)\n",
    "poster_free.remove(677)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_df['day_v2'] = poster_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day_v2                                                   \n",
       "1       Algorithms                                           143\n",
       "        Deep Learning                                          6\n",
       "        Theory                                                 6\n",
       "        Applications                                           4\n",
       "        Reinforcement Learning and Planning                    3\n",
       "        Neuroscience and Cognitive Science                     3\n",
       "        Probabilistic Methods                                  2\n",
       "        Optimization                                           2\n",
       "2       Theory                                                66\n",
       "        Deep Learning                                         48\n",
       "        Neuroscience and Cognitive Science                    12\n",
       "        Probabilistic Methods                                 11\n",
       "        Algorithms                                            10\n",
       "        Applications                                           9\n",
       "        Deep Learnin                                           4\n",
       "        Reinforcement Learning and Planning                    3\n",
       "        Optimization                                           3\n",
       "        Data, Competitions, Implementations, and Software      2\n",
       "        Reinforcement Learning and Plannin                     1\n",
       "3       Reinforcement Learning and Planning                   55\n",
       "        Applications                                          47\n",
       "        Algorithms                                            26\n",
       "        Probabilistic Methods                                  9\n",
       "        Optimization                                           9\n",
       "        Theory                                                 7\n",
       "        Deep Learning                                          6\n",
       "        Neuroscience and Cognitive Science                     6\n",
       "        Deep Learnin                                           1\n",
       "        Application                                            1\n",
       "        Data, Competitions, Implementations, and Software      1\n",
       "        Optimizatio                                            1\n",
       "4       Deep Learning                                        128\n",
       "        Algorithms                                            10\n",
       "        Optimization                                          10\n",
       "        Probabilistic Methods                                  7\n",
       "        Reinforcement Learning and Planning                    7\n",
       "        Neuroscience and Cognitive Science                     3\n",
       "        Theory                                                 1\n",
       "        Deep Learnin                                           1\n",
       "        Data, Competitions, Implementations, and Software      1\n",
       "        Applications                                           1\n",
       "5       Probabilistic Methods                                 76\n",
       "        Optimization                                          39\n",
       "        Theory                                                15\n",
       "        Algorithms                                            15\n",
       "        Reinforcement Learning and Planning                    8\n",
       "        Neuroscience and Cognitive Science                     8\n",
       "        Deep Learning                                          3\n",
       "        Data, Competitions, Implementations, and Software      2\n",
       "        Deep Learnin                                           1\n",
       "        Applications                                           1\n",
       "6       Applications                                         131\n",
       "        Optimization                                          17\n",
       "        Reinforcement Learning and Planning                    9\n",
       "        Deep Learning                                          3\n",
       "        Algorithms                                             3\n",
       "        Theory                                                 2\n",
       "        Application                                            1\n",
       "        Probabilistic Methods                                  1\n",
       "        Neuroscience and Cognitive Science                     1\n",
       "Name: Top-level Primary Subject Area, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_df['Top-level Primary Subject Area'].groupby(poster_df.day_v2).apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[con] 72994.22, 2, 62'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "searcher = Searcher(poster_day, poster_tpsa, poster_sim, poster_conflicts_first_author)\n",
    "\n",
    "update_cnt = 0\n",
    "for epoch in tnrange(5):\n",
    "#     np.random.shuffle(poster_free)\n",
    "#     for i,j in zip(poster_free[:-1:2], poster_free[1::2]):        \n",
    "#         sval, cval, bval = searcher.optimize_balance(i, j)\n",
    "#         update_cnt += 1\n",
    "#         if update_cnt % 500 == 1:\n",
    "#             clear_output()\n",
    "#             display('[bal] %.2f, %d, %d' % (sval, cval, bval))        \n",
    "    \n",
    "    np.random.shuffle(poster_free)\n",
    "    for i,j in zip(poster_free[:-1:2], poster_free[1::2]):        \n",
    "        sval, cval, bval = searcher.optimize_conflicts(i, j)\n",
    "        update_cnt += 1\n",
    "        if update_cnt % 100 == 1:\n",
    "            clear_output()\n",
    "            display('[con] %.2f, %d, %d' % (sval, cval, bval))\n",
    "\n",
    "#     np.random.shuffle(poster_free)\n",
    "#     for i,j in zip(poster_free[:-1:2], poster_free[1::2]):        \n",
    "#         sval, cval, bval = searcher.optimize_similarities(i, j)\n",
    "#         update_cnt += 1\n",
    "#         if update_cnt % 500 == 1:\n",
    "#             clear_output()\n",
    "#             display('[sim] %.2f, %d, %d' % (sval, cval, bval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_df['PosterSession'] = poster_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_df.to_csv('session_arr_final.csv',\n",
    "                 index=False, columns=['Paper ID', 'Paper Title',\n",
    "                                'Abstract', 'Subject Areas',\n",
    "                                'Primary Subject Area', 'Top-level Primary Subject Area',\n",
    "                                'tsne_all', 'tsne_tpms', 'Decision',\n",
    "                                'Session', 'PosterSession'], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving the posters of Day 4 talks from Day 1 to Day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in day4_talks:\n",
    "    poster_day[i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# move free posters from day 3 to day 1\n",
    "day3_free = [i for i in poster_free if poster_day[i] == 3]\n",
    "np.random.shuffle(day3_free)\n",
    "for i in day3_free[:len(day4_talks)]:\n",
    "    poster_day[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(find_conflicts(poster_day, poster_conflicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(find_conflicts(poster_day, poster_conflicts_first_author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_violators(poster_day, num_posters_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[sim] 75397.44, 0, 62'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "searcher = Searcher(poster_day, poster_tpsa, poster_sim, poster_conflicts_first_author)\n",
    "\n",
    "update_cnt = 0\n",
    "for epoch in tnrange(5000):\n",
    "#     np.random.shuffle(poster_free)\n",
    "#     for i,j in zip(poster_free[:-1:2], poster_free[1::2]):        \n",
    "#         sval, cval, bval = searcher.optimize_balance(i, j)\n",
    "#         update_cnt += 1\n",
    "#         if update_cnt % 500 == 1:\n",
    "#             clear_output()\n",
    "#             display('[bal] %.2f, %d, %d' % (sval, cval, bval))        \n",
    "    \n",
    "#     np.random.shuffle(poster_free)\n",
    "#     for i,j in zip(poster_free[:-1:2], poster_free[1::2]):        \n",
    "#         sval, cval, bval = searcher.optimize_conflicts(i, j)\n",
    "#         update_cnt += 1\n",
    "#         if update_cnt % 100 == 1:\n",
    "#             clear_output()\n",
    "#             display('[con] %.2f, %d, %d' % (sval, cval, bval))\n",
    "\n",
    "    np.random.shuffle(poster_free)\n",
    "    for i,j in zip(poster_free[:-1:2], poster_free[1::2]):        \n",
    "        sval, cval, bval = searcher.optimize_similarities(i, j)\n",
    "        update_cnt += 1\n",
    "        if update_cnt % 500 == 1:\n",
    "            clear_output()\n",
    "            display('[sim] %.2f, %d, %d' % (sval, cval, bval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poster_df['day_v3'] = poster_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day_v2                                                   \n",
       "1       Algorithms                                           66\n",
       "        Deep Learning                                        45\n",
       "        Applications                                         32\n",
       "        Probabilistic Methods                                23\n",
       "        Optimization                                         21\n",
       "        Theory                                               21\n",
       "        Neuroscience and cognitive science                   11\n",
       "        Reinforcement Learning and Planning                   8\n",
       "2       Algorithms                                           66\n",
       "        Deep Learning                                        45\n",
       "        Applications                                         32\n",
       "        Probabilistic Methods                                23\n",
       "        Theory                                               22\n",
       "        Optimization                                         21\n",
       "        Neuroscience and cognitive science                   11\n",
       "        Reinforcement Learning and Planning                   6\n",
       "3       Algorithms                                           64\n",
       "        Deep Learning                                        44\n",
       "        Applications                                         31\n",
       "        Probabilistic Methods                                23\n",
       "        Optimization                                         21\n",
       "        Theory                                               21\n",
       "        Neuroscience and cognitive science                   10\n",
       "        Reinforcement Learning and Planning                   8\n",
       "        None of the above                                     2\n",
       "        Data, Competitions, Implementations, and Software     2\n",
       "Name: Top-level Primary Subject Area, dtype: int64"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_df['Top-level Primary Subject Area'].groupby(poster_df.day_v2).apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day_v3                                                   \n",
       "1       Algorithms                                           66\n",
       "        Deep Learning                                        45\n",
       "        Applications                                         32\n",
       "        Probabilistic Methods                                23\n",
       "        Optimization                                         21\n",
       "        Theory                                               21\n",
       "        Neuroscience and cognitive science                   11\n",
       "        Reinforcement Learning and Planning                   8\n",
       "2       Algorithms                                           66\n",
       "        Deep Learning                                        45\n",
       "        Applications                                         32\n",
       "        Probabilistic Methods                                23\n",
       "        Theory                                               22\n",
       "        Optimization                                         21\n",
       "        Neuroscience and cognitive science                   11\n",
       "        Reinforcement Learning and Planning                   6\n",
       "3       Algorithms                                           64\n",
       "        Deep Learning                                        44\n",
       "        Applications                                         31\n",
       "        Probabilistic Methods                                23\n",
       "        Optimization                                         21\n",
       "        Theory                                               21\n",
       "        Neuroscience and cognitive science                   10\n",
       "        Reinforcement Learning and Planning                   8\n",
       "        None of the above                                     2\n",
       "        Data, Competitions, Implementations, and Software     2\n",
       "Name: Top-level Primary Subject Area, dtype: int64"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_df['Top-level Primary Subject Area'].groupby(poster_df.day_v3).apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_df['PosterSession'] = poster_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosterSession                                                   \n",
       "1              Deep Learning                                        134\n",
       "               Applications                                          16\n",
       "               Algorithms                                             7\n",
       "               Theory                                                 3\n",
       "               Optimization                                           3\n",
       "               Neuroscience and Cognitive Science                     2\n",
       "               Deep Learnin                                           1\n",
       "               Application                                            1\n",
       "               Probabilistic Methods                                  1\n",
       "               Reinforcement Learning and Planning                    1\n",
       "2              Applications                                         128\n",
       "               Deep Learning                                         15\n",
       "               Algorithms                                             8\n",
       "               Neuroscience and Cognitive Science                     8\n",
       "               Theory                                                 5\n",
       "               Reinforcement Learning and Planning                    2\n",
       "               Data, Competitions, Implementations, and Software      1\n",
       "               Probabilistic Methods                                  1\n",
       "               Optimization                                           1\n",
       "3              Theory                                                66\n",
       "               Applications                                          35\n",
       "               Deep Learning                                         22\n",
       "               Optimization                                          14\n",
       "               Algorithms                                            10\n",
       "               Reinforcement Learning and Planning                   10\n",
       "               Probabilistic Methods                                  8\n",
       "               Data, Competitions, Implementations, and Software      2\n",
       "               Neuroscience and Cognitive Science                     1\n",
       "               Optimizatio                                            1\n",
       "4              Reinforcement Learning and Planning                   65\n",
       "               Optimization                                          32\n",
       "               Probabilistic Methods                                 24\n",
       "               Theory                                                13\n",
       "               Neuroscience and Cognitive Science                    11\n",
       "               Algorithms                                             8\n",
       "               Deep Learning                                          7\n",
       "               Applications                                           7\n",
       "               Reinforcement Learning and Plannin                     1\n",
       "               Data, Competitions, Implementations, and Software      1\n",
       "5              Probabilistic Methods                                 71\n",
       "               Algorithms                                            47\n",
       "               Optimization                                          11\n",
       "               Theory                                                10\n",
       "               Neuroscience and Cognitive Science                    10\n",
       "               Deep Learning                                          7\n",
       "               Applications                                           5\n",
       "               Deep Learnin                                           4\n",
       "               Data, Competitions, Implementations, and Software      2\n",
       "               Application                                            1\n",
       "6              Algorithms                                           127\n",
       "               Optimization                                          19\n",
       "               Deep Learning                                          9\n",
       "               Reinforcement Learning and Planning                    7\n",
       "               Deep Learnin                                           2\n",
       "               Applications                                           2\n",
       "               Probabilistic Methods                                  1\n",
       "               Neuroscience and Cognitive Science                     1\n",
       "Name: Top-level Primary Subject Area, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poster_df['Top-level Primary Subject Area'].groupby(poster_df.PosterSession).apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "poster_df.to_csv('poster_new.csv',\n",
    "                 index=False, columns=['Paper ID', 'Paper Title',\n",
    "                                'Abstract', 'Subject Areas',\n",
    "                                'Primary Subject Area', 'Top-level Primary Subject Area',\n",
    "                                'tsne_all', 'tsne_tpms', 'Decision',\n",
    "                                'Session', 'PosterSession'], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
